2018-05-14 16:57:00.696551: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-14 16:57:00.696653: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-14 16:57:00.696661: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-05-14 16:57:00.696668: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-14 16:57:00.696673: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-05-14 16:57:01.835568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:03:00.0
Total memory: 10.91GiB
Free memory: 4.60GiB
2018-05-14 16:57:01.835805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2018-05-14 16:57:01.835824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2018-05-14 16:57:01.835859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0)
2018-05-14 16:57:48.785636: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 784.00MiB.  Current allocation summary follows.
2018-05-14 16:57:48.785766: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785784: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785796: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785808: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785820: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785832: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785844: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785856: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785869: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785884: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 1, Chunks in use: 0 209.5KiB allocated for chunks. 9.4KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785937: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785950: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785961: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785972: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785982: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.785993: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.786004: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.786014: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.786025: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.786036: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.786048: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 1, Chunks in use: 0 315.65MiB allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-05-14 16:57:48.786060: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 784.00MiB was 256.00MiB, Chunk State: 
2018-05-14 16:57:48.786083: I tensorflow/core/common_runtime/bfc_allocator.cc:666]   Size: 315.65MiB | Requested Size: 0B | in_use: 0, prev:   Size: 200.0KiB | Requested Size: 200.0KiB | in_use: 1
2018-05-14 16:57:48.786098: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020da00000 of size 1280
2018-05-14 16:57:48.786106: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020da00500 of size 256
2018-05-14 16:57:48.786114: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020da00600 of size 256
2018-05-14 16:57:48.786122: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020da00700 of size 256
2018-05-14 16:57:48.786129: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020da00800 of size 256
2018-05-14 16:57:48.786138: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020da00900 of size 9728
2018-05-14 16:57:48.786146: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020da02f00 of size 204800
2018-05-14 16:57:48.786154: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020da34f00 of size 266240
2018-05-14 16:57:48.786169: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020da75f00 of size 256
2018-05-14 16:57:48.786177: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020da76000 of size 256
2018-05-14 16:57:48.786186: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020da76100 of size 4096
2018-05-14 16:57:48.786194: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020da77100 of size 512
2018-05-14 16:57:48.786202: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020daab900 of size 345856
2018-05-14 16:57:48.786210: I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1020da77300 of size 214528
2018-05-14 16:57:48.786219: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1024de00000 of size 1073741824
2018-05-14 16:57:48.786228: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1028e000000 of size 1073741824
2018-05-14 16:57:48.786237: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102ce000000 of size 256
2018-05-14 16:57:48.786245: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102ce000100 of size 256
2018-05-14 16:57:48.786252: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102ce000200 of size 4096
2018-05-14 16:57:48.786260: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102ce001200 of size 512
2018-05-14 16:57:48.786268: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102ce001400 of size 256
2018-05-14 16:57:48.786275: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102ce001500 of size 256
2018-05-14 16:57:48.786283: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102ce001600 of size 9728
2018-05-14 16:57:48.786291: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102ce003c00 of size 9728
2018-05-14 16:57:48.786299: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102ce006200 of size 204800
2018-05-14 16:57:48.786307: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102ce038200 of size 204800
2018-05-14 16:57:48.786315: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102ce06a200 of size 822083584
2018-05-14 16:57:48.786324: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102ff06a200 of size 1324965376
2018-05-14 16:57:48.786333: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1034e000000 of size 266240
2018-05-14 16:57:48.786341: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1034e041000 of size 266240
2018-05-14 16:57:48.786348: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1034e082000 of size 256
2018-05-14 16:57:48.786356: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1034e082100 of size 256
2018-05-14 16:57:48.786364: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1034e082200 of size 256
2018-05-14 16:57:48.786372: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1034e082300 of size 256
2018-05-14 16:57:48.786379: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1034e082400 of size 4096
2018-05-14 16:57:48.786387: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1034e083400 of size 4096
2018-05-14 16:57:48.786395: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1034e084400 of size 512
2018-05-14 16:57:48.786402: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1034e084600 of size 512
2018-05-14 16:57:48.786410: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1034e084800 of size 9728
2018-05-14 16:57:48.786418: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1034e086e00 of size 204800
2018-05-14 16:57:48.786426: I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1034e0b8e00 of size 330985984
2018-05-14 16:57:48.786434: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2018-05-14 16:57:48.786451: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 14 Chunks of size 256 totalling 3.5KiB
2018-05-14 16:57:48.786462: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 4 Chunks of size 512 totalling 2.0KiB
2018-05-14 16:57:48.786471: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2018-05-14 16:57:48.786480: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 4 Chunks of size 4096 totalling 16.0KiB
2018-05-14 16:57:48.786489: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 4 Chunks of size 9728 totalling 38.0KiB
2018-05-14 16:57:48.786499: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 4 Chunks of size 204800 totalling 800.0KiB
2018-05-14 16:57:48.786508: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 3 Chunks of size 266240 totalling 780.0KiB
2018-05-14 16:57:48.786517: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 345856 totalling 337.8KiB
2018-05-14 16:57:48.786527: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 822083584 totalling 784.00MiB
2018-05-14 16:57:48.786536: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 1073741824 totalling 2.00GiB
2018-05-14 16:57:48.786545: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1324965376 totalling 1.23GiB
2018-05-14 16:57:48.786554: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 4.00GiB
2018-05-14 16:57:48.786571: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                  4627759104
InUse:                  4296558592
MaxInUse:               4296763392
NumAllocs:                      41
MaxAllocSize:           1324965376

2018-05-14 16:57:48.786588: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ******************xxxxx******************xxxxx************************************xxxxxxxxxx*_______
2018-05-14 16:57:48.786620: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[200704,1024]
Initializing models
logits' shape is: Tensor("Shape_5:0", shape=(2,), dtype=int32)
Y's shape is Tensor("Shape_6:0", shape=(2,), dtype=int32)
Traceback (most recent call last):
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1327, in _do_call
    return fn(*args)
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1306, in _run_fn
    status, run_metadata)
  File "/home1/wyk/conda/envs/python3/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[200704,1024]
	 [[Node: Variable_2/Assign = Assign[T=DT_FLOAT, _class=["loc:@Variable_2"], use_locking=true, validate_shape=true, _device="/job:localhost/replica:0/task:0/gpu:0"](Variable_2, random_normal_2)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "cnn.py", line 285, in <module>
    tf.app.run()
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "cnn.py", line 277, in main
    model = Model()
  File "cnn.py", line 159, in __init__
    self.sess.run(self.init)
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 895, in run
    run_metadata_ptr)
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1321, in _do_run
    options, run_metadata)
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[200704,1024]
	 [[Node: Variable_2/Assign = Assign[T=DT_FLOAT, _class=["loc:@Variable_2"], use_locking=true, validate_shape=true, _device="/job:localhost/replica:0/task:0/gpu:0"](Variable_2, random_normal_2)]]

Caused by op 'Variable_2/Assign', defined at:
  File "cnn.py", line 285, in <module>
    tf.app.run()
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "cnn.py", line 277, in main
    model = Model()
  File "cnn.py", line 121, in __init__
    'wd1': tf.Variable(tf.random_normal([7*7*64*64, 1024])),
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py", line 199, in __init__
    expected_shape=expected_shape)
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py", line 320, in _init_from_args
    validate_shape=validate_shape).op
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py", line 274, in assign
    validate_shape=validate_shape)
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py", line 43, in assign
    use_locking=use_locking, name=name)
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 767, in apply_op
    op_def=op_def)
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/home1/wyk/conda/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[200704,1024]
	 [[Node: Variable_2/Assign = Assign[T=DT_FLOAT, _class=["loc:@Variable_2"], use_locking=true, validate_shape=true, _device="/job:localhost/replica:0/task:0/gpu:0"](Variable_2, random_normal_2)]]

2018-05-14 17:05:04.308285: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-14 17:05:04.308386: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-14 17:05:04.308395: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-05-14 17:05:04.308402: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-14 17:05:04.308408: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-05-14 17:05:05.178011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:82:00.0
Total memory: 10.91GiB
Free memory: 10.55GiB
2018-05-14 17:05:05.178265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2018-05-14 17:05:05.178315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2018-05-14 17:05:05.178336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0)
Initializing models
logits' shape is: Tensor("Shape_5:0", shape=(2,), dtype=int32)
Y's shape is Tensor("Shape_6:0", shape=(2,), dtype=int32)
loaded label0
loaded label1
loaded label10
loaded label11
loaded label12
loaded label13
loaded label14
loaded label15
loaded label16
loaded label17
loaded label18
loaded label19
loaded label2
loaded label20
loaded label21
loaded label22
loaded label23
loaded label24
loaded label25
loaded label26
loaded label27
loaded label28
loaded label29
loaded label3
loaded label30
loaded label31
loaded label32
loaded label33
loaded label34
loaded label35
loaded label36
loaded label37
loaded label38
loaded label39
loaded label4
loaded label40
loaded label41
loaded label42
loaded label43
loaded label44
loaded label45
loaded label46
loaded label47
loaded label48
loaded label49
loaded label5
loaded label50
loaded label51
loaded label52
loaded label53
loaded label54
loaded label55
loaded label56
loaded label57
loaded label58
loaded label59
loaded label6
loaded label60
loaded label61
loaded label62
loaded label63
loaded label64
loaded label7
loaded label8
loaded label9
loaded label0
loaded label1
loaded label10
loaded label11
loaded label12
loaded label13
loaded label14
loaded label15
loaded label16
loaded label17
loaded label18
loaded label19
loaded label2
loaded label20
loaded label21
loaded label22
loaded label23
loaded label24
loaded label25
loaded label26
loaded label27
loaded label28
loaded label29
loaded label3
loaded label30
loaded label31
loaded label32
loaded label33
loaded label34
loaded label35
loaded label36
loaded label37
loaded label38
loaded label39
loaded label4
loaded label40
loaded label41
loaded label42
loaded label43
loaded label44
loaded label45
loaded label46
loaded label47
loaded label48
loaded label49
loaded label5
loaded label50
loaded label51
loaded label52
loaded label53
loaded label54
loaded label55
loaded label56
loaded label57
loaded label58
loaded label59
loaded label6
loaded label60
loaded label61
loaded label62
loaded label63
loaded label64
loaded label7
loaded label8
loaded label9
current loss is: 1962976.8 , acc is: 0.0 , iter= 0
tot_acc= 20.0 tot_input= 768
current accuracy is: 0.026041666666666668
saved to ./checkpoints
current loss is: 4889943.5 , acc is: 0.0 , iter= 1
current loss is: 5432470.0 , acc is: 0.046875 , iter= 2
current loss is: 3733108.0 , acc is: 0.0 , iter= 3
current loss is: 2434759.8 , acc is: 0.0 , iter= 4
current loss is: 2378891.5 , acc is: 0.0 , iter= 5
current loss is: 2011837.0 , acc is: 0.015625 , iter= 6
current loss is: 1466139.5 , acc is: 0.015625 , iter= 7
current loss is: 884159.9 , acc is: 0.0 , iter= 8
current loss is: 617091.3 , acc is: 0.03125 , iter= 9
current loss is: 382326.62 , acc is: 0.015625 , iter= 10
current loss is: 354992.03 , acc is: 0.0 , iter= 11
current loss is: 232402.69 , acc is: 0.015625 , iter= 12
current loss is: 121585.01 , acc is: 0.0 , iter= 13
current loss is: 75444.93 , acc is: 0.03125 , iter= 14
current loss is: 53956.72 , acc is: 0.015625 , iter= 15
current loss is: 38458.547 , acc is: 0.03125 , iter= 16
current loss is: 39817.527 , acc is: 0.03125 , iter= 17
current loss is: 32518.533 , acc is: 0.015625 , iter= 18
current loss is: 23502.674 , acc is: 0.03125 , iter= 19
current loss is: 20334.684 , acc is: 0.015625 , iter= 20
current loss is: 17623.45 , acc is: 0.015625 , iter= 21
current loss is: 14532.965 , acc is: 0.015625 , iter= 22
current loss is: 12399.919 , acc is: 0.03125 , iter= 23
current loss is: 9661.408 , acc is: 0.0625 , iter= 24
current loss is: 8746.531 , acc is: 0.03125 , iter= 25
current loss is: 7356.5527 , acc is: 0.03125 , iter= 26
current loss is: 6778.1704 , acc is: 0.03125 , iter= 27
current loss is: 7194.655 , acc is: 0.03125 , iter= 28
current loss is: 6496.549 , acc is: 0.0625 , iter= 29
current loss is: 4391.6094 , acc is: 0.046875 , iter= 30
current loss is: 5015.0415 , acc is: 0.015625 , iter= 31
current loss is: 4426.5615 , acc is: 0.03125 , iter= 32
current loss is: 4263.592 , acc is: 0.015625 , iter= 33
current loss is: 3158.937 , acc is: 0.0 , iter= 34
current loss is: 3657.6973 , acc is: 0.046875 , iter= 35
current loss is: 3396.2126 , acc is: 0.0 , iter= 36
current loss is: 2950.2603 , acc is: 0.015625 , iter= 37
current loss is: 2944.0625 , acc is: 0.03125 , iter= 38
current loss is: 2857.3555 , acc is: 0.0 , iter= 39
current loss is: 1794.5806 , acc is: 0.0 , iter= 40
current loss is: 2727.9326 , acc is: 0.015625 , iter= 41
current loss is: 2374.7144 , acc is: 0.015625 , iter= 42
current loss is: 2318.9375 , acc is: 0.046875 , iter= 43
current loss is: 2063.347 , acc is: 0.046875 , iter= 44
current loss is: 1507.7308 , acc is: 0.03125 , iter= 45
current loss is: 2258.4917 , acc is: 0.015625 , iter= 46
current loss is: 1289.2819 , acc is: 0.03125 , iter= 47
current loss is: 1611.5886 , acc is: 0.046875 , iter= 48
current loss is: 1582.4823 , acc is: 0.0 , iter= 49
current loss is: 1195.6372 , acc is: 0.046875 , iter= 50
current loss is: 1278.3164 , acc is: 0.015625 , iter= 51
current loss is: 970.82153 , acc is: 0.015625 , iter= 52
current loss is: 1456.443 , acc is: 0.0 , iter= 53
current loss is: 895.9557 , acc is: 0.0 , iter= 54
current loss is: 1203.9979 , acc is: 0.046875 , iter= 55
current loss is: 754.247 , acc is: 0.015625 , iter= 56
current loss is: 815.9634 , acc is: 0.015625 , iter= 57
current loss is: 723.67865 , acc is: 0.0 , iter= 58
current loss is: 817.24365 , acc is: 0.015625 , iter= 59
current loss is: 801.1664 , acc is: 0.0 , iter= 60
current loss is: 764.755 , acc is: 0.015625 , iter= 61
current loss is: 885.75214 , acc is: 0.0 , iter= 62
current loss is: 483.4698 , acc is: 0.046875 , iter= 63
current loss is: 425.15393 , acc is: 0.03125 , iter= 64
current loss is: 529.5283 , acc is: 0.0 , iter= 65
current loss is: 362.9371 , acc is: 0.03125 , iter= 66
current loss is: 887.37427 , acc is: 0.0 , iter= 67
current loss is: 656.6034 , acc is: 0.03125 , iter= 68
current loss is: 637.35974 , acc is: 0.03125 , iter= 69
current loss is: 555.67377 , acc is: 0.015625 , iter= 70
current loss is: 618.4082 , acc is: 0.015625 , iter= 71
current loss is: 516.8911 , acc is: 0.0 , iter= 72
current loss is: 517.93207 , acc is: 0.046875 , iter= 73
current loss is: 508.11078 , acc is: 0.03125 , iter= 74
current loss is: 497.90576 , acc is: 0.046875 , iter= 75
current loss is: 468.56653 , acc is: 0.046875 , iter= 76
current loss is: 608.49133 , acc is: 0.015625 , iter= 77
current loss is: 597.96155 , acc is: 0.046875 , iter= 78
current loss is: 826.05896 , acc is: 0.03125 , iter= 79
current loss is: 463.76215 , acc is: 0.015625 , iter= 80
current loss is: 601.13995 , acc is: 0.03125 , iter= 81
current loss is: 454.12152 , acc is: 0.015625 , iter= 82
current loss is: 409.8825 , acc is: 0.03125 , iter= 83
current loss is: 291.7025 , acc is: 0.03125 , iter= 84
current loss is: 595.9147 , acc is: 0.015625 , iter= 85
current loss is: 471.05658 , acc is: 0.015625 , iter= 86
current loss is: 422.59558 , acc is: 0.0 , iter= 87
current loss is: 434.08145 , acc is: 0.046875 , iter= 88
current loss is: 469.3205 , acc is: 0.046875 , iter= 89
current loss is: 327.91846 , acc is: 0.0 , iter= 90
current loss is: 502.90106 , acc is: 0.015625 , iter= 91
current loss is: 377.74292 , acc is: 0.0 , iter= 92
current loss is: 430.33926 , acc is: 0.015625 , iter= 93
current loss is: 585.8679 , acc is: 0.0 , iter= 94
current loss is: 323.90656 , acc is: 0.015625 , iter= 95
current loss is: 667.39465 , acc is: 0.0 , iter= 96
current loss is: 297.51212 , acc is: 0.015625 , iter= 97
current loss is: 317.4725 , acc is: 0.0625 , iter= 98
current loss is: 417.65546 , acc is: 0.0 , iter= 99
current loss is: 433.46228 , acc is: 0.0625 , iter= 100
current loss is: 319.5871 , acc is: 0.03125 , iter= 101
current loss is: 264.28174 , acc is: 0.046875 , iter= 102
current loss is: 272.7774 , acc is: 0.03125 , iter= 103
current loss is: 293.93875 , acc is: 0.015625 , iter= 104
current loss is: 358.89508 , acc is: 0.03125 , iter= 105
current loss is: 247.85501 , acc is: 0.0 , iter= 106
current loss is: 272.27075 , acc is: 0.015625 , iter= 107
current loss is: 337.87732 , acc is: 0.015625 , iter= 108
current loss is: 218.63748 , acc is: 0.03125 , iter= 109
current loss is: 327.06778 , acc is: 0.03125 , iter= 110
current loss is: 251.02203 , acc is: 0.0625 , iter= 111
current loss is: 293.00128 , acc is: 0.0 , iter= 112
current loss is: 304.91663 , acc is: 0.015625 , iter= 113
current loss is: 265.0351 , acc is: 0.03125 , iter= 114
current loss is: 365.51288 , acc is: 0.03125 , iter= 115
current loss is: 297.4047 , acc is: 0.0625 , iter= 116
current loss is: 222.01907 , acc is: 0.0 , iter= 117
current loss is: 406.1538 , acc is: 0.0 , iter= 118
current loss is: 209.97998 , acc is: 0.03125 , iter= 119
current loss is: 312.7176 , acc is: 0.015625 , iter= 120
current loss is: 220.84161 , acc is: 0.0 , iter= 121
current loss is: 174.76068 , acc is: 0.015625 , iter= 122
current loss is: 224.98718 , acc is: 0.0 , iter= 123
current loss is: 134.7226 , acc is: 0.015625 , iter= 124
current loss is: 249.56604 , acc is: 0.0 , iter= 125
current loss is: 144.27338 , acc is: 0.0625 , iter= 126
current loss is: 258.9927 , acc is: 0.015625 , iter= 127
current loss is: 255.78189 , acc is: 0.0 , iter= 128
current loss is: 222.33398 , acc is: 0.0 , iter= 129
current loss is: 194.76515 , acc is: 0.015625 , iter= 130
current loss is: 211.01834 , acc is: 0.03125 , iter= 131
current loss is: 173.59344 , acc is: 0.0 , iter= 132
current loss is: 227.33911 , acc is: 0.03125 , iter= 133
current loss is: 220.25388 , acc is: 0.015625 , iter= 134
current loss is: 175.57343 , acc is: 0.03125 , iter= 135
current loss is: 146.28664 , acc is: 0.03125 , iter= 136
current loss is: 233.74736 , acc is: 0.03125 , iter= 137
current loss is: 285.8556 , acc is: 0.09375 , iter= 138
current loss is: 396.5614 , acc is: 0.0 , iter= 139
current loss is: 255.66219 , acc is: 0.046875 , iter= 140
current loss is: 210.24167 , acc is: 0.0 , iter= 141
current loss is: 367.22263 , acc is: 0.015625 , iter= 142
current loss is: 248.17395 , acc is: 0.0 , iter= 143
current loss is: 188.38242 , acc is: 0.015625 , iter= 144
current loss is: 169.06836 , acc is: 0.0 , iter= 145
current loss is: 138.02278 , acc is: 0.0625 , iter= 146
current loss is: 265.60223 , acc is: 0.0625 , iter= 147
current loss is: 96.54668 , acc is: 0.0625 , iter= 148
current loss is: 233.69556 , acc is: 0.0 , iter= 149
current loss is: 168.10605 , acc is: 0.015625 , iter= 150
current loss is: 328.25708 , acc is: 0.015625 , iter= 151
current loss is: 188.88892 , acc is: 0.015625 , iter= 152
current loss is: 145.27277 , acc is: 0.015625 , iter= 153
current loss is: 111.16255 , acc is: 0.046875 , iter= 154
current loss is: 135.4512 , acc is: 0.0 , iter= 155
current loss is: 150.56183 , acc is: 0.03125 , iter= 156
current loss is: 164.87123 , acc is: 0.015625 , iter= 157
current loss is: 142.63348 , acc is: 0.015625 , iter= 158
current loss is: 173.53201 , acc is: 0.015625 , iter= 159
current loss is: 195.11542 , acc is: 0.015625 , iter= 160
current loss is: 88.40819 , acc is: 0.03125 , iter= 161
current loss is: 98.82352 , acc is: 0.03125 , iter= 162
current loss is: 115.725 , acc is: 0.046875 , iter= 163
current loss is: 100.285095 , acc is: 0.078125 , iter= 164
current loss is: 127.43915 , acc is: 0.03125 , iter= 165
current loss is: 123.20947 , acc is: 0.09375 , iter= 166
current loss is: 130.02235 , acc is: 0.0 , iter= 167
current loss is: 144.14804 , acc is: 0.015625 , iter= 168
current loss is: 134.003 , acc is: 0.015625 , iter= 169
current loss is: 134.44226 , acc is: 0.03125 , iter= 170
current loss is: 115.79597 , acc is: 0.03125 , iter= 171
current loss is: 77.5885 , acc is: 0.015625 , iter= 172
current loss is: 135.23863 , acc is: 0.03125 , iter= 173
current loss is: 124.49273 , acc is: 0.015625 , iter= 174
current loss is: 152.53223 , acc is: 0.046875 , iter= 175
current loss is: 181.28279 , acc is: 0.03125 , iter= 176
current loss is: 90.08891 , acc is: 0.046875 , iter= 177
current loss is: 142.67157 , acc is: 0.0 , iter= 178
current loss is: 112.53673 , acc is: 0.015625 , iter= 179
current loss is: 160.18286 , acc is: 0.03125 , iter= 180
current loss is: 134.87038 , acc is: 0.046875 , iter= 181
current loss is: 237.80295 , acc is: 0.03125 , iter= 182
current loss is: 67.7305 , acc is: 0.0 , iter= 183
current loss is: 126.03891 , acc is: 0.03125 , iter= 184
current loss is: 142.45522 , acc is: 0.03125 , iter= 185
current loss is: 78.56256 , acc is: 0.03125 , iter= 186
current loss is: 92.69165 , acc is: 0.046875 , iter= 187
current loss is: 113.64769 , acc is: 0.0625 , iter= 188
current loss is: 109.42898 , acc is: 0.0 , iter= 189
current loss is: 104.19976 , acc is: 0.015625 , iter= 190
current loss is: 87.70042 , acc is: 0.015625 , iter= 191
current loss is: 111.27694 , acc is: 0.046875 , iter= 192
current loss is: 87.59013 , acc is: 0.03125 , iter= 193
current loss is: 105.96489 , acc is: 0.015625 , iter= 194
current loss is: 171.8007 , acc is: 0.03125 , iter= 195
current loss is: 130.52458 , acc is: 0.0 , iter= 196
current loss is: 99.995575 , acc is: 0.015625 , iter= 197
current loss is: 139.02768 , acc is: 0.03125 , iter= 198
current loss is: 125.696686 , acc is: 0.03125 , iter= 199
current loss is: 103.66257 , acc is: 0.015625 , iter= 200
current loss is: 100.384094 , acc is: 0.0625 , iter= 201
current loss is: 83.62437 , acc is: 0.03125 , iter= 202
current loss is: 101.87118 , acc is: 0.078125 , iter= 203
current loss is: 112.595055 , acc is: 0.015625 , iter= 204
current loss is: 67.8404 , acc is: 0.0 , iter= 205
current loss is: 108.36079 , acc is: 0.015625 , iter= 206
current loss is: 68.982376 , acc is: 0.03125 , iter= 207
current loss is: 82.84529 , acc is: 0.03125 , iter= 208
current loss is: 93.12906 , acc is: 0.046875 , iter= 209
current loss is: 72.865036 , acc is: 0.015625 , iter= 210
current loss is: 92.876144 , acc is: 0.0 , iter= 211
current loss is: 84.74142 , acc is: 0.03125 , iter= 212
current loss is: 133.65274 , acc is: 0.03125 , iter= 213
current loss is: 71.14964 , acc is: 0.046875 , iter= 214
current loss is: 47.060555 , acc is: 0.03125 , iter= 215
current loss is: 153.91142 , acc is: 0.015625 , iter= 216
current loss is: 92.58606 , acc is: 0.03125 , iter= 217
current loss is: 72.368935 , acc is: 0.015625 , iter= 218
current loss is: 81.218056 , acc is: 0.015625 , iter= 219
current loss is: 71.92134 , acc is: 0.03125 , iter= 220
current loss is: 72.82434 , acc is: 0.015625 , iter= 221
current loss is: 136.30875 , acc is: 0.0 , iter= 222
current loss is: 139.14679 , acc is: 0.015625 , iter= 223
current loss is: 42.640587 , acc is: 0.03125 , iter= 224
current loss is: 64.16811 , acc is: 0.03125 , iter= 225
current loss is: 60.40391 , acc is: 0.09375 , iter= 226
current loss is: 100.46095 , acc is: 0.015625 , iter= 227
current loss is: 57.219337 , acc is: 0.0625 , iter= 228
current loss is: 41.34671 , acc is: 0.046875 , iter= 229
current loss is: 102.00526 , acc is: 0.015625 , iter= 230
current loss is: 46.124664 , acc is: 0.046875 , iter= 231
current loss is: 113.66591 , acc is: 0.015625 , iter= 232
current loss is: 48.526936 , acc is: 0.03125 , iter= 233
current loss is: 111.518295 , acc is: 0.015625 , iter= 234
current loss is: 115.62802 , acc is: 0.046875 , iter= 235
current loss is: 40.694218 , acc is: 0.046875 , iter= 236
current loss is: 67.532814 , acc is: 0.046875 , iter= 237
current loss is: 129.87463 , acc is: 0.046875 , iter= 238
current loss is: 63.297424 , acc is: 0.046875 , iter= 239
current loss is: 93.32489 , acc is: 0.046875 , iter= 240
current loss is: 54.088623 , acc is: 0.09375 , iter= 241
current loss is: 73.75719 , acc is: 0.03125 , iter= 242
current loss is: 105.02924 , acc is: 0.0 , iter= 243
current loss is: 59.33359 , acc is: 0.03125 , iter= 244
current loss is: 47.208218 , acc is: 0.0 , iter= 245
current loss is: 40.417553 , acc is: 0.03125 , iter= 246
current loss is: 70.29944 , acc is: 0.015625 , iter= 247
current loss is: 103.23889 , acc is: 0.03125 , iter= 248
current loss is: 86.57808 , acc is: 0.0 , iter= 249
current loss is: 66.23763 , acc is: 0.0 , iter= 250
current loss is: 71.542816 , acc is: 0.015625 , iter= 251
current loss is: 38.637985 , acc is: 0.03125 , iter= 252
current loss is: 46.624672 , acc is: 0.078125 , iter= 253
current loss is: 58.97351 , acc is: 0.09375 , iter= 254
current loss is: 52.17032 , acc is: 0.046875 , iter= 255
current loss is: 64.26683 , acc is: 0.03125 , iter= 256
current loss is: 53.847977 , acc is: 0.03125 , iter= 257
current loss is: 41.678623 , acc is: 0.015625 , iter= 258
current loss is: 32.764896 , acc is: 0.046875 , iter= 259
current loss is: 53.882996 , acc is: 0.0625 , iter= 260
current loss is: 59.686325 , acc is: 0.03125 , iter= 261
current loss is: 38.952583 , acc is: 0.03125 , iter= 262
current loss is: 60.10998 , acc is: 0.015625 , iter= 263
current loss is: 31.180914 , acc is: 0.03125 , iter= 264
current loss is: 61.856445 , acc is: 0.0625 , iter= 265
current loss is: 95.15202 , acc is: 0.03125 , iter= 266
current loss is: 34.115852 , acc is: 0.046875 , iter= 267
current loss is: 114.275635 , acc is: 0.0625 , iter= 268
current loss is: 46.783295 , acc is: 0.015625 , iter= 269
current loss is: 24.632362 , acc is: 0.078125 , iter= 270
current loss is: 43.030487 , acc is: 0.015625 , iter= 271
current loss is: 27.413042 , acc is: 0.0625 , iter= 272
current loss is: 35.567566 , acc is: 0.015625 , iter= 273
current loss is: 68.53324 , acc is: 0.03125 , iter= 274
current loss is: 33.59746 , acc is: 0.03125 , iter= 275
current loss is: 41.46401 , acc is: 0.03125 , iter= 276
current loss is: 49.819107 , acc is: 0.015625 , iter= 277
current loss is: 82.93213 , acc is: 0.015625 , iter= 278
current loss is: 72.15634 , acc is: 0.0 , iter= 279
current loss is: 37.2269 , acc is: 0.046875 , iter= 280
current loss is: 53.115185 , acc is: 0.015625 , iter= 281
current loss is: 40.088844 , acc is: 0.046875 , iter= 282
current loss is: 44.4034 , acc is: 0.046875 , iter= 283
current loss is: 51.647804 , acc is: 0.046875 , iter= 284
current loss is: 25.72957 , acc is: 0.046875 , iter= 285
current loss is: 30.693718 , acc is: 0.03125 , iter= 286
current loss is: 35.235836 , acc is: 0.0625 , iter= 287
current loss is: 38.62421 , acc is: 0.078125 , iter= 288
current loss is: 32.50428 , acc is: 0.03125 , iter= 289
current loss is: 18.957909 , acc is: 0.03125 , iter= 290
current loss is: 59.7624 , acc is: 0.03125 , iter= 291
current loss is: 30.137712 , acc is: 0.03125 , iter= 292
current loss is: 36.315563 , acc is: 0.03125 , iter= 293
current loss is: 50.957573 , acc is: 0.015625 , iter= 294
current loss is: 44.87805 , acc is: 0.0 , iter= 295
current loss is: 42.694336 , acc is: 0.015625 , iter= 296
current loss is: 43.04828 , acc is: 0.0 , iter= 297
current loss is: 65.987625 , acc is: 0.0625 , iter= 298
current loss is: 37.408607 , acc is: 0.015625 , iter= 299
current loss is: 38.674015 , acc is: 0.015625 , iter= 300
current loss is: 39.790695 , acc is: 0.015625 , iter= 301
current loss is: 16.682215 , acc is: 0.046875 , iter= 302
current loss is: 37.58107 , acc is: 0.015625 , iter= 303
current loss is: 44.738403 , acc is: 0.0625 , iter= 304
current loss is: 44.393097 , acc is: 0.03125 , iter= 305
current loss is: 19.2607 , acc is: 0.0625 , iter= 306
current loss is: 33.931847 , acc is: 0.015625 , iter= 307
current loss is: 31.26721 , acc is: 0.140625 , iter= 308
current loss is: 33.355026 , acc is: 0.0625 , iter= 309
current loss is: 28.571178 , acc is: 0.046875 , iter= 310
current loss is: 45.223534 , acc is: 0.015625 , iter= 311
current loss is: 39.491524 , acc is: 0.046875 , iter= 312
current loss is: 22.416023 , acc is: 0.03125 , iter= 313
current loss is: 21.560856 , acc is: 0.03125 , iter= 314
current loss is: 63.939552 , acc is: 0.015625 , iter= 315
current loss is: 50.76992 , acc is: 0.015625 , iter= 316
current loss is: 29.247335 , acc is: 0.03125 , iter= 317
current loss is: 28.43082 , acc is: 0.046875 , iter= 318
current loss is: 42.33527 , acc is: 0.03125 , iter= 319
current loss is: 30.907112 , acc is: 0.0625 , iter= 320
current loss is: 23.370985 , acc is: 0.015625 , iter= 321
current loss is: 35.650444 , acc is: 0.046875 , iter= 322
current loss is: 41.073715 , acc is: 0.015625 , iter= 323
current loss is: 45.253815 , acc is: 0.0 , iter= 324
current loss is: 23.481314 , acc is: 0.03125 , iter= 325
current loss is: 47.05107 , acc is: 0.03125 , iter= 326
current loss is: 40.785652 , acc is: 0.046875 , iter= 327
current loss is: 33.77514 , acc is: 0.046875 , iter= 328
current loss is: 30.257793 , acc is: 0.015625 , iter= 329
current loss is: 22.504532 , acc is: 0.03125 , iter= 330
current loss is: 25.345257 , acc is: 0.0 , iter= 331
current loss is: 34.377583 , acc is: 0.015625 , iter= 332
current loss is: 33.999825 , acc is: 0.03125 , iter= 333
current loss is: 13.925116 , acc is: 0.0625 , iter= 334
current loss is: 24.71114 , acc is: 0.0625 , iter= 335
current loss is: 34.656746 , acc is: 0.078125 , iter= 336
current loss is: 24.417652 , acc is: 0.015625 , iter= 337
current loss is: 10.314754 , acc is: 0.09375 , iter= 338
current loss is: 26.80232 , acc is: 0.015625 , iter= 339
current loss is: 21.087421 , acc is: 0.03125 , iter= 340
current loss is: 33.695908 , acc is: 0.03125 , iter= 341
current loss is: 20.077864 , acc is: 0.0625 , iter= 342
current loss is: 37.380432 , acc is: 0.03125 , iter= 343
current loss is: 17.485361 , acc is: 0.09375 , iter= 344
current loss is: 18.576263 , acc is: 0.046875 , iter= 345
current loss is: 43.975723 , acc is: 0.046875 , iter= 346
current loss is: 22.230812 , acc is: 0.03125 , iter= 347
current loss is: 29.665941 , acc is: 0.046875 , iter= 348
current loss is: 23.219437 , acc is: 0.046875 , iter= 349
current loss is: 18.52422 , acc is: 0.09375 , iter= 350
current loss is: 34.970055 , acc is: 0.0625 , iter= 351
current loss is: 21.032738 , acc is: 0.015625 , iter= 352
current loss is: 35.053295 , acc is: 0.0 , iter= 353
current loss is: 50.041565 , acc is: 0.078125 , iter= 354
current loss is: 11.590891 , acc is: 0.015625 , iter= 355
current loss is: 21.463966 , acc is: 0.03125 , iter= 356
current loss is: 25.291328 , acc is: 0.046875 , iter= 357
current loss is: 17.8314 , acc is: 0.03125 , iter= 358
current loss is: 21.299053 , acc is: 0.0625 , iter= 359
current loss is: 23.48421 , acc is: 0.0625 , iter= 360
current loss is: 22.383888 , acc is: 0.03125 , iter= 361
current loss is: 19.32215 , acc is: 0.015625 , iter= 362
current loss is: 16.118385 , acc is: 0.078125 , iter= 363
current loss is: 36.22972 , acc is: 0.046875 , iter= 364
current loss is: 21.494701 , acc is: 0.015625 , iter= 365
current loss is: 22.493519 , acc is: 0.015625 , iter= 366
current loss is: 13.177222 , acc is: 0.015625 , iter= 367
current loss is: 13.690445 , acc is: 0.015625 , iter= 368
current loss is: 14.08835 , acc is: 0.03125 , iter= 369
current loss is: 17.370426 , acc is: 0.0 , iter= 370
current loss is: 18.99172 , acc is: 0.046875 , iter= 371
current loss is: 22.5086 , acc is: 0.046875 , iter= 372
current loss is: 25.755968 , acc is: 0.0625 , iter= 373
current loss is: 22.297077 , acc is: 0.046875 , iter= 374
current loss is: 21.970724 , acc is: 0.015625 , iter= 375
current loss is: 23.298798 , acc is: 0.046875 , iter= 376
current loss is: 17.996395 , acc is: 0.03125 , iter= 377
current loss is: 9.239966 , acc is: 0.046875 , iter= 378
current loss is: 15.986908 , acc is: 0.0625 , iter= 379
current loss is: 10.769564 , acc is: 0.0 , iter= 380
current loss is: 24.246422 , acc is: 0.046875 , iter= 381
current loss is: 11.526474 , acc is: 0.046875 , iter= 382
current loss is: 15.710945 , acc is: 0.0 , iter= 383
current loss is: 29.65651 , acc is: 0.0625 , iter= 384
current loss is: 10.871807 , acc is: 0.015625 , iter= 385
current loss is: 15.556736 , acc is: 0.046875 , iter= 386
current loss is: 21.2989 , acc is: 0.046875 , iter= 387
current loss is: 26.32995 , acc is: 0.03125 , iter= 388
current loss is: 12.549513 , acc is: 0.0625 , iter= 389
current loss is: 9.224907 , acc is: 0.046875 , iter= 390
current loss is: 9.103659 , acc is: 0.03125 , iter= 391
current loss is: 38.969696 , acc is: 0.0625 , iter= 392
current loss is: 15.615706 , acc is: 0.046875 , iter= 393
current loss is: 26.020508 , acc is: 0.046875 , iter= 394
current loss is: 24.83142 , acc is: 0.0 , iter= 395
current loss is: 14.756929 , acc is: 0.03125 , iter= 396
current loss is: 9.4354315 , acc is: 0.03125 , iter= 397
current loss is: 11.331705 , acc is: 0.015625 , iter= 398
current loss is: 22.196007 , acc is: 0.078125 , iter= 399
current loss is: 8.688961 , acc is: 0.03125 , iter= 400
current loss is: 11.814997 , acc is: 0.046875 , iter= 401
current loss is: 10.678047 , acc is: 0.09375 , iter= 402
current loss is: 27.16099 , acc is: 0.03125 , iter= 403
current loss is: 11.313261 , acc is: 0.03125 , iter= 404
current loss is: 21.873997 , acc is: 0.03125 , iter= 405
current loss is: 11.459156 , acc is: 0.109375 , iter= 406
current loss is: 8.1816435 , acc is: 0.0 , iter= 407
current loss is: 23.852303 , acc is: 0.03125 , iter= 408
current loss is: 10.336501 , acc is: 0.046875 , iter= 409
current loss is: 6.259674 , acc is: 0.0625 , iter= 410
current loss is: 8.097223 , acc is: 0.0 , iter= 411
current loss is: 37.2126 , acc is: 0.0 , iter= 412
current loss is: 10.554694 , acc is: 0.015625 , iter= 413
current loss is: 7.8820567 , acc is: 0.03125 , iter= 414
current loss is: 7.73081 , acc is: 0.03125 , iter= 415
current loss is: 7.4008684 , acc is: 0.03125 , iter= 416
current loss is: 11.307812 , acc is: 0.046875 , iter= 417
current loss is: 12.349321 , acc is: 0.03125 , iter= 418
current loss is: 16.670975 , acc is: 0.0625 , iter= 419
current loss is: 8.619882 , acc is: 0.015625 , iter= 420
current loss is: 12.958204 , acc is: 0.03125 , iter= 421
current loss is: 7.199338 , acc is: 0.0625 , iter= 422
current loss is: 6.5275407 , acc is: 0.015625 , iter= 423
current loss is: 9.094248 , acc is: 0.09375 , iter= 424
current loss is: 9.0027895 , acc is: 0.03125 , iter= 425
current loss is: 44.13042 , acc is: 0.03125 , iter= 426
current loss is: 6.131328 , acc is: 0.03125 , iter= 427
current loss is: 5.7199144 , acc is: 0.046875 , iter= 428
current loss is: 9.293282 , acc is: 0.03125 , iter= 429
current loss is: 14.371393 , acc is: 0.0625 , iter= 430
current loss is: 5.7902393 , acc is: 0.046875 , iter= 431
current loss is: 20.98038 , acc is: 0.015625 , iter= 432
current loss is: 11.652533 , acc is: 0.078125 , iter= 433
current loss is: 20.922382 , acc is: 0.046875 , iter= 434
current loss is: 7.9862967 , acc is: 0.015625 , iter= 435
current loss is: 5.8611946 , acc is: 0.03125 , iter= 436
current loss is: 18.112263 , acc is: 0.03125 , iter= 437
current loss is: 15.175133 , acc is: 0.0625 , iter= 438
current loss is: 11.750504 , acc is: 0.0625 , iter= 439
current loss is: 9.33796 , acc is: 0.046875 , iter= 440
current loss is: 10.637718 , acc is: 0.046875 , iter= 441
current loss is: 11.0251255 , acc is: 0.046875 , iter= 442
current loss is: 7.101229 , acc is: 0.0625 , iter= 443
current loss is: 19.668152 , acc is: 0.046875 , iter= 444
current loss is: 14.32708 , acc is: 0.046875 , iter= 445
current loss is: 12.890996 , acc is: 0.046875 , iter= 446
current loss is: 11.314344 , acc is: 0.015625 , iter= 447
current loss is: 13.476502 , acc is: 0.0 , iter= 448
current loss is: 10.089124 , acc is: 0.0 , iter= 449
current loss is: 5.1787043 , acc is: 0.046875 , iter= 450
current loss is: 11.093906 , acc is: 0.0 , iter= 451
current loss is: 12.765332 , acc is: 0.046875 , iter= 452
current loss is: 6.477723 , acc is: 0.0 , iter= 453
current loss is: 14.287502 , acc is: 0.015625 , iter= 454
current loss is: 7.519784 , acc is: 0.03125 , iter= 455
current loss is: 17.995909 , acc is: 0.03125 , iter= 456
current loss is: 12.806349 , acc is: 0.078125 , iter= 457
current loss is: 7.8876724 , acc is: 0.046875 , iter= 458
current loss is: 5.5966225 , acc is: 0.03125 , iter= 459
current loss is: 13.7010145 , acc is: 0.046875 , iter= 460
current loss is: 10.972713 , acc is: 0.0 , iter= 461
current loss is: 17.424976 , acc is: 0.0 , iter= 462
current loss is: 5.548316 , acc is: 0.046875 , iter= 463
current loss is: 6.810736 , acc is: 0.109375 , iter= 464
current loss is: 7.2825775 , acc is: 0.109375 , iter= 465
current loss is: 8.682737 , acc is: 0.046875 , iter= 466
current loss is: 7.466943 , acc is: 0.015625 , iter= 467
current loss is: 5.5492687 , acc is: 0.078125 , iter= 468
current loss is: 10.086717 , acc is: 0.015625 , iter= 469
current loss is: 6.7100964 , acc is: 0.015625 , iter= 470
current loss is: 10.122789 , acc is: 0.03125 , iter= 471
current loss is: 11.816746 , acc is: 0.03125 , iter= 472
current loss is: 6.72739 , acc is: 0.03125 , iter= 473
current loss is: 5.854873 , acc is: 0.03125 , iter= 474
current loss is: 17.127525 , acc is: 0.015625 , iter= 475
current loss is: 7.208639 , acc is: 0.0625 , iter= 476
current loss is: 6.804263 , acc is: 0.015625 , iter= 477
current loss is: 19.579454 , acc is: 0.078125 , iter= 478
current loss is: 13.114109 , acc is: 0.015625 , iter= 479
current loss is: 11.275604 , acc is: 0.0 , iter= 480
current loss is: 14.613899 , acc is: 0.046875 , iter= 481
current loss is: 7.660351 , acc is: 0.015625 , iter= 482
current loss is: 7.7000237 , acc is: 0.046875 , iter= 483
current loss is: 4.947941 , acc is: 0.078125 , iter= 484
current loss is: 8.520828 , acc is: 0.03125 , iter= 485
current loss is: 4.5457087 , acc is: 0.0625 , iter= 486
current loss is: 5.382209 , acc is: 0.046875 , iter= 487
current loss is: 7.1138034 , acc is: 0.046875 , iter= 488
current loss is: 9.897528 , acc is: 0.046875 , iter= 489
current loss is: 4.927715 , acc is: 0.03125 , iter= 490
current loss is: 8.23366 , acc is: 0.03125 , iter= 491
current loss is: 16.146585 , acc is: 0.03125 , iter= 492
current loss is: 4.442959 , acc is: 0.078125 , iter= 493
current loss is: 6.4087234 , acc is: 0.03125 , iter= 494
current loss is: 18.096785 , acc is: 0.03125 , iter= 495
current loss is: 10.734448 , acc is: 0.03125 , iter= 496
current loss is: 15.899484 , acc is: 0.0625 , iter= 497
current loss is: 10.734573 , acc is: 0.03125 , iter= 498
current loss is: 4.57353 , acc is: 0.0 , iter= 499
current loss is: 5.3412824 , acc is: 0.046875 , iter= 500
current loss is: 15.747482 , acc is: 0.03125 , iter= 501
current loss is: 9.309217 , acc is: 0.03125 , iter= 502
current loss is: 5.0034933 , acc is: 0.078125 , iter= 503
current loss is: 6.927747 , acc is: 0.078125 , iter= 504
current loss is: 7.1601477 , acc is: 0.09375 , iter= 505
current loss is: 5.0670853 , acc is: 0.015625 , iter= 506
current loss is: 7.3733816 , acc is: 0.0625 , iter= 507
current loss is: 20.572704 , acc is: 0.0 , iter= 508
current loss is: 6.376466 , acc is: 0.03125 , iter= 509
current loss is: 6.739382 , acc is: 0.046875 , iter= 510
current loss is: 9.993722 , acc is: 0.015625 , iter= 511
current loss is: 6.576236 , acc is: 0.0625 , iter= 512
current loss is: 4.4045978 , acc is: 0.0 , iter= 513
current loss is: 4.905619 , acc is: 0.03125 , iter= 514
current loss is: 17.196003 , acc is: 0.03125 , iter= 515
current loss is: 6.158563 , acc is: 0.03125 , iter= 516
current loss is: 7.186807 , acc is: 0.0625 , iter= 517
current loss is: 6.694472 , acc is: 0.0625 , iter= 518
current loss is: 6.5449734 , acc is: 0.078125 , iter= 519
current loss is: 10.919424 , acc is: 0.015625 , iter= 520
current loss is: 4.9003925 , acc is: 0.046875 , iter= 521
current loss is: 4.757681 , acc is: 0.03125 , iter= 522
current loss is: 4.844328 , acc is: 0.09375 , iter= 523
current loss is: 10.189781 , acc is: 0.03125 , iter= 524
current loss is: 6.138153 , acc is: 0.0 , iter= 525
current loss is: 10.083036 , acc is: 0.03125 , iter= 526
current loss is: 6.162812 , acc is: 0.046875 , iter= 527
current loss is: 4.271944 , acc is: 0.109375 , iter= 528
current loss is: 5.05435 , acc is: 0.078125 , iter= 529
current loss is: 8.589271 , acc is: 0.03125 , iter= 530
current loss is: 5.7949624 , acc is: 0.03125 , iter= 531
current loss is: 10.2238865 , acc is: 0.015625 , iter= 532
current loss is: 10.7920065 , acc is: 0.046875 , iter= 533
current loss is: 13.844273 , acc is: 0.0625 , iter= 534
current loss is: 4.448664 , acc is: 0.09375 , iter= 535
current loss is: 4.30582 , acc is: 0.03125 , iter= 536
current loss is: 6.2587028 , acc is: 0.03125 , iter= 537
current loss is: 6.5944123 , acc is: 0.046875 , iter= 538
current loss is: 7.250926 , acc is: 0.0625 , iter= 539
current loss is: 11.894454 , acc is: 0.0 , iter= 540
current loss is: 4.0949907 , acc is: 0.015625 , iter= 541
current loss is: 4.6840353 , acc is: 0.078125 , iter= 542
current loss is: 7.8203716 , acc is: 0.0625 , iter= 543
current loss is: 5.946026 , acc is: 0.03125 , iter= 544
current loss is: 9.351502 , acc is: 0.03125 , iter= 545
current loss is: 4.2184772 , acc is: 0.0625 , iter= 546
current loss is: 18.70485 , acc is: 0.015625 , iter= 547
current loss is: 11.7070875 , acc is: 0.0 , iter= 548
current loss is: 14.802976 , acc is: 0.0 , iter= 549
current loss is: 8.852261 , acc is: 0.0625 , iter= 550
current loss is: 4.141569 , acc is: 0.03125 , iter= 551
current loss is: 5.8713236 , acc is: 0.03125 , iter= 552
current loss is: 6.777874 , acc is: 0.046875 , iter= 553
current loss is: 5.5524864 , acc is: 0.0625 , iter= 554
current loss is: 7.9167647 , acc is: 0.046875 , iter= 555
current loss is: 4.763096 , acc is: 0.078125 , iter= 556
current loss is: 6.2521267 , acc is: 0.078125 , iter= 557
current loss is: 10.82047 , acc is: 0.0625 , iter= 558
current loss is: 4.1707296 , acc is: 0.03125 , iter= 559
current loss is: 4.3592973 , acc is: 0.140625 , iter= 560
current loss is: 4.2129993 , acc is: 0.03125 , iter= 561
current loss is: 7.8318825 , acc is: 0.046875 , iter= 562
current loss is: 15.178584 , acc is: 0.03125 , iter= 563
current loss is: 4.4510784 , acc is: 0.03125 , iter= 564
current loss is: 9.09773 , acc is: 0.046875 , iter= 565
current loss is: 9.164154 , acc is: 0.015625 , iter= 566
current loss is: 7.183633 , acc is: 0.046875 , iter= 567
current loss is: 12.039379 , acc is: 0.015625 , iter= 568
current loss is: 12.897463 , acc is: 0.03125 , iter= 569
current loss is: 5.197918 , acc is: 0.015625 , iter= 570
current loss is: 6.0524673 , acc is: 0.03125 , iter= 571
current loss is: 5.786467 , acc is: 0.0625 , iter= 572
current loss is: 5.608007 , acc is: 0.125 , iter= 573
current loss is: 4.097184 , acc is: 0.0625 , iter= 574
current loss is: 5.3433228 , acc is: 0.03125 , iter= 575
current loss is: 14.479819 , acc is: 0.109375 , iter= 576
current loss is: 4.259113 , acc is: 0.0625 , iter= 577
current loss is: 17.787645 , acc is: 0.0625 , iter= 578
current loss is: 4.8255825 , acc is: 0.046875 , iter= 579
current loss is: 4.2060337 , acc is: 0.0625 , iter= 580
current loss is: 5.868352 , acc is: 0.046875 , iter= 581
current loss is: 7.2535 , acc is: 0.046875 , iter= 582
current loss is: 4.267657 , acc is: 0.015625 , iter= 583
current loss is: 4.258375 , acc is: 0.015625 , iter= 584
current loss is: 6.2325726 , acc is: 0.078125 , iter= 585
current loss is: 4.09743 , acc is: 0.046875 , iter= 586
current loss is: 7.771902 , acc is: 0.015625 , iter= 587
current loss is: 4.051343 , acc is: 0.0625 , iter= 588
current loss is: 4.5320096 , acc is: 0.015625 , iter= 589
current loss is: 4.4248285 , acc is: 0.109375 , iter= 590
current loss is: 4.3509693 , acc is: 0.03125 , iter= 591
current loss is: 4.9453764 , acc is: 0.078125 , iter= 592
current loss is: 7.747487 , acc is: 0.03125 , iter= 593
current loss is: 8.785411 , acc is: 0.046875 , iter= 594
current loss is: 4.65547 , acc is: 0.0625 , iter= 595
current loss is: 4.6386538 , acc is: 0.0625 , iter= 596
current loss is: 6.5449886 , acc is: 0.046875 , iter= 597
current loss is: 5.61623 , acc is: 0.046875 , iter= 598
current loss is: 4.282164 , acc is: 0.046875 , iter= 599
current loss is: 4.448934 , acc is: 0.046875 , iter= 600
current loss is: 8.477848 , acc is: 0.03125 , iter= 601
current loss is: 5.7350287 , acc is: 0.0625 , iter= 602
current loss is: 4.542344 , acc is: 0.03125 , iter= 603
current loss is: 6.7179375 , acc is: 0.09375 , iter= 604
current loss is: 5.0548887 , acc is: 0.015625 , iter= 605
current loss is: 16.843273 , acc is: 0.03125 , iter= 606
current loss is: 7.582514 , acc is: 0.046875 , iter= 607
current loss is: 4.0895576 , acc is: 0.0625 , iter= 608
current loss is: 4.2419934 , acc is: 0.046875 , iter= 609
current loss is: 4.4188976 , acc is: 0.078125 , iter= 610
current loss is: 10.703191 , acc is: 0.046875 , iter= 611
current loss is: 4.0601482 , acc is: 0.046875 , iter= 612
current loss is: 11.588506 , acc is: 0.0625 , iter= 613
current loss is: 4.5311346 , acc is: 0.03125 , iter= 614
current loss is: 5.961367 , acc is: 0.0 , iter= 615
current loss is: 5.7367496 , acc is: 0.0625 , iter= 616
current loss is: 5.563093 , acc is: 0.0625 , iter= 617
current loss is: 3.9899032 , acc is: 0.046875 , iter= 618
current loss is: 5.0190907 , acc is: 0.046875 , iter= 619
current loss is: 9.246548 , acc is: 0.015625 , iter= 620
current loss is: 5.6985593 , acc is: 0.03125 , iter= 621
current loss is: 4.424298 , acc is: 0.0625 , iter= 622
current loss is: 4.3471494 , acc is: 0.078125 , iter= 623
current loss is: 11.256522 , acc is: 0.03125 , iter= 624
current loss is: 6.202064 , acc is: 0.046875 , iter= 625
current loss is: 4.741906 , acc is: 0.0625 , iter= 626
current loss is: 5.4855795 , acc is: 0.0625 , iter= 627
current loss is: 8.421982 , acc is: 0.015625 , iter= 628
current loss is: 7.3098583 , acc is: 0.03125 , iter= 629
current loss is: 8.210382 , acc is: 0.046875 , iter= 630
current loss is: 6.264094 , acc is: 0.078125 , iter= 631
current loss is: 5.818781 , acc is: 0.0625 , iter= 632
current loss is: 4.0812874 , acc is: 0.0625 , iter= 633
current loss is: 5.928994 , acc is: 0.015625 , iter= 634
current loss is: 5.003117 , acc is: 0.03125 , iter= 635
current loss is: 5.4324493 , acc is: 0.0 , iter= 636
current loss is: 4.1940184 , acc is: 0.03125 , iter= 637
current loss is: 5.5150204 , acc is: 0.0 , iter= 638
current loss is: 6.7077107 , acc is: 0.0625 , iter= 639
current loss is: 5.020406 , acc is: 0.015625 , iter= 640
current loss is: 4.099043 , acc is: 0.046875 , iter= 641
current loss is: 6.552784 , acc is: 0.03125 , iter= 642
current loss is: 4.1962776 , acc is: 0.046875 , iter= 643
current loss is: 5.5897512 , acc is: 0.03125 , iter= 644
current loss is: 4.7125506 , acc is: 0.03125 , iter= 645
current loss is: 8.230936 , acc is: 0.015625 , iter= 646
current loss is: 4.0679045 , acc is: 0.0625 , iter= 647
current loss is: 4.3821063 , acc is: 0.09375 , iter= 648
current loss is: 4.3478937 , acc is: 0.015625 , iter= 649
current loss is: 4.158144 , acc is: 0.03125 , iter= 650
current loss is: 4.206629 , acc is: 0.078125 , iter= 651
current loss is: 8.33589 , acc is: 0.0625 , iter= 652
current loss is: 4.366523 , acc is: 0.046875 , iter= 653
current loss is: 4.2963514 , acc is: 0.046875 , iter= 654
current loss is: 4.1277227 , acc is: 0.046875 , iter= 655
current loss is: 4.426622 , acc is: 0.03125 , iter= 656
current loss is: 4.073148 , acc is: 0.0625 , iter= 657
current loss is: 4.455741 , acc is: 0.0625 , iter= 658
current loss is: 4.221861 , acc is: 0.03125 , iter= 659
current loss is: 4.4834538 , acc is: 0.046875 , iter= 660
current loss is: 4.322421 , acc is: 0.09375 , iter= 661
current loss is: 10.681992 , acc is: 0.109375 , iter= 662
current loss is: 5.027772 , acc is: 0.03125 , iter= 663
current loss is: 4.031289 , acc is: 0.078125 , iter= 664
current loss is: 4.9929075 , acc is: 0.0625 , iter= 665
current loss is: 3.926122 , acc is: 0.09375 , iter= 666
current loss is: 6.26344 , acc is: 0.015625 , iter= 667
current loss is: 7.8218904 , acc is: 0.078125 , iter= 668
current loss is: 11.5119705 , acc is: 0.046875 , iter= 669
current loss is: 6.613432 , acc is: 0.0625 , iter= 670
current loss is: 11.00965 , acc is: 0.0625 , iter= 671
current loss is: 7.178897 , acc is: 0.046875 , iter= 672
current loss is: 4.271459 , acc is: 0.0625 , iter= 673
current loss is: 6.2785163 , acc is: 0.015625 , iter= 674
current loss is: 9.880926 , acc is: 0.0625 , iter= 675
current loss is: 4.1732435 , acc is: 0.03125 , iter= 676
current loss is: 4.1171894 , acc is: 0.03125 , iter= 677
current loss is: 11.608136 , acc is: 0.03125 , iter= 678
current loss is: 4.3144035 , acc is: 0.03125 , iter= 679
current loss is: 8.439226 , acc is: 0.03125 , iter= 680
current loss is: 12.515548 , acc is: 0.015625 , iter= 681
current loss is: 6.222319 , acc is: 0.15625 , iter= 682
current loss is: 4.6515565 , acc is: 0.03125 , iter= 683
current loss is: 4.142163 , acc is: 0.0625 , iter= 684
current loss is: 4.9306493 , acc is: 0.0625 , iter= 685
current loss is: 4.4189568 , acc is: 0.03125 , iter= 686
current loss is: 6.4294295 , acc is: 0.03125 , iter= 687
current loss is: 5.750539 , acc is: 0.015625 , iter= 688
current loss is: 6.808318 , acc is: 0.0625 , iter= 689
current loss is: 12.282286 , acc is: 0.0 , iter= 690
current loss is: 4.048524 , acc is: 0.078125 , iter= 691
current loss is: 4.4680076 , acc is: 0.046875 , iter= 692
current loss is: 7.837246 , acc is: 0.0 , iter= 693
current loss is: 3.8890777 , acc is: 0.09375 , iter= 694
current loss is: 4.269112 , acc is: 0.0 , iter= 695
current loss is: 5.9488688 , acc is: 0.03125 , iter= 696
current loss is: 5.059846 , acc is: 0.078125 , iter= 697
current loss is: 5.252268 , acc is: 0.03125 , iter= 698
current loss is: 8.864958 , acc is: 0.046875 , iter= 699
current loss is: 11.604692 , acc is: 0.015625 , iter= 700
current loss is: 3.9320598 , acc is: 0.0625 , iter= 701
current loss is: 5.335905 , acc is: 0.046875 , iter= 702
current loss is: 6.2374563 , acc is: 0.078125 , iter= 703
current loss is: 8.292421 , acc is: 0.046875 , iter= 704
current loss is: 3.9805412 , acc is: 0.109375 , iter= 705
current loss is: 12.026312 , acc is: 0.03125 , iter= 706
current loss is: 6.4748936 , acc is: 0.078125 , iter= 707
current loss is: 5.219196 , acc is: 0.0625 , iter= 708
current loss is: 5.8577433 , acc is: 0.03125 , iter= 709
current loss is: 13.701124 , acc is: 0.03125 , iter= 710
current loss is: 4.182539 , acc is: 0.046875 , iter= 711
current loss is: 5.7705193 , acc is: 0.03125 , iter= 712
current loss is: 4.0020094 , acc is: 0.0625 , iter= 713
current loss is: 4.886318 , acc is: 0.078125 , iter= 714
current loss is: 4.017249 , acc is: 0.0625 , iter= 715
current loss is: 4.7103615 , acc is: 0.03125 , iter= 716
current loss is: 4.182308 , acc is: 0.046875 , iter= 717
current loss is: 4.4582944 , acc is: 0.015625 , iter= 718
current loss is: 4.0818634 , acc is: 0.0625 , iter= 719
current loss is: 4.1998386 , acc is: 0.015625 , iter= 720
current loss is: 5.2178993 , acc is: 0.078125 , iter= 721
current loss is: 4.1499643 , acc is: 0.03125 , iter= 722
current loss is: 4.5658493 , acc is: 0.046875 , iter= 723
current loss is: 8.463119 , acc is: 0.015625 , iter= 724
current loss is: 8.293107 , acc is: 0.0625 , iter= 725
current loss is: 5.607382 , acc is: 0.046875 , iter= 726
current loss is: 4.116886 , acc is: 0.015625 , iter= 727
current loss is: 5.694381 , acc is: 0.0625 , iter= 728
current loss is: 4.7064266 , acc is: 0.0625 , iter= 729
current loss is: 4.065192 , acc is: 0.0625 , iter= 730
current loss is: 5.9988213 , acc is: 0.03125 , iter= 731
current loss is: 4.950227 , acc is: 0.03125 , iter= 732
current loss is: 3.930332 , acc is: 0.078125 , iter= 733
current loss is: 7.4606514 , acc is: 0.109375 , iter= 734
current loss is: 5.062871 , acc is: 0.0 , iter= 735
current loss is: 7.9433165 , acc is: 0.015625 , iter= 736
current loss is: 4.548295 , acc is: 0.015625 , iter= 737
current loss is: 4.166189 , acc is: 0.046875 , iter= 738
current loss is: 4.081799 , acc is: 0.078125 , iter= 739
current loss is: 7.6663365 , acc is: 0.046875 , iter= 740
current loss is: 4.2399626 , acc is: 0.03125 , iter= 741
current loss is: 4.1165895 , acc is: 0.046875 , iter= 742
current loss is: 4.1517577 , acc is: 0.03125 , iter= 743
current loss is: 5.9983287 , acc is: 0.015625 , iter= 744
current loss is: 8.347502 , acc is: 0.0625 , iter= 745
current loss is: 6.37758 , acc is: 0.046875 , iter= 746
current loss is: 4.5913515 , acc is: 0.03125 , iter= 747
current loss is: 4.338314 , acc is: 0.03125 , iter= 748
current loss is: 4.4416237 , acc is: 0.03125 , iter= 749
current loss is: 5.369898 , acc is: 0.046875 , iter= 750
current loss is: 4.1190076 , acc is: 0.046875 , iter= 751
current loss is: 7.403305 , acc is: 0.046875 , iter= 752
current loss is: 4.0249434 , acc is: 0.0625 , iter= 753
current loss is: 4.3589087 , acc is: 0.046875 , iter= 754
current loss is: 4.148909 , acc is: 0.03125 , iter= 755
current loss is: 3.857307 , acc is: 0.109375 , iter= 756
current loss is: 4.1743965 , acc is: 0.0 , iter= 757
current loss is: 4.795676 , acc is: 0.0625 , iter= 758
current loss is: 5.189746 , acc is: 0.015625 , iter= 759
current loss is: 5.1426544 , acc is: 0.03125 , iter= 760
current loss is: 4.180254 , acc is: 0.03125 , iter= 761
current loss is: 5.8771696 , acc is: 0.015625 , iter= 762
current loss is: 6.9493885 , acc is: 0.03125 , iter= 763
current loss is: 3.9773145 , acc is: 0.046875 , iter= 764
current loss is: 4.1656938 , acc is: 0.0625 , iter= 765
current loss is: 4.8007126 , acc is: 0.078125 , iter= 766
current loss is: 5.21579 , acc is: 0.0625 , iter= 767
current loss is: 5.233185 , acc is: 0.0625 , iter= 768
current loss is: 4.1021023 , acc is: 0.03125 , iter= 769
current loss is: 4.8847837 , acc is: 0.0625 , iter= 770
current loss is: 4.2252755 , acc is: 0.015625 , iter= 771
current loss is: 4.0441895 , acc is: 0.109375 , iter= 772
current loss is: 3.9957066 , acc is: 0.046875 , iter= 773
current loss is: 4.6431212 , acc is: 0.046875 , iter= 774
current loss is: 9.333706 , acc is: 0.046875 , iter= 775
current loss is: 5.037161 , acc is: 0.03125 , iter= 776
current loss is: 4.0927486 , acc is: 0.0625 , iter= 777
current loss is: 4.4932003 , acc is: 0.0625 , iter= 778
current loss is: 4.678288 , acc is: 0.0 , iter= 779
current loss is: 4.0478063 , acc is: 0.109375 , iter= 780
current loss is: 3.8865058 , acc is: 0.078125 , iter= 781
current loss is: 5.6490436 , acc is: 0.046875 , iter= 782
current loss is: 4.025732 , acc is: 0.0625 , iter= 783
current loss is: 5.249627 , acc is: 0.015625 , iter= 784
current loss is: 4.099917 , acc is: 0.03125 , iter= 785
current loss is: 4.09194 , acc is: 0.046875 , iter= 786
current loss is: 4.1729918 , acc is: 0.015625 , iter= 787
current loss is: 4.158322 , acc is: 0.03125 , iter= 788
current loss is: 4.1531844 , acc is: 0.046875 , iter= 789
current loss is: 4.786762 , acc is: 0.03125 , iter= 790
current loss is: 5.658347 , acc is: 0.015625 , iter= 791
current loss is: 4.0406976 , acc is: 0.03125 , iter= 792
current loss is: 4.618688 , acc is: 0.0625 , iter= 793
current loss is: 4.972884 , acc is: 0.015625 , iter= 794
current loss is: 9.3075 , acc is: 0.03125 , iter= 795
current loss is: 6.277301 , acc is: 0.015625 , iter= 796
current loss is: 7.5285006 , acc is: 0.046875 , iter= 797
current loss is: 4.0978575 , acc is: 0.046875 , iter= 798
current loss is: 6.825551 , acc is: 0.09375 , iter= 799
current loss is: 4.9399405 , acc is: 0.015625 , iter= 800
current loss is: 4.0986958 , acc is: 0.03125 , iter= 801
current loss is: 3.9512296 , acc is: 0.09375 , iter= 802
current loss is: 4.0553555 , acc is: 0.046875 , iter= 803
current loss is: 4.038624 , acc is: 0.03125 , iter= 804
current loss is: 4.1857014 , acc is: 0.015625 , iter= 805
current loss is: 4.166492 , acc is: 0.015625 , iter= 806
current loss is: 4.5353475 , acc is: 0.0625 , iter= 807
current loss is: 4.083683 , acc is: 0.078125 , iter= 808
current loss is: 4.120297 , acc is: 0.015625 , iter= 809
current loss is: 5.148493 , acc is: 0.125 , iter= 810
current loss is: 4.614594 , acc is: 0.046875 , iter= 811
current loss is: 4.4813824 , acc is: 0.046875 , iter= 812
current loss is: 5.669133 , acc is: 0.046875 , iter= 813
current loss is: 3.9748344 , acc is: 0.078125 , iter= 814
current loss is: 3.978268 , acc is: 0.0625 , iter= 815
current loss is: 3.9799628 , acc is: 0.0625 , iter= 816
current loss is: 4.197317 , acc is: 0.09375 , iter= 817
current loss is: 8.604741 , acc is: 0.03125 , iter= 818
current loss is: 4.113644 , acc is: 0.015625 , iter= 819
current loss is: 4.118367 , acc is: 0.046875 , iter= 820
current loss is: 5.874693 , acc is: 0.015625 , iter= 821
current loss is: 5.8032637 , acc is: 0.078125 , iter= 822
current loss is: 4.019038 , acc is: 0.046875 , iter= 823
current loss is: 4.064097 , acc is: 0.046875 , iter= 824
current loss is: 4.782219 , acc is: 0.0 , iter= 825
current loss is: 5.0901127 , acc is: 0.0625 , iter= 826
current loss is: 3.9922616 , acc is: 0.046875 , iter= 827
current loss is: 7.764321 , acc is: 0.109375 , iter= 828
current loss is: 4.3527985 , acc is: 0.046875 , iter= 829
current loss is: 4.173827 , acc is: 0.03125 , iter= 830
current loss is: 3.9882283 , acc is: 0.0625 , iter= 831
current loss is: 4.281402 , acc is: 0.046875 , iter= 832
current loss is: 4.4917665 , acc is: 0.046875 , iter= 833
current loss is: 7.4639425 , acc is: 0.046875 , iter= 834
current loss is: 6.0872006 , acc is: 0.125 , iter= 835
current loss is: 4.187281 , acc is: 0.03125 , iter= 836
current loss is: 4.3924375 , acc is: 0.03125 , iter= 837
current loss is: 4.0181136 , acc is: 0.046875 , iter= 838
current loss is: 7.3142653 , acc is: 0.03125 , iter= 839
current loss is: 3.9695911 , acc is: 0.078125 , iter= 840
current loss is: 4.251381 , acc is: 0.0625 , iter= 841
current loss is: 5.2376013 , acc is: 0.015625 , iter= 842
current loss is: 4.8952646 , acc is: 0.015625 , iter= 843
current loss is: 4.158575 , acc is: 0.015625 , iter= 844
current loss is: 6.007092 , acc is: 0.0625 , iter= 845
current loss is: 5.4416294 , acc is: 0.03125 , iter= 846
current loss is: 5.5788994 , acc is: 0.09375 , iter= 847
current loss is: 6.351722 , acc is: 0.015625 , iter= 848
current loss is: 4.2191467 , acc is: 0.0 , iter= 849
current loss is: 4.505123 , acc is: 0.046875 , iter= 850
current loss is: 3.943008 , acc is: 0.078125 , iter= 851
current loss is: 6.0412 , acc is: 0.015625 , iter= 852
current loss is: 4.8423533 , acc is: 0.046875 , iter= 853
current loss is: 3.875694 , acc is: 0.09375 , iter= 854
current loss is: 4.0827246 , acc is: 0.0625 , iter= 855
current loss is: 8.60063 , acc is: 0.046875 , iter= 856
current loss is: 6.130435 , acc is: 0.03125 , iter= 857
current loss is: 4.289895 , acc is: 0.109375 , iter= 858
current loss is: 4.1139374 , acc is: 0.03125 , iter= 859
current loss is: 5.045986 , acc is: 0.0625 , iter= 860
current loss is: 3.8263876 , acc is: 0.09375 , iter= 861
current loss is: 4.187993 , acc is: 0.078125 , iter= 862
current loss is: 4.8934407 , acc is: 0.03125 , iter= 863
current loss is: 4.0362444 , acc is: 0.0625 , iter= 864
current loss is: 4.1371527 , acc is: 0.0625 , iter= 865
current loss is: 4.079643 , acc is: 0.03125 , iter= 866
current loss is: 7.1631513 , acc is: 0.03125 , iter= 867
current loss is: 5.7882695 , acc is: 0.046875 , iter= 868
current loss is: 4.7841916 , acc is: 0.078125 , iter= 869
current loss is: 6.4813013 , acc is: 0.0 , iter= 870
current loss is: 4.0846367 , acc is: 0.046875 , iter= 871
current loss is: 4.1012955 , acc is: 0.046875 , iter= 872
current loss is: 4.3669863 , acc is: 0.015625 , iter= 873
current loss is: 5.9730396 , acc is: 0.046875 , iter= 874
current loss is: 4.2507353 , acc is: 0.078125 , iter= 875
current loss is: 5.3994393 , acc is: 0.0625 , iter= 876
current loss is: 4.160612 , acc is: 0.046875 , iter= 877
current loss is: 5.302946 , acc is: 0.046875 , iter= 878
current loss is: 4.2401185 , acc is: 0.03125 , iter= 879
current loss is: 9.818952 , acc is: 0.015625 , iter= 880
current loss is: 4.291565 , acc is: 0.03125 , iter= 881
current loss is: 4.0787563 , acc is: 0.03125 , iter= 882
current loss is: 3.9423518 , acc is: 0.078125 , iter= 883
current loss is: 3.9676788 , acc is: 0.0625 , iter= 884
current loss is: 4.287185 , acc is: 0.046875 , iter= 885
current loss is: 4.0450783 , acc is: 0.0625 , iter= 886
current loss is: 5.412685 , acc is: 0.046875 , iter= 887
current loss is: 7.7179832 , acc is: 0.015625 , iter= 888
current loss is: 3.966518 , acc is: 0.078125 , iter= 889
current loss is: 3.9935076 , acc is: 0.09375 , iter= 890
current loss is: 4.0288177 , acc is: 0.0625 , iter= 891
current loss is: 3.9268742 , acc is: 0.09375 , iter= 892
current loss is: 7.7592497 , acc is: 0.0 , iter= 893
current loss is: 7.1235614 , acc is: 0.0625 , iter= 894
current loss is: 3.8516152 , acc is: 0.109375 , iter= 895
current loss is: 4.487764 , acc is: 0.015625 , iter= 896
current loss is: 5.129858 , acc is: 0.0 , iter= 897
current loss is: 4.4437556 , acc is: 0.015625 , iter= 898
current loss is: 4.1314487 , acc is: 0.015625 , iter= 899
current loss is: 4.185737 , acc is: 0.046875 , iter= 900
current loss is: 4.0525985 , acc is: 0.046875 , iter= 901
current loss is: 4.2625413 , acc is: 0.046875 , iter= 902
current loss is: 4.0397363 , acc is: 0.0625 , iter= 903
current loss is: 5.0357914 , acc is: 0.0625 , iter= 904
current loss is: 3.9607558 , acc is: 0.109375 , iter= 905
current loss is: 4.074648 , acc is: 0.03125 , iter= 906
current loss is: 4.223268 , acc is: 0.0 , iter= 907
current loss is: 4.8950796 , acc is: 0.046875 , iter= 908
current loss is: 4.0254045 , acc is: 0.0625 , iter= 909
current loss is: 4.135579 , acc is: 0.046875 , iter= 910
current loss is: 5.863925 , acc is: 0.03125 , iter= 911
current loss is: 4.413292 , acc is: 0.046875 , iter= 912
current loss is: 4.947688 , acc is: 0.046875 , iter= 913
current loss is: 3.9579563 , acc is: 0.0625 , iter= 914
current loss is: 4.308691 , acc is: 0.046875 , iter= 915
current loss is: 5.129402 , acc is: 0.03125 , iter= 916
current loss is: 5.130991 , acc is: 0.03125 , iter= 917
current loss is: 5.1837373 , acc is: 0.0625 , iter= 918
current loss is: 4.6462436 , acc is: 0.046875 , iter= 919
current loss is: 5.359332 , acc is: 0.015625 , iter= 920
current loss is: 4.137697 , acc is: 0.03125 , iter= 921
current loss is: 3.969499 , acc is: 0.078125 , iter= 922
current loss is: 3.9712539 , acc is: 0.046875 , iter= 923
current loss is: 5.7037725 , acc is: 0.03125 , iter= 924
current loss is: 5.2767735 , acc is: 0.0625 , iter= 925
current loss is: 4.0702047 , acc is: 0.078125 , iter= 926
current loss is: 3.9778924 , acc is: 0.09375 , iter= 927
current loss is: 4.0802383 , acc is: 0.046875 , iter= 928
current loss is: 4.184824 , acc is: 0.03125 , iter= 929
current loss is: 4.120805 , acc is: 0.03125 , iter= 930
current loss is: 4.1243725 , acc is: 0.0625 , iter= 931
current loss is: 4.7728405 , acc is: 0.046875 , iter= 932
current loss is: 4.1602936 , acc is: 0.0625 , iter= 933
current loss is: 3.8139536 , acc is: 0.109375 , iter= 934
current loss is: 7.768056 , acc is: 0.09375 , iter= 935
current loss is: 4.3904076 , acc is: 0.046875 , iter= 936
current loss is: 4.106861 , acc is: 0.078125 , iter= 937
current loss is: 4.6034217 , acc is: 0.03125 , iter= 938
current loss is: 4.0381203 , acc is: 0.046875 , iter= 939
current loss is: 4.1197295 , acc is: 0.03125 , iter= 940
current loss is: 9.085302 , acc is: 0.109375 , iter= 941
current loss is: 4.1340446 , acc is: 0.046875 , iter= 942
current loss is: 4.1689005 , acc is: 0.03125 , iter= 943
current loss is: 4.9775786 , acc is: 0.046875 , iter= 944
current loss is: 5.412145 , acc is: 0.03125 , iter= 945
current loss is: 5.014847 , acc is: 0.078125 , iter= 946
current loss is: 4.1764145 , acc is: 0.0625 , iter= 947
current loss is: 4.491126 , acc is: 0.015625 , iter= 948
current loss is: 4.163557 , acc is: 0.015625 , iter= 949
current loss is: 4.1527367 , acc is: 0.015625 , iter= 950
current loss is: 4.166686 , acc is: 0.0 , iter= 951
current loss is: 6.426061 , acc is: 0.015625 , iter= 952
current loss is: 5.567956 , acc is: 0.015625 , iter= 953
current loss is: 4.0478153 , acc is: 0.125 , iter= 954
current loss is: 6.29348 , acc is: 0.015625 , iter= 955
current loss is: 4.1524134 , acc is: 0.03125 , iter= 956
current loss is: 4.0290065 , acc is: 0.0625 , iter= 957
current loss is: 4.207201 , acc is: 0.046875 , iter= 958
current loss is: 6.680298 , acc is: 0.046875 , iter= 959
current loss is: 4.024453 , acc is: 0.078125 , iter= 960
current loss is: 4.2194448 , acc is: 0.015625 , iter= 961
current loss is: 4.219102 , acc is: 0.0625 , iter= 962
current loss is: 4.789857 , acc is: 0.015625 , iter= 963
current loss is: 3.9292977 , acc is: 0.0625 , iter= 964
current loss is: 4.534177 , acc is: 0.046875 , iter= 965
current loss is: 3.7877576 , acc is: 0.0625 , iter= 966
current loss is: 4.101327 , acc is: 0.03125 , iter= 967
current loss is: 6.073323 , acc is: 0.015625 , iter= 968
current loss is: 3.9710696 , acc is: 0.03125 , iter= 969
current loss is: 4.410706 , acc is: 0.03125 , iter= 970
current loss is: 4.734674 , acc is: 0.046875 , iter= 971
current loss is: 4.6801515 , acc is: 0.0625 , iter= 972
current loss is: 3.9718285 , acc is: 0.078125 , iter= 973
current loss is: 7.4135227 , acc is: 0.046875 , iter= 974
current loss is: 4.113206 , acc is: 0.03125 , iter= 975
current loss is: 3.9316494 , acc is: 0.078125 , iter= 976
current loss is: 4.1341877 , acc is: 0.03125 , iter= 977
current loss is: 7.284214 , acc is: 0.09375 , iter= 978
current loss is: 15.1546135 , acc is: 0.03125 , iter= 979
current loss is: 4.0559635 , acc is: 0.0625 , iter= 980
current loss is: 4.106261 , acc is: 0.03125 , iter= 981
current loss is: 4.479274 , acc is: 0.015625 , iter= 982
current loss is: 3.888529 , acc is: 0.0625 , iter= 983
current loss is: 4.0347133 , acc is: 0.0625 , iter= 984
current loss is: 4.0190926 , acc is: 0.078125 , iter= 985
current loss is: 3.7930732 , acc is: 0.125 , iter= 986
current loss is: 4.1210356 , acc is: 0.046875 , iter= 987
current loss is: 4.9415345 , acc is: 0.0 , iter= 988
current loss is: 4.3034763 , acc is: 0.0625 , iter= 989
current loss is: 4.4004593 , acc is: 0.0625 , iter= 990
current loss is: 3.9155176 , acc is: 0.0625 , iter= 991
current loss is: 4.161563 , acc is: 0.046875 , iter= 992
current loss is: 4.1669436 , acc is: 0.03125 , iter= 993
current loss is: 4.1792545 , acc is: 0.09375 , iter= 994
current loss is: 4.8653584 , acc is: 0.046875 , iter= 995
current loss is: 4.1788964 , acc is: 0.03125 , iter= 996
current loss is: 4.2272444 , acc is: 0.046875 , iter= 997
current loss is: 6.8324676 , acc is: 0.03125 , iter= 998
current loss is: 4.113807 , acc is: 0.015625 , iter= 999
current loss is: 5.3995266 , acc is: 0.015625 , iter= 1000
tot_acc= 19.0 tot_input= 768
current accuracy is: 0.024739583333333332
current loss is: 4.1365404 , acc is: 0.046875 , iter= 1001
current loss is: 6.7663956 , acc is: 0.03125 , iter= 1002
current loss is: 4.2598953 , acc is: 0.0625 , iter= 1003
current loss is: 4.0818276 , acc is: 0.046875 , iter= 1004
current loss is: 4.852169 , acc is: 0.03125 , iter= 1005
current loss is: 4.1468115 , acc is: 0.0625 , iter= 1006
current loss is: 4.0125027 , acc is: 0.046875 , iter= 1007
current loss is: 4.2007666 , acc is: 0.0625 , iter= 1008
current loss is: 4.2645273 , acc is: 0.015625 , iter= 1009
current loss is: 3.8516994 , acc is: 0.09375 , iter= 1010
current loss is: 4.170476 , acc is: 0.046875 , iter= 1011
current loss is: 4.0715637 , acc is: 0.03125 , iter= 1012
current loss is: 4.1545653 , acc is: 0.015625 , iter= 1013
current loss is: 4.105563 , acc is: 0.0625 , iter= 1014
current loss is: 4.1987176 , acc is: 0.046875 , iter= 1015
current loss is: 4.0813065 , acc is: 0.03125 , iter= 1016
current loss is: 4.101995 , acc is: 0.046875 , iter= 1017
current loss is: 4.125757 , acc is: 0.046875 , iter= 1018
current loss is: 4.855914 , acc is: 0.0625 , iter= 1019
current loss is: 4.1175985 , acc is: 0.03125 , iter= 1020
current loss is: 3.842918 , acc is: 0.09375 , iter= 1021
current loss is: 4.086638 , acc is: 0.078125 , iter= 1022
current loss is: 4.2215834 , acc is: 0.0625 , iter= 1023
current loss is: 4.044093 , acc is: 0.0625 , iter= 1024
current loss is: 5.4420485 , acc is: 0.03125 , iter= 1025
current loss is: 4.311906 , acc is: 0.0625 , iter= 1026
current loss is: 7.1198316 , acc is: 0.03125 , iter= 1027
current loss is: 4.3314986 , acc is: 0.015625 , iter= 1028
current loss is: 4.237808 , acc is: 0.046875 , iter= 1029
current loss is: 4.9422007 , acc is: 0.0 , iter= 1030
current loss is: 4.1087995 , acc is: 0.0625 , iter= 1031
current loss is: 4.0533566 , acc is: 0.078125 , iter= 1032
current loss is: 3.9611251 , acc is: 0.0625 , iter= 1033
current loss is: 4.847414 , acc is: 0.078125 , iter= 1034
current loss is: 4.029353 , acc is: 0.046875 , iter= 1035
current loss is: 4.1019497 , acc is: 0.0625 , iter= 1036
current loss is: 4.503732 , acc is: 0.03125 , iter= 1037
current loss is: 7.1609826 , acc is: 0.0625 , iter= 1038
current loss is: 3.8221314 , acc is: 0.09375 , iter= 1039
current loss is: 4.7616134 , acc is: 0.046875 , iter= 1040
current loss is: 4.0645075 , acc is: 0.046875 , iter= 1041
current loss is: 4.164688 , acc is: 0.09375 , iter= 1042
current loss is: 4.453864 , acc is: 0.03125 , iter= 1043
current loss is: 4.1128807 , acc is: 0.03125 , iter= 1044
current loss is: 5.4258146 , acc is: 0.03125 , iter= 1045
current loss is: 3.841944 , acc is: 0.140625 , iter= 1046
current loss is: 4.14686 , acc is: 0.046875 , iter= 1047
current loss is: 4.0398703 , acc is: 0.0625 , iter= 1048
current loss is: 4.011204 , acc is: 0.078125 , iter= 1049
current loss is: 4.281679 , acc is: 0.078125 , iter= 1050
current loss is: 4.0597715 , acc is: 0.09375 , iter= 1051
current loss is: 4.2559075 , acc is: 0.0 , iter= 1052
current loss is: 4.0509415 , acc is: 0.046875 , iter= 1053
current loss is: 4.5899734 , acc is: 0.015625 , iter= 1054
current loss is: 6.6317215 , acc is: 0.078125 , iter= 1055
current loss is: 4.4408693 , acc is: 0.109375 , iter= 1056
current loss is: 4.5108247 , acc is: 0.046875 , iter= 1057
current loss is: 4.371124 , acc is: 0.03125 , iter= 1058
current loss is: 4.058377 , acc is: 0.03125 , iter= 1059
current loss is: 3.9554694 , acc is: 0.046875 , iter= 1060
current loss is: 4.3851113 , acc is: 0.015625 , iter= 1061
current loss is: 4.1074796 , acc is: 0.015625 , iter= 1062
current loss is: 3.8877845 , acc is: 0.09375 , iter= 1063
current loss is: 5.9247184 , acc is: 0.046875 , iter= 1064
current loss is: 6.30042 , acc is: 0.046875 , iter= 1065
current loss is: 4.1131153 , acc is: 0.03125 , iter= 1066
current loss is: 4.222845 , acc is: 0.03125 , iter= 1067
current loss is: 4.1532183 , acc is: 0.078125 , iter= 1068
current loss is: 4.1607866 , acc is: 0.046875 , iter= 1069
current loss is: 4.1228056 , acc is: 0.03125 , iter= 1070
current loss is: 4.734063 , acc is: 0.078125 , iter= 1071
current loss is: 4.1901846 , acc is: 0.0625 , iter= 1072
current loss is: 3.8463845 , acc is: 0.09375 , iter= 1073
current loss is: 3.9251912 , acc is: 0.09375 , iter= 1074
current loss is: 4.170456 , acc is: 0.015625 , iter= 1075
current loss is: 3.8468127 , acc is: 0.09375 , iter= 1076
current loss is: 3.9836755 , acc is: 0.09375 , iter= 1077
current loss is: 4.004119 , acc is: 0.0625 , iter= 1078
current loss is: 4.094763 , acc is: 0.015625 , iter= 1079
current loss is: 3.9498823 , acc is: 0.0625 , iter= 1080
current loss is: 4.0932918 , acc is: 0.015625 , iter= 1081
current loss is: 4.0966015 , acc is: 0.03125 , iter= 1082
current loss is: 5.1608768 , acc is: 0.078125 , iter= 1083
current loss is: 4.1878214 , acc is: 0.109375 , iter= 1084
current loss is: 4.3932133 , acc is: 0.046875 , iter= 1085
current loss is: 4.318054 , acc is: 0.0 , iter= 1086
current loss is: 4.3949814 , acc is: 0.0625 , iter= 1087
current loss is: 3.9511323 , acc is: 0.078125 , iter= 1088
current loss is: 4.338461 , acc is: 0.015625 , iter= 1089
current loss is: 4.0035543 , acc is: 0.078125 , iter= 1090
current loss is: 4.0692616 , acc is: 0.03125 , iter= 1091
current loss is: 4.112405 , acc is: 0.015625 , iter= 1092
current loss is: 4.089868 , acc is: 0.046875 , iter= 1093
current loss is: 4.591794 , acc is: 0.03125 , iter= 1094
current loss is: 4.3256497 , acc is: 0.046875 , iter= 1095
current loss is: 4.955782 , acc is: 0.03125 , iter= 1096
current loss is: 4.135624 , acc is: 0.03125 , iter= 1097
current loss is: 6.3706264 , acc is: 0.078125 , iter= 1098
current loss is: 4.1014853 , acc is: 0.03125 , iter= 1099
current loss is: 3.9486017 , acc is: 0.078125 , iter= 1100
current loss is: 4.105048 , acc is: 0.078125 , iter= 1101
current loss is: 4.19461 , acc is: 0.0 , iter= 1102
current loss is: 3.855689 , acc is: 0.09375 , iter= 1103
current loss is: 4.1312423 , acc is: 0.03125 , iter= 1104
current loss is: 4.478457 , acc is: 0.03125 , iter= 1105
current loss is: 4.213829 , acc is: 0.078125 , iter= 1106
current loss is: 4.491429 , acc is: 0.015625 , iter= 1107
current loss is: 3.9146438 , acc is: 0.0625 , iter= 1108
current loss is: 4.214632 , acc is: 0.03125 , iter= 1109
current loss is: 3.9521632 , acc is: 0.0625 , iter= 1110
current loss is: 4.6524005 , acc is: 0.046875 , iter= 1111
current loss is: 4.199692 , acc is: 0.03125 , iter= 1112
current loss is: 6.2353783 , acc is: 0.046875 , iter= 1113
current loss is: 4.1542153 , acc is: 0.0625 , iter= 1114
current loss is: 3.8971725 , acc is: 0.078125 , iter= 1115
current loss is: 4.164094 , acc is: 0.0625 , iter= 1116
current loss is: 4.1329503 , acc is: 0.03125 , iter= 1117
current loss is: 4.128806 , acc is: 0.046875 , iter= 1118
current loss is: 4.0059643 , acc is: 0.0625 , iter= 1119
current loss is: 3.9634223 , acc is: 0.0625 , iter= 1120
current loss is: 4.1411004 , acc is: 0.0 , iter= 1121
current loss is: 3.970442 , acc is: 0.125 , iter= 1122
current loss is: 3.9292827 , acc is: 0.0625 , iter= 1123
current loss is: 4.1604176 , acc is: 0.0 , iter= 1124
current loss is: 4.2336664 , acc is: 0.015625 , iter= 1125
current loss is: 6.908935 , acc is: 0.0625 , iter= 1126
current loss is: 3.8835196 , acc is: 0.078125 , iter= 1127
current loss is: 5.0243397 , acc is: 0.03125 , iter= 1128
current loss is: 4.7097316 , acc is: 0.0625 , iter= 1129
current loss is: 4.1920137 , acc is: 0.015625 , iter= 1130
current loss is: 4.458171 , acc is: 0.046875 , iter= 1131
current loss is: 4.11626 , acc is: 0.03125 , iter= 1132
current loss is: 4.026987 , acc is: 0.046875 , iter= 1133
current loss is: 3.9119086 , acc is: 0.046875 , iter= 1134
current loss is: 3.940801 , acc is: 0.109375 , iter= 1135
current loss is: 3.9300158 , acc is: 0.078125 , iter= 1136
current loss is: 4.0149126 , acc is: 0.09375 , iter= 1137
current loss is: 4.6356406 , acc is: 0.015625 , iter= 1138
current loss is: 4.2138395 , acc is: 0.0625 , iter= 1139
current loss is: 4.0634475 , acc is: 0.046875 , iter= 1140
current loss is: 4.149374 , acc is: 0.03125 , iter= 1141
current loss is: 3.893678 , acc is: 0.09375 , iter= 1142
current loss is: 4.052318 , acc is: 0.03125 , iter= 1143
current loss is: 4.039142 , acc is: 0.046875 , iter= 1144
current loss is: 4.0658493 , acc is: 0.03125 , iter= 1145
current loss is: 4.207228 , acc is: 0.046875 , iter= 1146
current loss is: 3.9154334 , acc is: 0.09375 , iter= 1147
current loss is: 4.2541275 , acc is: 0.046875 , iter= 1148
current loss is: 4.007345 , acc is: 0.03125 , iter= 1149
current loss is: 7.0915728 , acc is: 0.03125 , iter= 1150
current loss is: 3.9977093 , acc is: 0.046875 , iter= 1151
current loss is: 4.121352 , acc is: 0.015625 , iter= 1152
current loss is: 3.8471475 , acc is: 0.09375 , iter= 1153
current loss is: 3.8812172 , acc is: 0.09375 , iter= 1154
current loss is: 4.3794866 , acc is: 0.0625 , iter= 1155
current loss is: 4.0252504 , acc is: 0.03125 , iter= 1156
current loss is: 3.992836 , acc is: 0.046875 , iter= 1157
current loss is: 5.188082 , acc is: 0.046875 , iter= 1158
current loss is: 4.9583497 , acc is: 0.03125 , iter= 1159
current loss is: 3.9123855 , acc is: 0.078125 , iter= 1160
current loss is: 4.042509 , acc is: 0.0625 , iter= 1161
current loss is: 4.0647936 , acc is: 0.078125 , iter= 1162
current loss is: 5.0686674 , acc is: 0.046875 , iter= 1163
current loss is: 5.9304576 , acc is: 0.015625 , iter= 1164
current loss is: 3.9794319 , acc is: 0.0625 , iter= 1165
current loss is: 4.257176 , acc is: 0.0 , iter= 1166
current loss is: 4.329209 , acc is: 0.0625 , iter= 1167
current loss is: 4.2305527 , acc is: 0.046875 , iter= 1168
current loss is: 4.053809 , acc is: 0.046875 , iter= 1169
current loss is: 4.053957 , acc is: 0.046875 , iter= 1170
current loss is: 4.084997 , acc is: 0.03125 , iter= 1171
current loss is: 4.064354 , acc is: 0.078125 , iter= 1172
current loss is: 4.1201615 , acc is: 0.09375 , iter= 1173
current loss is: 4.060293 , acc is: 0.03125 , iter= 1174
current loss is: 3.94739 , acc is: 0.078125 , iter= 1175
current loss is: 4.2376966 , acc is: 0.0 , iter= 1176
current loss is: 4.032951 , acc is: 0.078125 , iter= 1177
current loss is: 4.0452867 , acc is: 0.0625 , iter= 1178
current loss is: 3.981419 , acc is: 0.078125 , iter= 1179
current loss is: 4.0529146 , acc is: 0.046875 , iter= 1180
current loss is: 4.092328 , acc is: 0.03125 , iter= 1181
current loss is: 3.996455 , acc is: 0.046875 , iter= 1182
current loss is: 4.242704 , acc is: 0.03125 , iter= 1183
current loss is: 4.2061973 , acc is: 0.015625 , iter= 1184
current loss is: 4.0719614 , acc is: 0.03125 , iter= 1185
current loss is: 4.0923543 , acc is: 0.03125 , iter= 1186
current loss is: 4.4014444 , acc is: 0.0625 , iter= 1187
current loss is: 7.56336 , acc is: 0.078125 , iter= 1188
current loss is: 4.0925817 , acc is: 0.03125 , iter= 1189
current loss is: 4.149207 , acc is: 0.03125 , iter= 1190
current loss is: 4.0200777 , acc is: 0.03125 , iter= 1191
current loss is: 3.917053 , acc is: 0.078125 , iter= 1192
current loss is: 3.994946 , acc is: 0.0625 , iter= 1193
current loss is: 4.163995 , acc is: 0.046875 , iter= 1194
current loss is: 5.7281566 , acc is: 0.0625 , iter= 1195
current loss is: 3.9591336 , acc is: 0.0625 , iter= 1196
current loss is: 4.166604 , acc is: 0.015625 , iter= 1197
current loss is: 4.032137 , acc is: 0.0625 , iter= 1198
current loss is: 4.0699577 , acc is: 0.03125 , iter= 1199
current loss is: 5.365315 , acc is: 0.03125 , iter= 1200
current loss is: 4.214732 , acc is: 0.015625 , iter= 1201
current loss is: 4.013583 , acc is: 0.0625 , iter= 1202
current loss is: 4.6834207 , acc is: 0.03125 , iter= 1203
current loss is: 5.3901844 , acc is: 0.046875 , iter= 1204
current loss is: 4.072659 , acc is: 0.046875 , iter= 1205
current loss is: 5.1236744 , acc is: 0.03125 , iter= 1206
current loss is: 4.0439787 , acc is: 0.046875 , iter= 1207
current loss is: 3.9499905 , acc is: 0.078125 , iter= 1208
current loss is: 4.1983137 , acc is: 0.046875 , iter= 1209
current loss is: 4.03588 , acc is: 0.078125 , iter= 1210
current loss is: 4.121026 , acc is: 0.03125 , iter= 1211
current loss is: 3.9256768 , acc is: 0.0625 , iter= 1212
current loss is: 4.158255 , acc is: 0.0625 , iter= 1213
current loss is: 4.145209 , acc is: 0.03125 , iter= 1214
current loss is: 3.9571314 , acc is: 0.078125 , iter= 1215
current loss is: 4.09394 , acc is: 0.015625 , iter= 1216
current loss is: 4.0589924 , acc is: 0.03125 , iter= 1217
current loss is: 4.152738 , acc is: 0.015625 , iter= 1218
current loss is: 4.192473 , acc is: 0.078125 , iter= 1219
current loss is: 4.118024 , acc is: 0.046875 , iter= 1220
current loss is: 4.0401506 , acc is: 0.03125 , iter= 1221
current loss is: 4.3511963 , acc is: 0.03125 , iter= 1222
current loss is: 4.1554127 , acc is: 0.015625 , iter= 1223
current loss is: 4.142615 , acc is: 0.046875 , iter= 1224
current loss is: 3.9814532 , acc is: 0.078125 , iter= 1225
current loss is: 4.0416646 , acc is: 0.0625 , iter= 1226
current loss is: 4.0140696 , acc is: 0.078125 , iter= 1227
current loss is: 4.1480627 , acc is: 0.046875 , iter= 1228
current loss is: 4.071836 , acc is: 0.078125 , iter= 1229
current loss is: 4.1376147 , acc is: 0.03125 , iter= 1230
current loss is: 4.0534325 , acc is: 0.046875 , iter= 1231
current loss is: 3.968947 , acc is: 0.078125 , iter= 1232
current loss is: 3.929308 , acc is: 0.0625 , iter= 1233
current loss is: 4.215642 , acc is: 0.0625 , iter= 1234
current loss is: 3.8981752 , acc is: 0.109375 , iter= 1235
current loss is: 4.0042005 , acc is: 0.046875 , iter= 1236
current loss is: 5.166255 , acc is: 0.0625 , iter= 1237
current loss is: 4.030483 , acc is: 0.0625 , iter= 1238
current loss is: 4.0235333 , acc is: 0.03125 , iter= 1239
current loss is: 4.224723 , acc is: 0.03125 , iter= 1240
current loss is: 4.130947 , acc is: 0.046875 , iter= 1241
current loss is: 4.2341065 , acc is: 0.015625 , iter= 1242
current loss is: 4.138914 , acc is: 0.046875 , iter= 1243
current loss is: 4.086753 , acc is: 0.0625 , iter= 1244
current loss is: 3.9592562 , acc is: 0.078125 , iter= 1245
current loss is: 4.0734577 , acc is: 0.046875 , iter= 1246
current loss is: 3.900901 , acc is: 0.078125 , iter= 1247
current loss is: 4.632922 , acc is: 0.0625 , iter= 1248
current loss is: 3.9218273 , acc is: 0.046875 , iter= 1249
current loss is: 4.1603184 , acc is: 0.0 , iter= 1250
current loss is: 3.9392118 , acc is: 0.0625 , iter= 1251
current loss is: 3.9512787 , acc is: 0.046875 , iter= 1252
current loss is: 4.0207367 , acc is: 0.078125 , iter= 1253
current loss is: 4.492787 , acc is: 0.03125 , iter= 1254
current loss is: 3.9715676 , acc is: 0.03125 , iter= 1255
current loss is: 4.0318327 , acc is: 0.0625 , iter= 1256
current loss is: 3.9798808 , acc is: 0.078125 , iter= 1257
current loss is: 4.288346 , acc is: 0.046875 , iter= 1258
current loss is: 4.3586326 , acc is: 0.0625 , iter= 1259
current loss is: 3.8356798 , acc is: 0.09375 , iter= 1260
current loss is: 4.135725 , acc is: 0.015625 , iter= 1261
current loss is: 4.087736 , acc is: 0.046875 , iter= 1262
current loss is: 3.9840012 , acc is: 0.0625 , iter= 1263
current loss is: 4.039976 , acc is: 0.03125 , iter= 1264
current loss is: 3.9711943 , acc is: 0.046875 , iter= 1265
current loss is: 3.9616542 , acc is: 0.078125 , iter= 1266
current loss is: 3.959254 , acc is: 0.109375 , iter= 1267
current loss is: 4.110841 , acc is: 0.015625 , iter= 1268
current loss is: 3.9329786 , acc is: 0.109375 , iter= 1269
current loss is: 4.179973 , acc is: 0.03125 , iter= 1270
current loss is: 4.260172 , acc is: 0.046875 , iter= 1271
current loss is: 4.125958 , acc is: 0.03125 , iter= 1272
current loss is: 3.9708 , acc is: 0.0625 , iter= 1273
current loss is: 4.0799785 , acc is: 0.0625 , iter= 1274
current loss is: 4.1630836 , acc is: 0.046875 , iter= 1275
current loss is: 3.969612 , acc is: 0.078125 , iter= 1276
current loss is: 4.5088215 , acc is: 0.03125 , iter= 1277
current loss is: 4.105542 , acc is: 0.03125 , iter= 1278
current loss is: 3.8722472 , acc is: 0.078125 , iter= 1279
current loss is: 4.1718745 , acc is: 0.015625 , iter= 1280
current loss is: 4.182749 , acc is: 0.03125 , iter= 1281
current loss is: 4.1923137 , acc is: 0.03125 , iter= 1282
current loss is: 4.085009 , acc is: 0.046875 , iter= 1283
current loss is: 4.1588163 , acc is: 0.03125 , iter= 1284
current loss is: 4.126789 , acc is: 0.015625 , iter= 1285
current loss is: 4.077901 , acc is: 0.046875 , iter= 1286
current loss is: 4.100548 , acc is: 0.015625 , iter= 1287
current loss is: 3.9441674 , acc is: 0.078125 , iter= 1288
current loss is: 5.1869106 , acc is: 0.0625 , iter= 1289
current loss is: 4.066042 , acc is: 0.046875 , iter= 1290
current loss is: 3.780831 , acc is: 0.109375 , iter= 1291
current loss is: 4.045329 , acc is: 0.09375 , iter= 1292
current loss is: 3.9395185 , acc is: 0.0625 , iter= 1293
current loss is: 3.967602 , acc is: 0.078125 , iter= 1294
current loss is: 4.1339445 , acc is: 0.046875 , iter= 1295
current loss is: 4.120401 , acc is: 0.0625 , iter= 1296
current loss is: 4.0199366 , acc is: 0.0625 , iter= 1297
current loss is: 4.0398397 , acc is: 0.0625 , iter= 1298
current loss is: 4.115617 , acc is: 0.046875 , iter= 1299
current loss is: 4.166422 , acc is: 0.015625 , iter= 1300
current loss is: 4.0987983 , acc is: 0.015625 , iter= 1301
current loss is: 3.9533226 , acc is: 0.0625 , iter= 1302
current loss is: 7.7336197 , acc is: 0.03125 , iter= 1303
current loss is: 4.2228756 , acc is: 0.03125 , iter= 1304
current loss is: 4.024682 , acc is: 0.03125 , iter= 1305
current loss is: 4.016863 , acc is: 0.046875 , iter= 1306
current loss is: 3.962222 , acc is: 0.09375 , iter= 1307
current loss is: 4.069461 , acc is: 0.015625 , iter= 1308
current loss is: 3.8215833 , acc is: 0.09375 , iter= 1309
current loss is: 4.1440144 , acc is: 0.0 , iter= 1310
current loss is: 4.0397463 , acc is: 0.0625 , iter= 1311
current loss is: 4.031278 , acc is: 0.03125 , iter= 1312
current loss is: 4.090228 , acc is: 0.046875 , iter= 1313
current loss is: 3.983148 , acc is: 0.046875 , iter= 1314
current loss is: 4.02958 , acc is: 0.0625 , iter= 1315
current loss is: 3.9784963 , acc is: 0.0625 , iter= 1316
current loss is: 3.9155455 , acc is: 0.109375 , iter= 1317
current loss is: 3.896674 , acc is: 0.078125 , iter= 1318
current loss is: 4.085896 , acc is: 0.015625 , iter= 1319
current loss is: 4.0427766 , acc is: 0.03125 , iter= 1320
current loss is: 4.101112 , acc is: 0.03125 , iter= 1321
current loss is: 7.945932 , acc is: 0.0 , iter= 1322
current loss is: 4.115718 , acc is: 0.046875 , iter= 1323
current loss is: 4.153949 , acc is: 0.015625 , iter= 1324
current loss is: 3.8339856 , acc is: 0.09375 , iter= 1325
current loss is: 4.378128 , acc is: 0.078125 , iter= 1326
current loss is: 4.086806 , acc is: 0.078125 , iter= 1327
current loss is: 3.985222 , acc is: 0.046875 , iter= 1328
current loss is: 4.0200505 , acc is: 0.078125 , iter= 1329
current loss is: 7.272263 , acc is: 0.09375 , iter= 1330
current loss is: 4.083748 , acc is: 0.046875 , iter= 1331
current loss is: 3.9770236 , acc is: 0.046875 , iter= 1332
current loss is: 4.1064277 , acc is: 0.03125 , iter= 1333
current loss is: 4.094369 , acc is: 0.03125 , iter= 1334
current loss is: 5.5599475 , acc is: 0.09375 , iter= 1335
current loss is: 4.069087 , acc is: 0.046875 , iter= 1336
current loss is: 4.0805264 , acc is: 0.015625 , iter= 1337
current loss is: 4.14071 , acc is: 0.046875 , iter= 1338
current loss is: 4.125823 , acc is: 0.03125 , iter= 1339
current loss is: 3.883008 , acc is: 0.09375 , iter= 1340
current loss is: 3.9973366 , acc is: 0.046875 , iter= 1341
current loss is: 3.9822416 , acc is: 0.078125 , iter= 1342
current loss is: 5.080822 , acc is: 0.03125 , iter= 1343
current loss is: 4.10354 , acc is: 0.03125 , iter= 1344
current loss is: 4.1510086 , acc is: 0.015625 , iter= 1345
current loss is: 3.9147213 , acc is: 0.078125 , iter= 1346
current loss is: 4.112892 , acc is: 0.046875 , iter= 1347
current loss is: 3.9006724 , acc is: 0.078125 , iter= 1348
current loss is: 3.9819317 , acc is: 0.0625 , iter= 1349
current loss is: 4.6065345 , acc is: 0.046875 , iter= 1350
current loss is: 4.134839 , acc is: 0.015625 , iter= 1351
current loss is: 4.108424 , acc is: 0.046875 , iter= 1352
current loss is: 3.9338384 , acc is: 0.0625 , iter= 1353
current loss is: 4.1733174 , acc is: 0.046875 , iter= 1354
current loss is: 4.09497 , acc is: 0.0625 , iter= 1355
current loss is: 4.139362 , acc is: 0.046875 , iter= 1356
current loss is: 3.9938347 , acc is: 0.0625 , iter= 1357
current loss is: 4.005651 , acc is: 0.0625 , iter= 1358
current loss is: 3.9965053 , acc is: 0.03125 , iter= 1359
current loss is: 3.9374323 , acc is: 0.0625 , iter= 1360
current loss is: 4.15963 , acc is: 0.015625 , iter= 1361
current loss is: 3.9209719 , acc is: 0.0625 , iter= 1362
current loss is: 4.112175 , acc is: 0.015625 , iter= 1363
current loss is: 4.363056 , acc is: 0.125 , iter= 1364
current loss is: 4.121321 , acc is: 0.015625 , iter= 1365
current loss is: 4.0196567 , acc is: 0.0625 , iter= 1366
current loss is: 4.1325154 , acc is: 0.0625 , iter= 1367
current loss is: 3.9356577 , acc is: 0.09375 , iter= 1368
current loss is: 4.043437 , acc is: 0.03125 , iter= 1369
current loss is: 4.0184116 , acc is: 0.03125 , iter= 1370
current loss is: 4.0282555 , acc is: 0.046875 , iter= 1371
current loss is: 4.005618 , acc is: 0.046875 , iter= 1372
current loss is: 3.9139218 , acc is: 0.0625 , iter= 1373
current loss is: 4.0414166 , acc is: 0.078125 , iter= 1374
current loss is: 4.2214546 , acc is: 0.03125 , iter= 1375
current loss is: 4.040911 , acc is: 0.046875 , iter= 1376
current loss is: 5.0276117 , acc is: 0.046875 , iter= 1377
current loss is: 3.9287884 , acc is: 0.125 , iter= 1378
current loss is: 3.9937036 , acc is: 0.0625 , iter= 1379
current loss is: 4.2056465 , acc is: 0.078125 , iter= 1380
current loss is: 4.189804 , acc is: 0.046875 , iter= 1381
current loss is: 4.064171 , acc is: 0.03125 , iter= 1382
current loss is: 4.220194 , acc is: 0.015625 , iter= 1383
current loss is: 4.0490003 , acc is: 0.0625 , iter= 1384
current loss is: 4.2304993 , acc is: 0.0 , iter= 1385
current loss is: 3.977772 , acc is: 0.0625 , iter= 1386
current loss is: 4.172061 , acc is: 0.078125 , iter= 1387
current loss is: 3.9880967 , acc is: 0.046875 , iter= 1388
current loss is: 3.979333 , acc is: 0.078125 , iter= 1389
current loss is: 4.149917 , acc is: 0.03125 , iter= 1390
current loss is: 4.2647095 , acc is: 0.015625 , iter= 1391
current loss is: 4.2318444 , acc is: 0.078125 , iter= 1392
current loss is: 4.232095 , acc is: 0.015625 , iter= 1393
current loss is: 3.8941717 , acc is: 0.0625 , iter= 1394
current loss is: 4.019101 , acc is: 0.03125 , iter= 1395
current loss is: 4.985282 , acc is: 0.046875 , iter= 1396
current loss is: 4.2254996 , acc is: 0.015625 , iter= 1397
current loss is: 3.9828486 , acc is: 0.078125 , iter= 1398
current loss is: 4.117148 , acc is: 0.03125 , iter= 1399
current loss is: 4.152491 , acc is: 0.0 , iter= 1400
current loss is: 4.043645 , acc is: 0.078125 , iter= 1401
current loss is: 4.448426 , acc is: 0.03125 , iter= 1402
current loss is: 3.9217715 , acc is: 0.0625 , iter= 1403
current loss is: 5.0203075 , acc is: 0.078125 , iter= 1404
current loss is: 4.073476 , acc is: 0.0625 , iter= 1405
current loss is: 4.1241064 , acc is: 0.046875 , iter= 1406
current loss is: 4.673894 , acc is: 0.0625 , iter= 1407
current loss is: 3.9862738 , acc is: 0.046875 , iter= 1408
current loss is: 4.016895 , acc is: 0.03125 , iter= 1409
current loss is: 4.0299363 , acc is: 0.046875 , iter= 1410
current loss is: 4.000577 , acc is: 0.046875 , iter= 1411
current loss is: 4.0873885 , acc is: 0.03125 , iter= 1412
current loss is: 5.6121407 , acc is: 0.03125 , iter= 1413
current loss is: 4.7776623 , acc is: 0.046875 , iter= 1414
current loss is: 3.969235 , acc is: 0.078125 , iter= 1415
current loss is: 4.0617437 , acc is: 0.046875 , iter= 1416
current loss is: 4.0864315 , acc is: 0.046875 , iter= 1417
current loss is: 3.8531375 , acc is: 0.0625 , iter= 1418
current loss is: 4.0943375 , acc is: 0.03125 , iter= 1419
current loss is: 3.8943915 , acc is: 0.0625 , iter= 1420
current loss is: 4.2209997 , acc is: 0.0 , iter= 1421
current loss is: 3.8910835 , acc is: 0.0625 , iter= 1422
current loss is: 3.9988828 , acc is: 0.09375 , iter= 1423
current loss is: 4.213318 , acc is: 0.015625 , iter= 1424
current loss is: 4.021576 , acc is: 0.0625 , iter= 1425
current loss is: 3.798182 , acc is: 0.125 , iter= 1426
current loss is: 5.435983 , acc is: 0.03125 , iter= 1427
current loss is: 4.0070252 , acc is: 0.078125 , iter= 1428
current loss is: 4.0563126 , acc is: 0.03125 , iter= 1429
current loss is: 4.1845226 , acc is: 0.015625 , iter= 1430
current loss is: 4.1128445 , acc is: 0.03125 , iter= 1431
current loss is: 4.140634 , acc is: 0.0625 , iter= 1432
current loss is: 4.187766 , acc is: 0.03125 , iter= 1433
current loss is: 5.293976 , acc is: 0.078125 , iter= 1434
current loss is: 3.968322 , acc is: 0.09375 , iter= 1435
current loss is: 5.181859 , acc is: 0.0625 , iter= 1436
current loss is: 4.1526327 , acc is: 0.015625 , iter= 1437
current loss is: 3.8957014 , acc is: 0.078125 , iter= 1438
current loss is: 4.1724997 , acc is: 0.046875 , iter= 1439
current loss is: 4.071239 , acc is: 0.03125 , iter= 1440
current loss is: 3.9021513 , acc is: 0.0625 , iter= 1441
current loss is: 4.1252613 , acc is: 0.015625 , iter= 1442
current loss is: 4.059145 , acc is: 0.0625 , iter= 1443
current loss is: 4.0579395 , acc is: 0.046875 , iter= 1444
current loss is: 4.957809 , acc is: 0.03125 , iter= 1445
current loss is: 4.128981 , acc is: 0.03125 , iter= 1446
current loss is: 4.0467777 , acc is: 0.03125 , iter= 1447
current loss is: 3.9887333 , acc is: 0.0625 , iter= 1448
current loss is: 4.1257157 , acc is: 0.03125 , iter= 1449
current loss is: 5.0408792 , acc is: 0.03125 , iter= 1450
current loss is: 4.1454744 , acc is: 0.03125 , iter= 1451
current loss is: 3.9325194 , acc is: 0.0625 , iter= 1452
current loss is: 4.679898 , acc is: 0.0625 , iter= 1453
current loss is: 4.112012 , acc is: 0.015625 , iter= 1454
current loss is: 4.010665 , acc is: 0.125 , iter= 1455
current loss is: 4.0251045 , acc is: 0.0625 , iter= 1456
current loss is: 4.1443586 , acc is: 0.046875 , iter= 1457
current loss is: 4.1275597 , acc is: 0.015625 , iter= 1458
current loss is: 4.0921082 , acc is: 0.03125 , iter= 1459
current loss is: 4.1409235 , acc is: 0.046875 , iter= 1460
current loss is: 4.326054 , acc is: 0.03125 , iter= 1461
current loss is: 6.921901 , acc is: 0.0625 , iter= 1462
current loss is: 4.0623474 , acc is: 0.0625 , iter= 1463
current loss is: 4.0970693 , acc is: 0.015625 , iter= 1464
current loss is: 4.076021 , acc is: 0.0625 , iter= 1465
current loss is: 4.001239 , acc is: 0.03125 , iter= 1466
current loss is: 4.123259 , acc is: 0.046875 , iter= 1467
current loss is: 4.107342 , acc is: 0.015625 , iter= 1468
current loss is: 3.9966135 , acc is: 0.0625 , iter= 1469
current loss is: 4.0913134 , acc is: 0.03125 , iter= 1470
current loss is: 3.9998984 , acc is: 0.0625 , iter= 1471
current loss is: 4.117872 , acc is: 0.0625 , iter= 1472
current loss is: 4.0364428 , acc is: 0.03125 , iter= 1473
current loss is: 4.2423677 , acc is: 0.015625 , iter= 1474
current loss is: 4.100979 , acc is: 0.0625 , iter= 1475
current loss is: 4.034078 , acc is: 0.03125 , iter= 1476
current loss is: 3.9409716 , acc is: 0.0625 , iter= 1477
current loss is: 4.0120378 , acc is: 0.03125 , iter= 1478
current loss is: 4.0176506 , acc is: 0.046875 , iter= 1479
current loss is: 4.055051 , acc is: 0.03125 , iter= 1480
current loss is: 4.079376 , acc is: 0.0625 , iter= 1481
current loss is: 3.9195104 , acc is: 0.109375 , iter= 1482
current loss is: 4.065412 , acc is: 0.046875 , iter= 1483
current loss is: 3.9377174 , acc is: 0.0625 , iter= 1484
current loss is: 4.119279 , acc is: 0.0625 , iter= 1485
current loss is: 3.9468756 , acc is: 0.046875 , iter= 1486
current loss is: 5.308688 , acc is: 0.046875 , iter= 1487
current loss is: 4.069469 , acc is: 0.03125 , iter= 1488
current loss is: 4.1188717 , acc is: 0.046875 , iter= 1489
current loss is: 4.295485 , acc is: 0.015625 , iter= 1490
current loss is: 4.359013 , acc is: 0.09375 , iter= 1491
current loss is: 4.1785536 , acc is: 0.0 , iter= 1492
current loss is: 4.0193954 , acc is: 0.0625 , iter= 1493
current loss is: 3.9765718 , acc is: 0.0625 , iter= 1494
current loss is: 4.0674496 , acc is: 0.0625 , iter= 1495
current loss is: 3.7597964 , acc is: 0.09375 , iter= 1496
current loss is: 3.9909418 , acc is: 0.03125 , iter= 1497
current loss is: 4.6594934 , acc is: 0.09375 , iter= 1498
current loss is: 3.9216907 , acc is: 0.078125 , iter= 1499
current loss is: 3.9720817 , acc is: 0.0625 , iter= 1500
current loss is: 3.9171712 , acc is: 0.078125 , iter= 1501
current loss is: 3.962161 , acc is: 0.078125 , iter= 1502
current loss is: 4.3990383 , acc is: 0.046875 , iter= 1503
current loss is: 3.9073086 , acc is: 0.078125 , iter= 1504
current loss is: 4.2148323 , acc is: 0.046875 , iter= 1505
current loss is: 3.9887607 , acc is: 0.0625 , iter= 1506
current loss is: 4.035776 , acc is: 0.09375 , iter= 1507
current loss is: 4.1193204 , acc is: 0.03125 , iter= 1508
current loss is: 4.0171337 , acc is: 0.078125 , iter= 1509
current loss is: 4.113904 , acc is: 0.03125 , iter= 1510
current loss is: 4.0930014 , acc is: 0.046875 , iter= 1511
current loss is: 4.0114026 , acc is: 0.09375 , iter= 1512
current loss is: 5.230116 , acc is: 0.046875 , iter= 1513
current loss is: 4.1033134 , acc is: 0.046875 , iter= 1514
current loss is: 5.0696836 , acc is: 0.03125 , iter= 1515
current loss is: 3.8638077 , acc is: 0.109375 , iter= 1516
current loss is: 4.017627 , acc is: 0.046875 , iter= 1517
current loss is: 4.0073233 , acc is: 0.046875 , iter= 1518
current loss is: 3.8757524 , acc is: 0.0625 , iter= 1519
current loss is: 4.022147 , acc is: 0.078125 , iter= 1520
current loss is: 4.159622 , acc is: 0.03125 , iter= 1521
current loss is: 4.788447 , acc is: 0.046875 , iter= 1522
current loss is: 3.9117224 , acc is: 0.0625 , iter= 1523
current loss is: 3.9208567 , acc is: 0.0625 , iter= 1524
current loss is: 3.9342508 , acc is: 0.046875 , iter= 1525
current loss is: 4.226515 , acc is: 0.03125 , iter= 1526
current loss is: 4.130344 , acc is: 0.015625 , iter= 1527
current loss is: 4.12925 , acc is: 0.046875 , iter= 1528
current loss is: 4.01146 , acc is: 0.046875 , iter= 1529
current loss is: 3.992227 , acc is: 0.046875 , iter= 1530
current loss is: 4.085413 , acc is: 0.015625 , iter= 1531
current loss is: 3.90525 , acc is: 0.078125 , iter= 1532
current loss is: 4.1177816 , acc is: 0.015625 , iter= 1533
current loss is: 4.109378 , acc is: 0.03125 , iter= 1534
current loss is: 4.1078625 , acc is: 0.046875 , iter= 1535
current loss is: 4.1903367 , acc is: 0.03125 , iter= 1536
current loss is: 4.1577234 , acc is: 0.015625 , iter= 1537
current loss is: 3.8732598 , acc is: 0.078125 , iter= 1538
current loss is: 6.764459 , acc is: 0.03125 , iter= 1539
current loss is: 4.163762 , acc is: 0.015625 , iter= 1540
current loss is: 4.016716 , acc is: 0.03125 , iter= 1541
current loss is: 4.132429 , acc is: 0.03125 , iter= 1542
current loss is: 3.945147 , acc is: 0.078125 , iter= 1543
current loss is: 4.0941987 , acc is: 0.03125 , iter= 1544
current loss is: 4.1433473 , acc is: 0.03125 , iter= 1545
current loss is: 4.072192 , acc is: 0.0625 , iter= 1546
current loss is: 4.0268493 , acc is: 0.078125 , iter= 1547
current loss is: 4.7215204 , acc is: 0.03125 , iter= 1548
current loss is: 4.192658 , acc is: 0.046875 , iter= 1549
current loss is: 3.9221535 , acc is: 0.0625 , iter= 1550
current loss is: 4.0507455 , acc is: 0.03125 , iter= 1551
current loss is: 3.9740882 , acc is: 0.078125 , iter= 1552
current loss is: 4.1381474 , acc is: 0.03125 , iter= 1553
current loss is: 4.053071 , acc is: 0.0625 , iter= 1554
current loss is: 3.9879265 , acc is: 0.0625 , iter= 1555
current loss is: 3.896244 , acc is: 0.078125 , iter= 1556
current loss is: 4.166648 , acc is: 0.0 , iter= 1557
current loss is: 4.0559077 , acc is: 0.03125 , iter= 1558
current loss is: 4.070545 , acc is: 0.015625 , iter= 1559
current loss is: 3.861121 , acc is: 0.125 , iter= 1560
current loss is: 3.9561305 , acc is: 0.078125 , iter= 1561
current loss is: 3.9109302 , acc is: 0.0625 , iter= 1562
current loss is: 3.9119592 , acc is: 0.046875 , iter= 1563
current loss is: 4.008556 , acc is: 0.046875 , iter= 1564
current loss is: 4.0087967 , acc is: 0.0625 , iter= 1565
current loss is: 4.0852523 , acc is: 0.046875 , iter= 1566
current loss is: 3.9840503 , acc is: 0.078125 , iter= 1567
current loss is: 3.976389 , acc is: 0.046875 , iter= 1568
current loss is: 4.0451713 , acc is: 0.03125 , iter= 1569
current loss is: 4.074549 , acc is: 0.015625 , iter= 1570
current loss is: 3.8719568 , acc is: 0.046875 , iter= 1571
current loss is: 4.028145 , acc is: 0.0625 , iter= 1572
current loss is: 3.8947606 , acc is: 0.125 , iter= 1573
current loss is: 4.629327 , acc is: 0.0625 , iter= 1574
current loss is: 4.071258 , acc is: 0.03125 , iter= 1575
current loss is: 4.992257 , acc is: 0.03125 , iter= 1576
current loss is: 4.092676 , acc is: 0.046875 , iter= 1577
current loss is: 4.0039525 , acc is: 0.0625 , iter= 1578
current loss is: 4.1292186 , acc is: 0.015625 , iter= 1579
current loss is: 4.1081004 , acc is: 0.046875 , iter= 1580
current loss is: 3.9499931 , acc is: 0.09375 , iter= 1581
current loss is: 4.152462 , acc is: 0.0 , iter= 1582
current loss is: 4.8039823 , acc is: 0.0625 , iter= 1583
current loss is: 3.951251 , acc is: 0.046875 , iter= 1584
current loss is: 4.5702934 , acc is: 0.046875 , iter= 1585
current loss is: 4.1989193 , acc is: 0.03125 , iter= 1586
current loss is: 4.065504 , acc is: 0.015625 , iter= 1587
current loss is: 4.171633 , acc is: 0.03125 , iter= 1588
current loss is: 3.9911838 , acc is: 0.03125 , iter= 1589
current loss is: 3.857677 , acc is: 0.078125 , iter= 1590
current loss is: 4.093896 , acc is: 0.046875 , iter= 1591
current loss is: 4.0770473 , acc is: 0.078125 , iter= 1592
current loss is: 3.8845277 , acc is: 0.078125 , iter= 1593
current loss is: 4.1061115 , acc is: 0.0625 , iter= 1594
current loss is: 3.9065762 , acc is: 0.078125 , iter= 1595
current loss is: 4.103944 , acc is: 0.03125 , iter= 1596
current loss is: 4.1603723 , acc is: 0.0 , iter= 1597
current loss is: 4.000559 , acc is: 0.046875 , iter= 1598
current loss is: 4.1071196 , acc is: 0.0625 , iter= 1599
current loss is: 3.9836426 , acc is: 0.03125 , iter= 1600
current loss is: 3.9708426 , acc is: 0.09375 , iter= 1601
current loss is: 4.188993 , acc is: 0.0 , iter= 1602
current loss is: 3.8387084 , acc is: 0.09375 , iter= 1603
current loss is: 3.8845382 , acc is: 0.09375 , iter= 1604
current loss is: 3.995212 , acc is: 0.0625 , iter= 1605
current loss is: 4.0254292 , acc is: 0.046875 , iter= 1606
current loss is: 3.9972 , acc is: 0.0625 , iter= 1607
current loss is: 4.0149684 , acc is: 0.03125 , iter= 1608
current loss is: 4.1928844 , acc is: 0.0625 , iter= 1609
current loss is: 4.172493 , acc is: 0.03125 , iter= 1610
current loss is: 4.1789303 , acc is: 0.0 , iter= 1611
current loss is: 4.07016 , acc is: 0.03125 , iter= 1612
current loss is: 3.9495537 , acc is: 0.078125 , iter= 1613
current loss is: 3.9475508 , acc is: 0.0625 , iter= 1614
current loss is: 4.0093303 , acc is: 0.046875 , iter= 1615
current loss is: 4.0346103 , acc is: 0.046875 , iter= 1616
current loss is: 3.858561 , acc is: 0.109375 , iter= 1617
current loss is: 4.492669 , acc is: 0.046875 , iter= 1618
current loss is: 4.2432737 , acc is: 0.0 , iter= 1619
current loss is: 4.070161 , acc is: 0.046875 , iter= 1620
current loss is: 3.8654957 , acc is: 0.09375 , iter= 1621
current loss is: 4.144418 , acc is: 0.03125 , iter= 1622
current loss is: 3.9631884 , acc is: 0.046875 , iter= 1623
current loss is: 4.01851 , acc is: 0.046875 , iter= 1624
current loss is: 4.388645 , acc is: 0.078125 , iter= 1625
current loss is: 3.8362377 , acc is: 0.09375 , iter= 1626
current loss is: 4.129073 , acc is: 0.03125 , iter= 1627
current loss is: 4.1130447 , acc is: 0.046875 , iter= 1628
current loss is: 4.0825434 , acc is: 0.078125 , iter= 1629
current loss is: 3.8771768 , acc is: 0.125 , iter= 1630
current loss is: 4.0741887 , acc is: 0.046875 , iter= 1631
current loss is: 4.116335 , acc is: 0.015625 , iter= 1632
current loss is: 4.0381994 , acc is: 0.03125 , iter= 1633
current loss is: 3.9568596 , acc is: 0.078125 , iter= 1634
current loss is: 4.1035004 , acc is: 0.03125 , iter= 1635
current loss is: 3.9678643 , acc is: 0.078125 , iter= 1636
current loss is: 4.015728 , acc is: 0.03125 , iter= 1637
current loss is: 6.55524 , acc is: 0.09375 , iter= 1638
current loss is: 4.097619 , acc is: 0.046875 , iter= 1639
current loss is: 4.1393623 , acc is: 0.046875 , iter= 1640
current loss is: 4.0123773 , acc is: 0.046875 , iter= 1641
current loss is: 4.0595074 , acc is: 0.046875 , iter= 1642
current loss is: 3.9350657 , acc is: 0.0625 , iter= 1643
current loss is: 4.2531643 , acc is: 0.03125 , iter= 1644
current loss is: 3.972734 , acc is: 0.0625 , iter= 1645
current loss is: 4.156963 , acc is: 0.0 , iter= 1646
current loss is: 4.098816 , acc is: 0.0 , iter= 1647
current loss is: 3.9609838 , acc is: 0.09375 , iter= 1648
current loss is: 4.1265826 , acc is: 0.015625 , iter= 1649
current loss is: 4.3604174 , acc is: 0.03125 , iter= 1650
current loss is: 3.9970202 , acc is: 0.0625 , iter= 1651
current loss is: 4.035556 , acc is: 0.03125 , iter= 1652
current loss is: 4.1352196 , acc is: 0.03125 , iter= 1653
current loss is: 4.114163 , acc is: 0.015625 , iter= 1654
current loss is: 3.8918793 , acc is: 0.078125 , iter= 1655
current loss is: 4.079104 , acc is: 0.015625 , iter= 1656
current loss is: 4.4839354 , acc is: 0.015625 , iter= 1657
current loss is: 4.1679335 , acc is: 0.015625 , iter= 1658
current loss is: 4.1235867 , acc is: 0.015625 , iter= 1659
current loss is: 4.015044 , acc is: 0.03125 , iter= 1660
current loss is: 4.115307 , acc is: 0.046875 , iter= 1661
current loss is: 4.161782 , acc is: 0.0 , iter= 1662
current loss is: 4.643751 , acc is: 0.046875 , iter= 1663
current loss is: 3.7311296 , acc is: 0.109375 , iter= 1664
current loss is: 3.977626 , acc is: 0.0625 , iter= 1665
current loss is: 3.9936807 , acc is: 0.078125 , iter= 1666
current loss is: 3.8630064 , acc is: 0.078125 , iter= 1667
current loss is: 4.0771837 , acc is: 0.03125 , iter= 1668
current loss is: 3.9551528 , acc is: 0.078125 , iter= 1669
current loss is: 3.8708603 , acc is: 0.109375 , iter= 1670
current loss is: 4.14014 , acc is: 0.078125 , iter= 1671
current loss is: 4.0444975 , acc is: 0.03125 , iter= 1672
current loss is: 4.2040343 , acc is: 0.015625 , iter= 1673
current loss is: 3.94863 , acc is: 0.046875 , iter= 1674
current loss is: 4.0846157 , acc is: 0.03125 , iter= 1675
current loss is: 4.191414 , acc is: 0.0 , iter= 1676
current loss is: 4.1118298 , acc is: 0.03125 , iter= 1677
current loss is: 3.937044 , acc is: 0.078125 , iter= 1678
current loss is: 3.9325519 , acc is: 0.0625 , iter= 1679
current loss is: 4.1193247 , acc is: 0.046875 , iter= 1680
current loss is: 4.0979705 , acc is: 0.015625 , iter= 1681
current loss is: 4.9761133 , acc is: 0.0625 , iter= 1682
current loss is: 4.032898 , acc is: 0.09375 , iter= 1683
current loss is: 4.1062355 , acc is: 0.03125 , iter= 1684
current loss is: 4.0332065 , acc is: 0.046875 , iter= 1685
current loss is: 3.8828855 , acc is: 0.0625 , iter= 1686
current loss is: 3.9739602 , acc is: 0.046875 , iter= 1687
current loss is: 4.119832 , acc is: 0.015625 , iter= 1688
current loss is: 4.0672836 , acc is: 0.046875 , iter= 1689
current loss is: 4.149334 , acc is: 0.0 , iter= 1690
current loss is: 4.1061325 , acc is: 0.015625 , iter= 1691
current loss is: 3.8297727 , acc is: 0.09375 , iter= 1692
current loss is: 4.589244 , acc is: 0.078125 , iter= 1693
current loss is: 3.8887882 , acc is: 0.09375 , iter= 1694
current loss is: 6.2893643 , acc is: 0.078125 , iter= 1695
current loss is: 4.169196 , acc is: 0.03125 , iter= 1696
current loss is: 3.9974947 , acc is: 0.09375 , iter= 1697
current loss is: 3.8785427 , acc is: 0.109375 , iter= 1698
current loss is: 4.1668506 , acc is: 0.03125 , iter= 1699
current loss is: 3.8836737 , acc is: 0.078125 , iter= 1700
current loss is: 3.9699066 , acc is: 0.078125 , iter= 1701
current loss is: 4.1559935 , acc is: 0.03125 , iter= 1702
current loss is: 4.0762568 , acc is: 0.0625 , iter= 1703
current loss is: 4.0643935 , acc is: 0.0625 , iter= 1704
current loss is: 3.901833 , acc is: 0.078125 , iter= 1705
current loss is: 4.0674944 , acc is: 0.046875 , iter= 1706
current loss is: 3.9253993 , acc is: 0.09375 , iter= 1707
current loss is: 3.9275563 , acc is: 0.09375 , iter= 1708
current loss is: 3.8268697 , acc is: 0.109375 , iter= 1709
current loss is: 5.829855 , acc is: 0.0625 , iter= 1710
current loss is: 4.0457807 , acc is: 0.0625 , iter= 1711
current loss is: 4.8674006 , acc is: 0.0625 , iter= 1712
current loss is: 4.0860987 , acc is: 0.046875 , iter= 1713
current loss is: 4.0395627 , acc is: 0.0625 , iter= 1714
current loss is: 3.9774127 , acc is: 0.03125 , iter= 1715
current loss is: 3.958696 , acc is: 0.078125 , iter= 1716
current loss is: 4.0945845 , acc is: 0.03125 , iter= 1717
current loss is: 4.1613283 , acc is: 0.015625 , iter= 1718
current loss is: 3.9826179 , acc is: 0.0625 , iter= 1719
current loss is: 3.9719803 , acc is: 0.0625 , iter= 1720
current loss is: 3.9661674 , acc is: 0.046875 , iter= 1721
current loss is: 4.115182 , acc is: 0.0625 , iter= 1722
current loss is: 4.1614933 , acc is: 0.0625 , iter= 1723
current loss is: 4.1018724 , acc is: 0.03125 , iter= 1724
current loss is: 3.8287244 , acc is: 0.078125 , iter= 1725
current loss is: 4.067714 , acc is: 0.03125 , iter= 1726
current loss is: 4.0674 , acc is: 0.015625 , iter= 1727
current loss is: 4.0321155 , acc is: 0.03125 , iter= 1728
current loss is: 3.9977903 , acc is: 0.046875 , iter= 1729
current loss is: 3.9646676 , acc is: 0.0625 , iter= 1730
current loss is: 4.074419 , acc is: 0.109375 , iter= 1731
current loss is: 3.9331255 , acc is: 0.046875 , iter= 1732
current loss is: 4.023174 , acc is: 0.046875 , iter= 1733
current loss is: 4.051443 , acc is: 0.046875 , iter= 1734
current loss is: 3.9682522 , acc is: 0.078125 , iter= 1735
current loss is: 4.114173 , acc is: 0.046875 , iter= 1736
current loss is: 4.2678075 , acc is: 0.046875 , iter= 1737
current loss is: 3.9163601 , acc is: 0.046875 , iter= 1738
current loss is: 4.017441 , acc is: 0.03125 , iter= 1739
current loss is: 4.057988 , acc is: 0.03125 , iter= 1740
current loss is: 4.015445 , acc is: 0.078125 , iter= 1741
current loss is: 4.0924664 , acc is: 0.046875 , iter= 1742
current loss is: 4.068958 , acc is: 0.03125 , iter= 1743
current loss is: 4.113948 , acc is: 0.0625 , iter= 1744
current loss is: 4.1228867 , acc is: 0.015625 , iter= 1745
current loss is: 3.962996 , acc is: 0.0625 , iter= 1746
current loss is: 4.0983844 , acc is: 0.046875 , iter= 1747
current loss is: 3.9602528 , acc is: 0.046875 , iter= 1748
current loss is: 3.9821033 , acc is: 0.09375 , iter= 1749
current loss is: 4.0183563 , acc is: 0.0625 , iter= 1750
current loss is: 4.0562983 , acc is: 0.0625 , iter= 1751
current loss is: 3.8875632 , acc is: 0.109375 , iter= 1752
current loss is: 4.080951 , acc is: 0.015625 , iter= 1753
current loss is: 3.946664 , acc is: 0.046875 , iter= 1754
current loss is: 4.0483847 , acc is: 0.046875 , iter= 1755
current loss is: 3.9299812 , acc is: 0.078125 , iter= 1756
current loss is: 4.2564855 , acc is: 0.078125 , iter= 1757
current loss is: 3.8473754 , acc is: 0.09375 , iter= 1758
current loss is: 4.138571 , acc is: 0.015625 , iter= 1759
current loss is: 4.002049 , acc is: 0.046875 , iter= 1760
current loss is: 4.0284123 , acc is: 0.046875 , iter= 1761
current loss is: 3.9542375 , acc is: 0.0625 , iter= 1762
current loss is: 4.1638193 , acc is: 0.015625 , iter= 1763
current loss is: 4.176279 , acc is: 0.046875 , iter= 1764
current loss is: 4.096242 , acc is: 0.03125 , iter= 1765
current loss is: 4.0910654 , acc is: 0.03125 , iter= 1766
current loss is: 4.00859 , acc is: 0.046875 , iter= 1767
current loss is: 3.883954 , acc is: 0.09375 , iter= 1768
current loss is: 4.025467 , acc is: 0.078125 , iter= 1769
current loss is: 4.0736313 , acc is: 0.03125 , iter= 1770
current loss is: 4.000827 , acc is: 0.03125 , iter= 1771
current loss is: 4.146868 , acc is: 0.03125 , iter= 1772
current loss is: 4.097597 , acc is: 0.0625 , iter= 1773
current loss is: 4.003331 , acc is: 0.0625 , iter= 1774
current loss is: 3.9923923 , acc is: 0.046875 , iter= 1775
current loss is: 4.0496054 , acc is: 0.03125 , iter= 1776
current loss is: 4.023528 , acc is: 0.03125 , iter= 1777
current loss is: 4.0263586 , acc is: 0.046875 , iter= 1778
current loss is: 3.8679967 , acc is: 0.125 , iter= 1779
current loss is: 3.9473267 , acc is: 0.09375 , iter= 1780
current loss is: 4.1477985 , acc is: 0.03125 , iter= 1781
current loss is: 4.143241 , acc is: 0.03125 , iter= 1782
current loss is: 3.9745634 , acc is: 0.09375 , iter= 1783
current loss is: 4.1064773 , acc is: 0.03125 , iter= 1784
current loss is: 4.3913555 , acc is: 0.03125 , iter= 1785
current loss is: 4.831726 , acc is: 0.03125 , iter= 1786
current loss is: 3.9013994 , acc is: 0.078125 , iter= 1787
current loss is: 5.816322 , acc is: 0.03125 , iter= 1788
current loss is: 3.9239197 , acc is: 0.0625 , iter= 1789
current loss is: 4.028722 , acc is: 0.03125 , iter= 1790
current loss is: 4.020869 , acc is: 0.0625 , iter= 1791
current loss is: 4.0652742 , acc is: 0.03125 , iter= 1792
current loss is: 4.025154 , acc is: 0.0625 , iter= 1793
current loss is: 4.1245756 , acc is: 0.015625 , iter= 1794
current loss is: 4.039758 , acc is: 0.0625 , iter= 1795
current loss is: 4.1076937 , acc is: 0.046875 , iter= 1796
current loss is: 4.0905495 , acc is: 0.078125 , iter= 1797
current loss is: 4.0086975 , acc is: 0.046875 , iter= 1798
current loss is: 3.9589856 , acc is: 0.078125 , iter= 1799
current loss is: 4.1222944 , acc is: 0.03125 , iter= 1800
current loss is: 4.0211763 , acc is: 0.046875 , iter= 1801
current loss is: 4.713545 , acc is: 0.03125 , iter= 1802
current loss is: 4.0906057 , acc is: 0.03125 , iter= 1803
current loss is: 4.0760474 , acc is: 0.046875 , iter= 1804
current loss is: 3.9479153 , acc is: 0.046875 , iter= 1805
current loss is: 4.123658 , acc is: 0.0 , iter= 1806
current loss is: 4.1107 , acc is: 0.03125 , iter= 1807
current loss is: 4.010529 , acc is: 0.046875 , iter= 1808
current loss is: 3.950769 , acc is: 0.0625 , iter= 1809
current loss is: 4.1986346 , acc is: 0.078125 , iter= 1810
current loss is: 4.113635 , acc is: 0.015625 , iter= 1811
current loss is: 4.3894167 , acc is: 0.03125 , iter= 1812
current loss is: 3.7586634 , acc is: 0.109375 , iter= 1813
current loss is: 4.0926037 , acc is: 0.015625 , iter= 1814
current loss is: 3.8589196 , acc is: 0.078125 , iter= 1815
current loss is: 4.303759 , acc is: 0.015625 , iter= 1816
current loss is: 4.2704415 , acc is: 0.125 , iter= 1817
current loss is: 3.95948 , acc is: 0.078125 , iter= 1818
current loss is: 3.9370885 , acc is: 0.0625 , iter= 1819
current loss is: 4.1571136 , acc is: 0.046875 , iter= 1820
current loss is: 4.3378196 , acc is: 0.0625 , iter= 1821
current loss is: 4.05427 , acc is: 0.046875 , iter= 1822
current loss is: 4.112806 , acc is: 0.046875 , iter= 1823
current loss is: 4.7230453 , acc is: 0.046875 , iter= 1824
current loss is: 3.9280605 , acc is: 0.0625 , iter= 1825
current loss is: 4.38407 , acc is: 0.078125 , iter= 1826
current loss is: 4.1593184 , acc is: 0.015625 , iter= 1827
current loss is: 4.122757 , acc is: 0.03125 , iter= 1828
current loss is: 4.3665 , acc is: 0.046875 , iter= 1829
current loss is: 4.0679092 , acc is: 0.03125 , iter= 1830
current loss is: 4.0178213 , acc is: 0.0625 , iter= 1831
current loss is: 4.1239033 , acc is: 0.046875 , iter= 1832
current loss is: 4.167116 , acc is: 0.03125 , iter= 1833
current loss is: 3.9672585 , acc is: 0.046875 , iter= 1834
current loss is: 7.150937 , acc is: 0.015625 , iter= 1835
current loss is: 4.0449443 , acc is: 0.0625 , iter= 1836
current loss is: 4.542708 , acc is: 0.09375 , iter= 1837
current loss is: 4.021458 , acc is: 0.046875 , iter= 1838
current loss is: 3.9863713 , acc is: 0.0625 , iter= 1839
current loss is: 4.147629 , acc is: 0.046875 , iter= 1840
current loss is: 3.9818773 , acc is: 0.0625 , iter= 1841
current loss is: 4.0026226 , acc is: 0.0625 , iter= 1842
current loss is: 3.9213169 , acc is: 0.078125 , iter= 1843
current loss is: 4.0558896 , acc is: 0.078125 , iter= 1844
current loss is: 3.9670155 , acc is: 0.078125 , iter= 1845
current loss is: 4.1026125 , acc is: 0.03125 , iter= 1846
current loss is: 4.1526346 , acc is: 0.03125 , iter= 1847
current loss is: 4.2149067 , acc is: 0.125 , iter= 1848
current loss is: 3.906763 , acc is: 0.09375 , iter= 1849
current loss is: 4.0547576 , acc is: 0.03125 , iter= 1850
current loss is: 3.992527 , acc is: 0.046875 , iter= 1851
current loss is: 4.033369 , acc is: 0.015625 , iter= 1852
current loss is: 3.9369326 , acc is: 0.09375 , iter= 1853
current loss is: 4.0016317 , acc is: 0.046875 , iter= 1854
current loss is: 3.999188 , acc is: 0.046875 , iter= 1855
current loss is: 4.169592 , acc is: 0.0 , iter= 1856
current loss is: 4.070301 , acc is: 0.046875 , iter= 1857
current loss is: 3.9885201 , acc is: 0.0625 , iter= 1858
current loss is: 4.0472918 , acc is: 0.109375 , iter= 1859
current loss is: 4.000573 , acc is: 0.046875 , iter= 1860
current loss is: 4.103054 , acc is: 0.015625 , iter= 1861
current loss is: 4.1551948 , acc is: 0.015625 , iter= 1862
current loss is: 4.0286193 , acc is: 0.109375 , iter= 1863
current loss is: 4.1041365 , acc is: 0.015625 , iter= 1864
current loss is: 4.0926085 , acc is: 0.03125 , iter= 1865
current loss is: 4.1088514 , acc is: 0.015625 , iter= 1866
current loss is: 4.0152946 , acc is: 0.078125 , iter= 1867
current loss is: 4.095792 , acc is: 0.015625 , iter= 1868
current loss is: 4.0393543 , acc is: 0.03125 , iter= 1869
current loss is: 4.028945 , acc is: 0.03125 , iter= 1870
current loss is: 4.024931 , acc is: 0.078125 , iter= 1871
current loss is: 4.2378874 , acc is: 0.015625 , iter= 1872
current loss is: 4.187292 , acc is: 0.0 , iter= 1873
current loss is: 4.374285 , acc is: 0.03125 , iter= 1874
current loss is: 4.0221744 , acc is: 0.09375 , iter= 1875
current loss is: 3.9898796 , acc is: 0.0625 , iter= 1876
current loss is: 3.8752263 , acc is: 0.09375 , iter= 1877
current loss is: 3.927749 , acc is: 0.078125 , iter= 1878
current loss is: 3.9099655 , acc is: 0.078125 , iter= 1879
current loss is: 4.024157 , acc is: 0.078125 , iter= 1880
current loss is: 4.07192 , acc is: 0.0625 , iter= 1881
current loss is: 4.1069117 , acc is: 0.03125 , iter= 1882
current loss is: 4.0997195 , acc is: 0.015625 , iter= 1883
current loss is: 4.375021 , acc is: 0.078125 , iter= 1884
current loss is: 3.9414089 , acc is: 0.078125 , iter= 1885
current loss is: 4.0602236 , acc is: 0.046875 , iter= 1886
current loss is: 4.1169214 , acc is: 0.0625 , iter= 1887
current loss is: 4.004992 , acc is: 0.03125 , iter= 1888
current loss is: 3.89815 , acc is: 0.078125 , iter= 1889
current loss is: 4.191733 , acc is: 0.015625 , iter= 1890
current loss is: 3.976784 , acc is: 0.0625 , iter= 1891
current loss is: 3.9784951 , acc is: 0.03125 , iter= 1892
current loss is: 3.8824015 , acc is: 0.109375 , iter= 1893
current loss is: 6.1097927 , acc is: 0.125 , iter= 1894
current loss is: 4.0972853 , acc is: 0.03125 , iter= 1895
current loss is: 4.1198545 , acc is: 0.078125 , iter= 1896
current loss is: 4.71917 , acc is: 0.078125 , iter= 1897
current loss is: 4.060215 , acc is: 0.046875 , iter= 1898
current loss is: 3.7667637 , acc is: 0.078125 , iter= 1899
current loss is: 3.96165 , acc is: 0.046875 , iter= 1900
current loss is: 3.9085846 , acc is: 0.078125 , iter= 1901
current loss is: 4.0470343 , acc is: 0.046875 , iter= 1902
current loss is: 3.9448197 , acc is: 0.078125 , iter= 1903
current loss is: 4.0267963 , acc is: 0.046875 , iter= 1904
current loss is: 3.8732326 , acc is: 0.0625 , iter= 1905
current loss is: 3.9857082 , acc is: 0.03125 , iter= 1906
current loss is: 4.0402 , acc is: 0.03125 , iter= 1907
current loss is: 4.1506968 , acc is: 0.046875 , iter= 1908
current loss is: 3.810214 , acc is: 0.109375 , iter= 1909
current loss is: 6.8887434 , acc is: 0.015625 , iter= 1910
current loss is: 3.9542017 , acc is: 0.0625 , iter= 1911
current loss is: 3.9185967 , acc is: 0.09375 , iter= 1912
current loss is: 4.1122627 , acc is: 0.015625 , iter= 1913
current loss is: 4.1413884 , acc is: 0.03125 , iter= 1914
current loss is: 3.8267508 , acc is: 0.15625 , iter= 1915
current loss is: 4.926671 , acc is: 0.046875 , iter= 1916
current loss is: 3.9343212 , acc is: 0.078125 , iter= 1917
current loss is: 4.4741006 , acc is: 0.03125 , iter= 1918
current loss is: 3.9651616 , acc is: 0.078125 , iter= 1919
current loss is: 3.8756616 , acc is: 0.09375 , iter= 1920
current loss is: 4.0840354 , acc is: 0.0 , iter= 1921
current loss is: 4.793191 , acc is: 0.046875 , iter= 1922
current loss is: 4.035593 , acc is: 0.0625 , iter= 1923
current loss is: 4.16301 , acc is: 0.046875 , iter= 1924
current loss is: 4.003956 , acc is: 0.078125 , iter= 1925
current loss is: 4.026678 , acc is: 0.0625 , iter= 1926
current loss is: 6.5474796 , acc is: 0.109375 , iter= 1927
current loss is: 4.011195 , acc is: 0.046875 , iter= 1928
current loss is: 4.048566 , acc is: 0.0625 , iter= 1929
current loss is: 3.9684772 , acc is: 0.046875 , iter= 1930
current loss is: 4.0381966 , acc is: 0.078125 , iter= 1931
current loss is: 4.069599 , acc is: 0.046875 , iter= 1932
current loss is: 5.237067 , acc is: 0.078125 , iter= 1933
current loss is: 4.1574993 , acc is: 0.0 , iter= 1934
current loss is: 4.0550175 , acc is: 0.078125 , iter= 1935
current loss is: 3.9663525 , acc is: 0.0625 , iter= 1936
current loss is: 4.076041 , acc is: 0.015625 , iter= 1937
current loss is: 4.0843067 , acc is: 0.046875 , iter= 1938
current loss is: 5.712858 , acc is: 0.046875 , iter= 1939
current loss is: 4.01124 , acc is: 0.046875 , iter= 1940
current loss is: 4.7994785 , acc is: 0.03125 , iter= 1941
current loss is: 4.1159706 , acc is: 0.0625 , iter= 1942
current loss is: 4.1178718 , acc is: 0.03125 , iter= 1943
current loss is: 4.0720644 , acc is: 0.03125 , iter= 1944
current loss is: 3.942998 , acc is: 0.046875 , iter= 1945
current loss is: 4.0787888 , acc is: 0.03125 , iter= 1946
current loss is: 3.9515352 , acc is: 0.09375 , iter= 1947
current loss is: 4.055434 , acc is: 0.015625 , iter= 1948
current loss is: 3.820791 , acc is: 0.078125 , iter= 1949
current loss is: 4.0945826 , acc is: 0.03125 , iter= 1950
current loss is: 4.0405865 , acc is: 0.0625 , iter= 1951
current loss is: 3.9339933 , acc is: 0.09375 , iter= 1952
current loss is: 4.1904154 , acc is: 0.03125 , iter= 1953
current loss is: 3.886777 , acc is: 0.078125 , iter= 1954
current loss is: 4.0450325 , acc is: 0.046875 , iter= 1955
current loss is: 4.9587374 , acc is: 0.046875 , iter= 1956
current loss is: 3.8314695 , acc is: 0.125 , iter= 1957
current loss is: 3.9616485 , acc is: 0.078125 , iter= 1958
current loss is: 4.009291 , acc is: 0.078125 , iter= 1959
current loss is: 3.9219446 , acc is: 0.0625 , iter= 1960
current loss is: 4.0468144 , acc is: 0.0625 , iter= 1961
current loss is: 4.027129 , acc is: 0.046875 , iter= 1962
current loss is: 4.115294 , acc is: 0.046875 , iter= 1963
current loss is: 4.1582065 , acc is: 0.015625 , iter= 1964
current loss is: 4.1357713 , acc is: 0.0625 , iter= 1965
current loss is: 4.9583097 , acc is: 0.015625 , iter= 1966
current loss is: 4.059486 , acc is: 0.015625 , iter= 1967
current loss is: 3.913336 , acc is: 0.078125 , iter= 1968
current loss is: 3.8613749 , acc is: 0.109375 , iter= 1969
current loss is: 3.9794214 , acc is: 0.046875 , iter= 1970
current loss is: 4.108671 , acc is: 0.03125 , iter= 1971
current loss is: 4.2022896 , acc is: 0.015625 , iter= 1972
current loss is: 4.2111278 , acc is: 0.03125 , iter= 1973
current loss is: 4.1126003 , acc is: 0.015625 , iter= 1974
current loss is: 4.1087923 , acc is: 0.109375 , iter= 1975
current loss is: 4.0957017 , acc is: 0.015625 , iter= 1976
current loss is: 4.0174627 , acc is: 0.0625 , iter= 1977
current loss is: 4.035816 , acc is: 0.046875 , iter= 1978
current loss is: 3.9778628 , acc is: 0.046875 , iter= 1979
current loss is: 4.0438137 , acc is: 0.03125 , iter= 1980
current loss is: 4.0884843 , acc is: 0.015625 , iter= 1981
current loss is: 3.8266687 , acc is: 0.09375 , iter= 1982
current loss is: 3.953493 , acc is: 0.046875 , iter= 1983
current loss is: 3.7894936 , acc is: 0.09375 , iter= 1984
current loss is: 4.0902896 , acc is: 0.046875 , iter= 1985
current loss is: 4.0954256 , acc is: 0.015625 , iter= 1986
current loss is: 3.824665 , acc is: 0.09375 , iter= 1987
current loss is: 3.9589148 , acc is: 0.09375 , iter= 1988
current loss is: 4.039009 , acc is: 0.015625 , iter= 1989
current loss is: 3.9742653 , acc is: 0.0625 , iter= 1990
current loss is: 3.9435964 , acc is: 0.0625 , iter= 1991
current loss is: 4.0064316 , acc is: 0.0625 , iter= 1992
current loss is: 3.9280438 , acc is: 0.0625 , iter= 1993
current loss is: 4.103956 , acc is: 0.015625 , iter= 1994
current loss is: 4.156877 , acc is: 0.0625 , iter= 1995
current loss is: 4.130681 , acc is: 0.03125 , iter= 1996
current loss is: 4.1117563 , acc is: 0.03125 , iter= 1997
current loss is: 4.1020393 , acc is: 0.125 , iter= 1998
current loss is: 4.106079 , acc is: 0.015625 , iter= 1999
current loss is: 4.010365 , acc is: 0.046875 , iter= 2000
tot_acc= 19.0 tot_input= 768
current accuracy is: 0.024739583333333332
current loss is: 4.7753997 , acc is: 0.03125 , iter= 2001
current loss is: 4.0296507 , acc is: 0.03125 , iter= 2002
current loss is: 5.010379 , acc is: 0.0625 , iter= 2003
current loss is: 5.983865 , acc is: 0.0 , iter= 2004
current loss is: 3.970447 , acc is: 0.046875 , iter= 2005
current loss is: 3.8340673 , acc is: 0.125 , iter= 2006
current loss is: 4.021276 , acc is: 0.0625 , iter= 2007
current loss is: 4.0735965 , acc is: 0.0625 , iter= 2008
current loss is: 3.9827235 , acc is: 0.015625 , iter= 2009
current loss is: 4.774955 , acc is: 0.046875 , iter= 2010
current loss is: 4.118366 , acc is: 0.03125 , iter= 2011
current loss is: 4.1519265 , acc is: 0.046875 , iter= 2012
current loss is: 3.9256966 , acc is: 0.09375 , iter= 2013
current loss is: 3.957154 , acc is: 0.046875 , iter= 2014
current loss is: 4.154177 , acc is: 0.0 , iter= 2015
current loss is: 4.038067 , acc is: 0.046875 , iter= 2016
current loss is: 4.1679354 , acc is: 0.046875 , iter= 2017
current loss is: 4.1339955 , acc is: 0.015625 , iter= 2018
current loss is: 3.9699764 , acc is: 0.078125 , iter= 2019
current loss is: 3.8453403 , acc is: 0.09375 , iter= 2020
current loss is: 4.080287 , acc is: 0.03125 , iter= 2021
current loss is: 4.0462947 , acc is: 0.015625 , iter= 2022
current loss is: 4.0544 , acc is: 0.0625 , iter= 2023
current loss is: 4.088658 , acc is: 0.046875 , iter= 2024
current loss is: 4.0842 , acc is: 0.015625 , iter= 2025
current loss is: 3.9024546 , acc is: 0.0625 , iter= 2026
current loss is: 4.0721216 , acc is: 0.0625 , iter= 2027
current loss is: 5.1078854 , acc is: 0.03125 , iter= 2028
current loss is: 3.8626952 , acc is: 0.0625 , iter= 2029
current loss is: 4.052513 , acc is: 0.03125 , iter= 2030
current loss is: 4.131362 , acc is: 0.015625 , iter= 2031
current loss is: 3.9885244 , acc is: 0.046875 , iter= 2032
current loss is: 4.116661 , acc is: 0.046875 , iter= 2033
current loss is: 4.0291348 , acc is: 0.03125 , iter= 2034
current loss is: 4.004714 , acc is: 0.0625 , iter= 2035
current loss is: 4.1449738 , acc is: 0.015625 , iter= 2036
current loss is: 4.1326103 , acc is: 0.0625 , iter= 2037
current loss is: 3.9290662 , acc is: 0.09375 , iter= 2038
current loss is: 3.9559202 , acc is: 0.046875 , iter= 2039
current loss is: 4.160882 , acc is: 0.078125 , iter= 2040
current loss is: 4.1905327 , acc is: 0.03125 , iter= 2041
current loss is: 3.9937875 , acc is: 0.0625 , iter= 2042
current loss is: 4.084637 , acc is: 0.03125 , iter= 2043
current loss is: 4.203042 , acc is: 0.03125 , iter= 2044
current loss is: 3.948529 , acc is: 0.109375 , iter= 2045
current loss is: 4.082014 , acc is: 0.03125 , iter= 2046
current loss is: 3.7571237 , acc is: 0.125 , iter= 2047
current loss is: 3.8610287 , acc is: 0.078125 , iter= 2048
current loss is: 4.0000434 , acc is: 0.0625 , iter= 2049
current loss is: 4.014393 , acc is: 0.0625 , iter= 2050
current loss is: 3.9933379 , acc is: 0.0625 , iter= 2051
current loss is: 3.9951344 , acc is: 0.0625 , iter= 2052
current loss is: 4.033489 , acc is: 0.03125 , iter= 2053
current loss is: 3.9462638 , acc is: 0.0625 , iter= 2054
current loss is: 4.13408 , acc is: 0.03125 , iter= 2055
current loss is: 3.9258828 , acc is: 0.078125 , iter= 2056
current loss is: 3.9656632 , acc is: 0.09375 , iter= 2057
current loss is: 4.078127 , acc is: 0.0625 , iter= 2058
current loss is: 3.961963 , acc is: 0.046875 , iter= 2059
current loss is: 3.8607388 , acc is: 0.078125 , iter= 2060
current loss is: 3.8827765 , acc is: 0.09375 , iter= 2061
current loss is: 4.04018 , acc is: 0.046875 , iter= 2062
current loss is: 4.2769012 , acc is: 0.0 , iter= 2063
current loss is: 3.9710913 , acc is: 0.046875 , iter= 2064
current loss is: 3.9130168 , acc is: 0.078125 , iter= 2065
current loss is: 3.931377 , acc is: 0.09375 , iter= 2066
current loss is: 3.9672556 , acc is: 0.0625 , iter= 2067
current loss is: 4.0421515 , acc is: 0.046875 , iter= 2068
current loss is: 4.0671515 , acc is: 0.015625 , iter= 2069
current loss is: 4.0561504 , acc is: 0.015625 , iter= 2070
current loss is: 4.042942 , acc is: 0.03125 , iter= 2071
current loss is: 4.0570326 , acc is: 0.03125 , iter= 2072
current loss is: 3.9532652 , acc is: 0.046875 , iter= 2073
current loss is: 3.8643446 , acc is: 0.078125 , iter= 2074
current loss is: 3.8730617 , acc is: 0.078125 , iter= 2075
current loss is: 4.173501 , acc is: 0.015625 , iter= 2076
current loss is: 4.1566763 , acc is: 0.046875 , iter= 2077
current loss is: 3.9959052 , acc is: 0.078125 , iter= 2078
current loss is: 4.142568 , acc is: 0.03125 , iter= 2079
current loss is: 3.8921409 , acc is: 0.078125 , iter= 2080
current loss is: 3.9095268 , acc is: 0.046875 , iter= 2081
current loss is: 3.8516433 , acc is: 0.109375 , iter= 2082
current loss is: 3.8987887 , acc is: 0.09375 , iter= 2083
current loss is: 4.0870285 , acc is: 0.046875 , iter= 2084
current loss is: 4.0294304 , acc is: 0.03125 , iter= 2085
current loss is: 4.071574 , acc is: 0.046875 , iter= 2086
current loss is: 3.91279 , acc is: 0.078125 , iter= 2087
current loss is: 3.8610926 , acc is: 0.125 , iter= 2088
current loss is: 4.1504936 , acc is: 0.0 , iter= 2089
current loss is: 3.9982393 , acc is: 0.0625 , iter= 2090
current loss is: 4.0255632 , acc is: 0.046875 , iter= 2091
current loss is: 4.4368677 , acc is: 0.03125 , iter= 2092
current loss is: 3.9128125 , acc is: 0.078125 , iter= 2093
current loss is: 3.9132333 , acc is: 0.078125 , iter= 2094
current loss is: 4.1406417 , acc is: 0.046875 , iter= 2095
current loss is: 4.274604 , acc is: 0.0625 , iter= 2096
current loss is: 3.9513352 , acc is: 0.046875 , iter= 2097
current loss is: 4.1740003 , acc is: 0.03125 , iter= 2098
current loss is: 4.1641827 , acc is: 0.015625 , iter= 2099
current loss is: 4.094697 , acc is: 0.03125 , iter= 2100
current loss is: 3.9862688 , acc is: 0.078125 , iter= 2101
current loss is: 4.063143 , acc is: 0.0625 , iter= 2102
current loss is: 4.1102643 , acc is: 0.015625 , iter= 2103
current loss is: 3.9678173 , acc is: 0.046875 , iter= 2104
current loss is: 4.0663586 , acc is: 0.046875 , iter= 2105
current loss is: 3.7860184 , acc is: 0.09375 , iter= 2106
current loss is: 3.932648 , acc is: 0.0625 , iter= 2107
current loss is: 3.949549 , acc is: 0.09375 , iter= 2108
current loss is: 4.105419 , acc is: 0.046875 , iter= 2109
current loss is: 3.893944 , acc is: 0.09375 , iter= 2110
current loss is: 4.248558 , acc is: 0.03125 , iter= 2111
current loss is: 4.0751762 , acc is: 0.03125 , iter= 2112
current loss is: 4.1460032 , acc is: 0.046875 , iter= 2113
current loss is: 4.1053705 , acc is: 0.046875 , iter= 2114
current loss is: 4.016163 , acc is: 0.046875 , iter= 2115
current loss is: 3.9632742 , acc is: 0.09375 , iter= 2116
current loss is: 4.013451 , acc is: 0.09375 , iter= 2117
current loss is: 3.8700962 , acc is: 0.0625 , iter= 2118
current loss is: 4.042781 , acc is: 0.046875 , iter= 2119
current loss is: 4.090355 , acc is: 0.015625 , iter= 2120
current loss is: 3.893812 , acc is: 0.09375 , iter= 2121
current loss is: 3.9836533 , acc is: 0.046875 , iter= 2122
current loss is: 4.080507 , acc is: 0.046875 , iter= 2123
current loss is: 4.001443 , acc is: 0.046875 , iter= 2124
current loss is: 3.9823172 , acc is: 0.0625 , iter= 2125
current loss is: 3.971528 , acc is: 0.09375 , iter= 2126
current loss is: 4.091582 , acc is: 0.03125 , iter= 2127
current loss is: 3.8534293 , acc is: 0.09375 , iter= 2128
current loss is: 3.850884 , acc is: 0.078125 , iter= 2129
current loss is: 4.065877 , acc is: 0.03125 , iter= 2130
current loss is: 4.0187244 , acc is: 0.046875 , iter= 2131
current loss is: 4.176011 , acc is: 0.015625 , iter= 2132
current loss is: 4.0334473 , acc is: 0.03125 , iter= 2133
current loss is: 4.108902 , acc is: 0.03125 , iter= 2134
current loss is: 4.418248 , acc is: 0.015625 , iter= 2135
current loss is: 4.622984 , acc is: 0.046875 , iter= 2136
current loss is: 3.9511821 , acc is: 0.0625 , iter= 2137
current loss is: 3.9567854 , acc is: 0.078125 , iter= 2138
current loss is: 3.9685533 , acc is: 0.09375 , iter= 2139
current loss is: 4.0321617 , acc is: 0.046875 , iter= 2140
current loss is: 4.0273113 , acc is: 0.015625 , iter= 2141
current loss is: 3.9954414 , acc is: 0.03125 , iter= 2142
current loss is: 3.9063182 , acc is: 0.078125 , iter= 2143
current loss is: 4.1310844 , acc is: 0.015625 , iter= 2144
current loss is: 3.791095 , acc is: 0.09375 , iter= 2145
current loss is: 3.788385 , acc is: 0.09375 , iter= 2146
current loss is: 4.0263286 , acc is: 0.0625 , iter= 2147
current loss is: 3.8847604 , acc is: 0.078125 , iter= 2148
current loss is: 4.895317 , acc is: 0.046875 , iter= 2149
current loss is: 4.1150117 , acc is: 0.03125 , iter= 2150
current loss is: 3.9814472 , acc is: 0.046875 , iter= 2151
current loss is: 4.999946 , acc is: 0.046875 , iter= 2152
current loss is: 3.9633563 , acc is: 0.0625 , iter= 2153
current loss is: 3.7268806 , acc is: 0.109375 , iter= 2154
current loss is: 4.0531435 , acc is: 0.046875 , iter= 2155
current loss is: 3.8780923 , acc is: 0.09375 , iter= 2156
current loss is: 4.05205 , acc is: 0.078125 , iter= 2157
current loss is: 3.690539 , acc is: 0.140625 , iter= 2158
current loss is: 3.8096218 , acc is: 0.125 , iter= 2159
current loss is: 3.8917527 , acc is: 0.09375 , iter= 2160
current loss is: 3.8871853 , acc is: 0.09375 , iter= 2161
current loss is: 4.0663795 , acc is: 0.0625 , iter= 2162
current loss is: 3.9425492 , acc is: 0.09375 , iter= 2163
current loss is: 4.0149984 , acc is: 0.0625 , iter= 2164
current loss is: 4.102646 , acc is: 0.03125 , iter= 2165
current loss is: 4.1753445 , acc is: 0.03125 , iter= 2166
current loss is: 4.054956 , acc is: 0.046875 , iter= 2167
current loss is: 4.1109424 , acc is: 0.03125 , iter= 2168
current loss is: 4.0939116 , acc is: 0.015625 , iter= 2169
current loss is: 4.1240273 , acc is: 0.015625 , iter= 2170
current loss is: 3.9974046 , acc is: 0.0625 , iter= 2171
current loss is: 4.294016 , acc is: 0.046875 , iter= 2172
current loss is: 3.8845294 , acc is: 0.15625 , iter= 2173
current loss is: 4.0493317 , acc is: 0.03125 , iter= 2174
current loss is: 4.106179 , acc is: 0.0625 , iter= 2175
current loss is: 4.0747223 , acc is: 0.03125 , iter= 2176
current loss is: 3.955102 , acc is: 0.0625 , iter= 2177
current loss is: 4.0932236 , acc is: 0.03125 , iter= 2178
current loss is: 4.4258614 , acc is: 0.03125 , iter= 2179
current loss is: 4.104293 , acc is: 0.046875 , iter= 2180
current loss is: 4.1619105 , acc is: 0.015625 , iter= 2181
current loss is: 3.9077013 , acc is: 0.078125 , iter= 2182
current loss is: 3.8391109 , acc is: 0.09375 , iter= 2183
current loss is: 4.183035 , acc is: 0.03125 , iter= 2184
current loss is: 3.9688613 , acc is: 0.078125 , iter= 2185
current loss is: 4.02786 , acc is: 0.0625 , iter= 2186
current loss is: 4.0063496 , acc is: 0.03125 , iter= 2187
current loss is: 4.18395 , acc is: 0.015625 , iter= 2188
current loss is: 3.9503608 , acc is: 0.0625 , iter= 2189
current loss is: 3.9940448 , acc is: 0.0625 , iter= 2190
current loss is: 3.8781993 , acc is: 0.109375 , iter= 2191
current loss is: 4.0481596 , acc is: 0.046875 , iter= 2192
current loss is: 4.1250396 , acc is: 0.015625 , iter= 2193
current loss is: 4.1148443 , acc is: 0.015625 , iter= 2194
current loss is: 4.034485 , acc is: 0.046875 , iter= 2195
current loss is: 4.013307 , acc is: 0.0625 , iter= 2196
current loss is: 4.1485825 , acc is: 0.03125 , iter= 2197
current loss is: 4.006947 , acc is: 0.0625 , iter= 2198
current loss is: 4.10654 , acc is: 0.046875 , iter= 2199
current loss is: 4.1241856 , acc is: 0.0625 , iter= 2200
current loss is: 4.211241 , acc is: 0.046875 , iter= 2201
current loss is: 4.0273542 , acc is: 0.078125 , iter= 2202
current loss is: 3.8973835 , acc is: 0.078125 , iter= 2203
current loss is: 4.017826 , acc is: 0.078125 , iter= 2204
current loss is: 4.027162 , acc is: 0.0625 , iter= 2205
current loss is: 3.9721553 , acc is: 0.03125 , iter= 2206
current loss is: 3.8590965 , acc is: 0.078125 , iter= 2207
current loss is: 4.1205387 , acc is: 0.015625 , iter= 2208
current loss is: 4.0224276 , acc is: 0.0625 , iter= 2209
current loss is: 4.0140486 , acc is: 0.046875 , iter= 2210
current loss is: 3.7791877 , acc is: 0.078125 , iter= 2211
current loss is: 4.152363 , acc is: 0.015625 , iter= 2212
current loss is: 4.036154 , acc is: 0.03125 , iter= 2213
current loss is: 3.870378 , acc is: 0.078125 , iter= 2214
current loss is: 4.122096 , acc is: 0.0625 , iter= 2215
current loss is: 4.0118194 , acc is: 0.046875 , iter= 2216
current loss is: 4.1018896 , acc is: 0.046875 , iter= 2217
current loss is: 4.033831 , acc is: 0.046875 , iter= 2218
current loss is: 4.0253925 , acc is: 0.046875 , iter= 2219
current loss is: 4.631383 , acc is: 0.046875 , iter= 2220
current loss is: 3.8614783 , acc is: 0.09375 , iter= 2221
current loss is: 4.0081806 , acc is: 0.03125 , iter= 2222
current loss is: 4.1843233 , acc is: 0.015625 , iter= 2223
current loss is: 3.932398 , acc is: 0.0625 , iter= 2224
current loss is: 4.775816 , acc is: 0.03125 , iter= 2225
current loss is: 3.8451452 , acc is: 0.09375 , iter= 2226
current loss is: 4.0650635 , acc is: 0.03125 , iter= 2227
current loss is: 4.036216 , acc is: 0.046875 , iter= 2228
current loss is: 3.933492 , acc is: 0.109375 , iter= 2229
current loss is: 4.0920935 , acc is: 0.046875 , iter= 2230
current loss is: 3.829791 , acc is: 0.109375 , iter= 2231
current loss is: 3.9425926 , acc is: 0.078125 , iter= 2232
current loss is: 3.9329066 , acc is: 0.0625 , iter= 2233
current loss is: 4.0215654 , acc is: 0.078125 , iter= 2234
current loss is: 3.9403024 , acc is: 0.09375 , iter= 2235
current loss is: 4.1192303 , acc is: 0.046875 , iter= 2236
current loss is: 4.1280813 , acc is: 0.015625 , iter= 2237
current loss is: 3.5858138 , acc is: 0.171875 , iter= 2238
current loss is: 4.0144567 , acc is: 0.0625 , iter= 2239
current loss is: 3.9164045 , acc is: 0.078125 , iter= 2240
current loss is: 3.895162 , acc is: 0.0625 , iter= 2241
current loss is: 4.095443 , acc is: 0.046875 , iter= 2242
current loss is: 4.080576 , acc is: 0.015625 , iter= 2243
current loss is: 4.048109 , acc is: 0.03125 , iter= 2244
current loss is: 4.120124 , acc is: 0.03125 , iter= 2245
current loss is: 4.0979013 , acc is: 0.0625 , iter= 2246
current loss is: 4.010923 , acc is: 0.046875 , iter= 2247
current loss is: 3.9738429 , acc is: 0.09375 , iter= 2248
current loss is: 4.095333 , acc is: 0.0625 , iter= 2249
current loss is: 3.9015753 , acc is: 0.046875 , iter= 2250
current loss is: 4.1322346 , acc is: 0.03125 , iter= 2251
current loss is: 3.9553456 , acc is: 0.046875 , iter= 2252
current loss is: 3.8853805 , acc is: 0.109375 , iter= 2253
current loss is: 4.043063 , acc is: 0.03125 , iter= 2254
current loss is: 3.900493 , acc is: 0.078125 , iter= 2255
current loss is: 4.512485 , acc is: 0.03125 , iter= 2256
current loss is: 4.02172 , acc is: 0.046875 , iter= 2257
current loss is: 4.074502 , acc is: 0.03125 , iter= 2258
current loss is: 3.980373 , acc is: 0.09375 , iter= 2259
current loss is: 3.8421292 , acc is: 0.125 , iter= 2260
current loss is: 4.037875 , acc is: 0.046875 , iter= 2261
current loss is: 4.183419 , acc is: 0.03125 , iter= 2262
current loss is: 3.7981744 , acc is: 0.125 , iter= 2263
current loss is: 4.183305 , acc is: 0.046875 , iter= 2264
current loss is: 4.1882505 , acc is: 0.015625 , iter= 2265
current loss is: 3.841568 , acc is: 0.09375 , iter= 2266
current loss is: 3.880612 , acc is: 0.078125 , iter= 2267
current loss is: 4.0084777 , acc is: 0.03125 , iter= 2268
current loss is: 3.9758987 , acc is: 0.046875 , iter= 2269
current loss is: 4.038729 , acc is: 0.046875 , iter= 2270
current loss is: 4.1174645 , acc is: 0.015625 , iter= 2271
current loss is: 4.0883675 , acc is: 0.046875 , iter= 2272
current loss is: 4.1382923 , acc is: 0.03125 , iter= 2273
current loss is: 3.9648237 , acc is: 0.046875 , iter= 2274
current loss is: 3.9759874 , acc is: 0.046875 , iter= 2275
current loss is: 4.01407 , acc is: 0.046875 , iter= 2276
current loss is: 3.9110937 , acc is: 0.09375 , iter= 2277
current loss is: 4.1034102 , acc is: 0.03125 , iter= 2278
current loss is: 4.0338893 , acc is: 0.0625 , iter= 2279
current loss is: 4.0416594 , acc is: 0.046875 , iter= 2280
current loss is: 4.0045567 , acc is: 0.046875 , iter= 2281
current loss is: 4.133586 , acc is: 0.015625 , iter= 2282
current loss is: 4.183137 , acc is: 0.0 , iter= 2283
current loss is: 3.915122 , acc is: 0.078125 , iter= 2284
current loss is: 4.134472 , acc is: 0.015625 , iter= 2285
current loss is: 3.9749875 , acc is: 0.09375 , iter= 2286
current loss is: 4.087985 , acc is: 0.046875 , iter= 2287
current loss is: 4.3128834 , acc is: 0.046875 , iter= 2288
current loss is: 3.9935012 , acc is: 0.078125 , iter= 2289
current loss is: 3.8784747 , acc is: 0.09375 , iter= 2290
current loss is: 4.1133175 , acc is: 0.03125 , iter= 2291
current loss is: 3.9268627 , acc is: 0.078125 , iter= 2292
current loss is: 4.8956037 , acc is: 0.03125 , iter= 2293
current loss is: 4.081501 , acc is: 0.046875 , iter= 2294
current loss is: 3.9052575 , acc is: 0.09375 , iter= 2295
current loss is: 3.8859293 , acc is: 0.078125 , iter= 2296
current loss is: 3.957303 , acc is: 0.0625 , iter= 2297
current loss is: 3.9679773 , acc is: 0.0625 , iter= 2298
current loss is: 4.0249834 , acc is: 0.046875 , iter= 2299
current loss is: 4.199105 , acc is: 0.03125 , iter= 2300
current loss is: 3.9263086 , acc is: 0.046875 , iter= 2301
current loss is: 3.856635 , acc is: 0.078125 , iter= 2302
current loss is: 4.1250515 , acc is: 0.046875 , iter= 2303
current loss is: 4.112217 , acc is: 0.046875 , iter= 2304
current loss is: 4.067402 , acc is: 0.046875 , iter= 2305
current loss is: 4.0314436 , acc is: 0.046875 , iter= 2306
current loss is: 3.8822055 , acc is: 0.0625 , iter= 2307
current loss is: 3.8473153 , acc is: 0.109375 , iter= 2308
current loss is: 3.921607 , acc is: 0.0625 , iter= 2309
current loss is: 4.0557003 , acc is: 0.046875 , iter= 2310
current loss is: 4.010748 , acc is: 0.0625 , iter= 2311
current loss is: 4.0562954 , acc is: 0.046875 , iter= 2312
current loss is: 3.8446455 , acc is: 0.09375 , iter= 2313
current loss is: 3.9346244 , acc is: 0.0625 , iter= 2314
current loss is: 4.0091457 , acc is: 0.046875 , iter= 2315
current loss is: 4.118204 , acc is: 0.046875 , iter= 2316
current loss is: 4.043668 , acc is: 0.03125 , iter= 2317
current loss is: 4.071859 , acc is: 0.015625 , iter= 2318
current loss is: 4.06494 , acc is: 0.046875 , iter= 2319
current loss is: 4.472902 , acc is: 0.046875 , iter= 2320
current loss is: 4.083416 , acc is: 0.015625 , iter= 2321
current loss is: 4.0178313 , acc is: 0.0625 , iter= 2322
current loss is: 3.9106078 , acc is: 0.109375 , iter= 2323
current loss is: 3.843351 , acc is: 0.09375 , iter= 2324
current loss is: 4.151473 , acc is: 0.09375 , iter= 2325
current loss is: 4.1308284 , acc is: 0.078125 , iter= 2326
current loss is: 3.9368372 , acc is: 0.078125 , iter= 2327
current loss is: 3.8807368 , acc is: 0.0625 , iter= 2328
current loss is: 3.9662492 , acc is: 0.046875 , iter= 2329
current loss is: 3.9397564 , acc is: 0.09375 , iter= 2330
current loss is: 4.027402 , acc is: 0.046875 , iter= 2331
current loss is: 5.930185 , acc is: 0.09375 , iter= 2332
current loss is: 4.1049423 , acc is: 0.046875 , iter= 2333
current loss is: 3.8742707 , acc is: 0.109375 , iter= 2334
current loss is: 4.015465 , acc is: 0.046875 , iter= 2335
current loss is: 4.024163 , acc is: 0.046875 , iter= 2336
current loss is: 4.0066333 , acc is: 0.03125 , iter= 2337
current loss is: 4.0013847 , acc is: 0.0625 , iter= 2338
current loss is: 4.1550403 , acc is: 0.015625 , iter= 2339
current loss is: 4.1021786 , acc is: 0.046875 , iter= 2340
current loss is: 4.1388206 , acc is: 0.0 , iter= 2341
current loss is: 4.1505103 , acc is: 0.046875 , iter= 2342
current loss is: 3.963648 , acc is: 0.046875 , iter= 2343
current loss is: 3.8979416 , acc is: 0.0625 , iter= 2344
current loss is: 3.9795449 , acc is: 0.09375 , iter= 2345
current loss is: 3.9464173 , acc is: 0.078125 , iter= 2346
current loss is: 3.972907 , acc is: 0.046875 , iter= 2347
current loss is: 4.0539293 , acc is: 0.046875 , iter= 2348
current loss is: 4.03459 , acc is: 0.046875 , iter= 2349
current loss is: 4.1073236 , acc is: 0.015625 , iter= 2350
current loss is: 4.1426497 , acc is: 0.03125 , iter= 2351
current loss is: 3.9993138 , acc is: 0.0625 , iter= 2352
current loss is: 3.939477 , acc is: 0.078125 , iter= 2353
current loss is: 3.9919734 , acc is: 0.046875 , iter= 2354
current loss is: 4.1545386 , acc is: 0.0 , iter= 2355
current loss is: 6.443636 , acc is: 0.09375 , iter= 2356
current loss is: 7.417178 , acc is: 0.140625 , iter= 2357
current loss is: 3.9132903 , acc is: 0.046875 , iter= 2358
current loss is: 4.0179644 , acc is: 0.03125 , iter= 2359
current loss is: 3.8795948 , acc is: 0.09375 , iter= 2360
current loss is: 3.9094074 , acc is: 0.09375 , iter= 2361
current loss is: 4.0246515 , acc is: 0.046875 , iter= 2362
current loss is: 4.1199985 , acc is: 0.046875 , iter= 2363
current loss is: 4.002934 , acc is: 0.078125 , iter= 2364
current loss is: 3.9164343 , acc is: 0.0625 , iter= 2365
current loss is: 4.110426 , acc is: 0.015625 , iter= 2366
current loss is: 4.159725 , acc is: 0.015625 , iter= 2367
current loss is: 4.0870075 , acc is: 0.03125 , iter= 2368
current loss is: 4.031754 , acc is: 0.03125 , iter= 2369
current loss is: 4.1392856 , acc is: 0.09375 , iter= 2370
current loss is: 4.1317396 , acc is: 0.015625 , iter= 2371
current loss is: 3.989007 , acc is: 0.0625 , iter= 2372
current loss is: 3.949866 , acc is: 0.0625 , iter= 2373
current loss is: 4.0250893 , acc is: 0.0625 , iter= 2374
current loss is: 3.9345176 , acc is: 0.0625 , iter= 2375
current loss is: 4.0526695 , acc is: 0.015625 , iter= 2376
current loss is: 3.9216154 , acc is: 0.140625 , iter= 2377
current loss is: 4.014022 , acc is: 0.03125 , iter= 2378
current loss is: 4.27395 , acc is: 0.03125 , iter= 2379
current loss is: 4.1534586 , acc is: 0.015625 , iter= 2380
current loss is: 4.137942 , acc is: 0.015625 , iter= 2381
current loss is: 3.8379538 , acc is: 0.078125 , iter= 2382
current loss is: 4.1265683 , acc is: 0.046875 , iter= 2383
current loss is: 3.9328604 , acc is: 0.0625 , iter= 2384
current loss is: 4.069191 , acc is: 0.0625 , iter= 2385
current loss is: 3.7186794 , acc is: 0.125 , iter= 2386
current loss is: 4.165005 , acc is: 0.03125 , iter= 2387
current loss is: 4.1481023 , acc is: 0.03125 , iter= 2388
current loss is: 4.043571 , acc is: 0.0625 , iter= 2389
current loss is: 3.9929209 , acc is: 0.046875 , iter= 2390
current loss is: 3.9360542 , acc is: 0.0625 , iter= 2391
current loss is: 3.8992972 , acc is: 0.109375 , iter= 2392
current loss is: 4.1167793 , acc is: 0.015625 , iter= 2393
current loss is: 3.9699712 , acc is: 0.046875 , iter= 2394
current loss is: 3.9799852 , acc is: 0.09375 , iter= 2395
current loss is: 3.974001 , acc is: 0.0625 , iter= 2396
current loss is: 4.000599 , acc is: 0.078125 , iter= 2397
current loss is: 4.0240817 , acc is: 0.046875 , iter= 2398
current loss is: 4.019374 , acc is: 0.03125 , iter= 2399
current loss is: 4.050251 , acc is: 0.03125 , iter= 2400
current loss is: 3.9912784 , acc is: 0.0625 , iter= 2401
current loss is: 4.0670085 , acc is: 0.078125 , iter= 2402
current loss is: 3.9807575 , acc is: 0.0625 , iter= 2403
current loss is: 4.083323 , acc is: 0.03125 , iter= 2404
current loss is: 4.0194507 , acc is: 0.0625 , iter= 2405
current loss is: 4.088658 , acc is: 0.046875 , iter= 2406
current loss is: 4.066422 , acc is: 0.046875 , iter= 2407
current loss is: 4.0415297 , acc is: 0.015625 , iter= 2408
current loss is: 3.9773564 , acc is: 0.09375 , iter= 2409
current loss is: 4.0034766 , acc is: 0.046875 , iter= 2410
current loss is: 3.828611 , acc is: 0.09375 , iter= 2411
current loss is: 4.125711 , acc is: 0.015625 , iter= 2412
current loss is: 4.037134 , acc is: 0.046875 , iter= 2413
current loss is: 3.8438542 , acc is: 0.09375 , iter= 2414
current loss is: 4.028734 , acc is: 0.078125 , iter= 2415
current loss is: 4.058832 , acc is: 0.046875 , iter= 2416
current loss is: 4.071308 , acc is: 0.0625 , iter= 2417
current loss is: 4.1834354 , acc is: 0.015625 , iter= 2418
current loss is: 4.0362225 , acc is: 0.046875 , iter= 2419
current loss is: 3.8833015 , acc is: 0.09375 , iter= 2420
current loss is: 3.983586 , acc is: 0.046875 , iter= 2421
current loss is: 4.0030212 , acc is: 0.078125 , iter= 2422
current loss is: 3.9885821 , acc is: 0.03125 , iter= 2423
current loss is: 4.0904875 , acc is: 0.03125 , iter= 2424
current loss is: 4.0477047 , acc is: 0.046875 , iter= 2425
current loss is: 4.101628 , acc is: 0.015625 , iter= 2426
current loss is: 4.1048784 , acc is: 0.015625 , iter= 2427
current loss is: 3.8171692 , acc is: 0.109375 , iter= 2428
current loss is: 4.2525625 , acc is: 0.0625 , iter= 2429
current loss is: 4.0438404 , acc is: 0.03125 , iter= 2430
current loss is: 3.9534898 , acc is: 0.078125 , iter= 2431
current loss is: 4.0615997 , acc is: 0.03125 , iter= 2432
current loss is: 3.9287462 , acc is: 0.0625 , iter= 2433
current loss is: 4.0025034 , acc is: 0.078125 , iter= 2434
current loss is: 3.9872928 , acc is: 0.0625 , iter= 2435
current loss is: 4.0647464 , acc is: 0.046875 , iter= 2436
current loss is: 4.048428 , acc is: 0.046875 , iter= 2437
current loss is: 4.077744 , acc is: 0.0625 , iter= 2438
current loss is: 3.9362936 , acc is: 0.046875 , iter= 2439
current loss is: 4.0911255 , acc is: 0.078125 , iter= 2440
current loss is: 3.8102853 , acc is: 0.09375 , iter= 2441
current loss is: 4.0053115 , acc is: 0.09375 , iter= 2442
current loss is: 3.720246 , acc is: 0.109375 , iter= 2443
current loss is: 4.0644274 , acc is: 0.046875 , iter= 2444
current loss is: 4.018418 , acc is: 0.03125 , iter= 2445
current loss is: 4.0918345 , acc is: 0.03125 , iter= 2446
current loss is: 4.0090957 , acc is: 0.046875 , iter= 2447
current loss is: 3.8912685 , acc is: 0.078125 , iter= 2448
current loss is: 3.9372249 , acc is: 0.078125 , iter= 2449
current loss is: 4.052103 , acc is: 0.03125 , iter= 2450
current loss is: 4.109999 , acc is: 0.015625 , iter= 2451
current loss is: 3.8374403 , acc is: 0.109375 , iter= 2452
current loss is: 4.0515976 , acc is: 0.03125 , iter= 2453
current loss is: 4.0030785 , acc is: 0.078125 , iter= 2454
current loss is: 3.9377651 , acc is: 0.078125 , iter= 2455
current loss is: 3.9873328 , acc is: 0.0625 , iter= 2456
current loss is: 3.9082778 , acc is: 0.078125 , iter= 2457
current loss is: 4.0693426 , acc is: 0.046875 , iter= 2458
current loss is: 4.0219364 , acc is: 0.046875 , iter= 2459
current loss is: 4.0749235 , acc is: 0.03125 , iter= 2460
current loss is: 4.0778723 , acc is: 0.015625 , iter= 2461
current loss is: 4.0385237 , acc is: 0.078125 , iter= 2462
current loss is: 4.008708 , acc is: 0.0625 , iter= 2463
current loss is: 4.0338364 , acc is: 0.046875 , iter= 2464
current loss is: 3.8793488 , acc is: 0.0625 , iter= 2465
current loss is: 3.988236 , acc is: 0.046875 , iter= 2466
current loss is: 4.1754 , acc is: 0.0 , iter= 2467
current loss is: 3.8265996 , acc is: 0.078125 , iter= 2468
current loss is: 3.8880181 , acc is: 0.0625 , iter= 2469
current loss is: 4.099283 , acc is: 0.03125 , iter= 2470
current loss is: 4.171139 , acc is: 0.0 , iter= 2471
current loss is: 4.037707 , acc is: 0.046875 , iter= 2472
current loss is: 3.9949083 , acc is: 0.078125 , iter= 2473
current loss is: 4.0976486 , acc is: 0.015625 , iter= 2474
current loss is: 3.954434 , acc is: 0.046875 , iter= 2475
current loss is: 3.992124 , acc is: 0.03125 , iter= 2476
current loss is: 4.093039 , acc is: 0.015625 , iter= 2477
current loss is: 3.90628 , acc is: 0.078125 , iter= 2478
current loss is: 4.015846 , acc is: 0.0625 , iter= 2479
current loss is: 3.8978364 , acc is: 0.109375 , iter= 2480
current loss is: 3.808873 , acc is: 0.109375 , iter= 2481
current loss is: 3.8053503 , acc is: 0.140625 , iter= 2482
current loss is: 3.982452 , acc is: 0.0625 , iter= 2483
current loss is: 3.961801 , acc is: 0.046875 , iter= 2484
current loss is: 3.941956 , acc is: 0.09375 , iter= 2485
current loss is: 3.9057062 , acc is: 0.078125 , iter= 2486
current loss is: 4.2280064 , acc is: 0.0 , iter= 2487
current loss is: 4.033257 , acc is: 0.046875 , iter= 2488
current loss is: 4.2027225 , acc is: 0.0 , iter= 2489
current loss is: 4.0585375 , acc is: 0.046875 , iter= 2490
current loss is: 3.8050828 , acc is: 0.140625 , iter= 2491
current loss is: 4.396487 , acc is: 0.046875 , iter= 2492
current loss is: 3.8120153 , acc is: 0.078125 , iter= 2493
current loss is: 4.1172695 , acc is: 0.03125 , iter= 2494
current loss is: 3.8876143 , acc is: 0.078125 , iter= 2495
current loss is: 4.0530286 , acc is: 0.046875 , iter= 2496
current loss is: 4.024163 , acc is: 0.0625 , iter= 2497
current loss is: 3.9700184 , acc is: 0.046875 , iter= 2498
current loss is: 4.08148 , acc is: 0.046875 , iter= 2499
current loss is: 3.9752467 , acc is: 0.09375 , iter= 2500
current loss is: 4.075122 , acc is: 0.03125 , iter= 2501
current loss is: 4.0055437 , acc is: 0.0625 , iter= 2502
current loss is: 3.9546247 , acc is: 0.09375 , iter= 2503
current loss is: 4.047909 , acc is: 0.03125 , iter= 2504
current loss is: 4.0372 , acc is: 0.046875 , iter= 2505
current loss is: 4.038003 , acc is: 0.015625 , iter= 2506
current loss is: 4.1285133 , acc is: 0.03125 , iter= 2507
current loss is: 3.9484458 , acc is: 0.078125 , iter= 2508
current loss is: 3.903436 , acc is: 0.078125 , iter= 2509
current loss is: 3.9158044 , acc is: 0.0625 , iter= 2510
current loss is: 3.9967918 , acc is: 0.03125 , iter= 2511
current loss is: 3.9477503 , acc is: 0.09375 , iter= 2512
current loss is: 3.9918358 , acc is: 0.09375 , iter= 2513
current loss is: 4.29623 , acc is: 0.046875 , iter= 2514
current loss is: 3.9062219 , acc is: 0.078125 , iter= 2515
current loss is: 3.9734273 , acc is: 0.0625 , iter= 2516
current loss is: 4.0549088 , acc is: 0.046875 , iter= 2517
current loss is: 3.9877522 , acc is: 0.046875 , iter= 2518
current loss is: 3.9637904 , acc is: 0.0625 , iter= 2519
current loss is: 4.1004715 , acc is: 0.03125 , iter= 2520
current loss is: 4.059305 , acc is: 0.03125 , iter= 2521
current loss is: 3.9913836 , acc is: 0.0625 , iter= 2522
current loss is: 3.9036577 , acc is: 0.09375 , iter= 2523
current loss is: 4.094896 , acc is: 0.046875 , iter= 2524
current loss is: 4.014102 , acc is: 0.03125 , iter= 2525
current loss is: 4.045184 , acc is: 0.0625 , iter= 2526
current loss is: 3.9389887 , acc is: 0.0625 , iter= 2527
current loss is: 3.8867335 , acc is: 0.09375 , iter= 2528
current loss is: 4.126401 , acc is: 0.046875 , iter= 2529
current loss is: 4.1364155 , acc is: 0.046875 , iter= 2530
current loss is: 4.774105 , acc is: 0.046875 , iter= 2531
current loss is: 4.123088 , acc is: 0.0 , iter= 2532
current loss is: 4.1134844 , acc is: 0.0625 , iter= 2533
current loss is: 4.020975 , acc is: 0.09375 , iter= 2534
current loss is: 3.9510658 , acc is: 0.0625 , iter= 2535
current loss is: 4.005314 , acc is: 0.03125 , iter= 2536
current loss is: 4.142991 , acc is: 0.015625 , iter= 2537
current loss is: 3.9291525 , acc is: 0.078125 , iter= 2538
current loss is: 3.9602523 , acc is: 0.046875 , iter= 2539
current loss is: 3.9854672 , acc is: 0.078125 , iter= 2540
current loss is: 4.5830812 , acc is: 0.015625 , iter= 2541
current loss is: 3.932693 , acc is: 0.0625 , iter= 2542
current loss is: 4.0726967 , acc is: 0.015625 , iter= 2543
current loss is: 4.1655283 , acc is: 0.078125 , iter= 2544
current loss is: 3.9357948 , acc is: 0.0625 , iter= 2545
current loss is: 3.819537 , acc is: 0.09375 , iter= 2546
current loss is: 4.040086 , acc is: 0.078125 , iter= 2547
current loss is: 4.0855412 , acc is: 0.046875 , iter= 2548
current loss is: 4.0913553 , acc is: 0.046875 , iter= 2549
current loss is: 4.021381 , acc is: 0.109375 , iter= 2550
current loss is: 4.015093 , acc is: 0.046875 , iter= 2551
current loss is: 4.0885525 , acc is: 0.015625 , iter= 2552
current loss is: 3.846784 , acc is: 0.125 , iter= 2553
current loss is: 4.0669613 , acc is: 0.0625 , iter= 2554
current loss is: 4.099237 , acc is: 0.015625 , iter= 2555
current loss is: 4.068572 , acc is: 0.046875 , iter= 2556
current loss is: 4.041878 , acc is: 0.03125 , iter= 2557
current loss is: 3.9889364 , acc is: 0.03125 , iter= 2558
current loss is: 4.0793715 , acc is: 0.046875 , iter= 2559
current loss is: 4.173255 , acc is: 0.015625 , iter= 2560
current loss is: 3.9520257 , acc is: 0.078125 , iter= 2561
current loss is: 3.934579 , acc is: 0.046875 , iter= 2562
current loss is: 3.9912436 , acc is: 0.03125 , iter= 2563
current loss is: 3.9799037 , acc is: 0.0625 , iter= 2564
current loss is: 4.034061 , acc is: 0.03125 , iter= 2565
current loss is: 3.764721 , acc is: 0.09375 , iter= 2566
current loss is: 3.9574947 , acc is: 0.0625 , iter= 2567
current loss is: 4.1558 , acc is: 0.03125 , iter= 2568
current loss is: 4.437339 , acc is: 0.0625 , iter= 2569
current loss is: 4.1682324 , acc is: 0.015625 , iter= 2570
current loss is: 4.183914 , acc is: 0.015625 , iter= 2571
current loss is: 3.9837184 , acc is: 0.09375 , iter= 2572
current loss is: 4.447203 , acc is: 0.015625 , iter= 2573
current loss is: 4.0427246 , acc is: 0.03125 , iter= 2574
current loss is: 3.884937 , acc is: 0.0625 , iter= 2575
current loss is: 4.2465115 , acc is: 0.015625 , iter= 2576
current loss is: 4.003455 , acc is: 0.0625 , iter= 2577
current loss is: 4.0235868 , acc is: 0.03125 , iter= 2578
current loss is: 4.0476923 , acc is: 0.015625 , iter= 2579
current loss is: 4.07227 , acc is: 0.03125 , iter= 2580
current loss is: 4.0200763 , acc is: 0.0625 , iter= 2581
current loss is: 4.02186 , acc is: 0.03125 , iter= 2582
current loss is: 4.0164647 , acc is: 0.046875 , iter= 2583
current loss is: 4.080653 , acc is: 0.015625 , iter= 2584
current loss is: 4.0500917 , acc is: 0.015625 , iter= 2585
current loss is: 4.015135 , acc is: 0.09375 , iter= 2586
current loss is: 3.83987 , acc is: 0.09375 , iter= 2587
current loss is: 3.8951979 , acc is: 0.078125 , iter= 2588
current loss is: 4.113389 , acc is: 0.0625 , iter= 2589
current loss is: 3.9562058 , acc is: 0.046875 , iter= 2590
current loss is: 4.0889297 , acc is: 0.03125 , iter= 2591
current loss is: 3.874484 , acc is: 0.109375 , iter= 2592
current loss is: 3.8901787 , acc is: 0.09375 , iter= 2593
current loss is: 4.003695 , acc is: 0.046875 , iter= 2594
current loss is: 4.0194917 , acc is: 0.0625 , iter= 2595
current loss is: 4.4300523 , acc is: 0.046875 , iter= 2596
current loss is: 4.081998 , acc is: 0.015625 , iter= 2597
current loss is: 4.0735846 , acc is: 0.015625 , iter= 2598
current loss is: 3.7716951 , acc is: 0.109375 , iter= 2599
current loss is: 4.0020146 , acc is: 0.0625 , iter= 2600
current loss is: 4.1525936 , acc is: 0.015625 , iter= 2601
current loss is: 3.9196725 , acc is: 0.09375 , iter= 2602
current loss is: 3.858901 , acc is: 0.09375 , iter= 2603
current loss is: 4.103724 , acc is: 0.015625 , iter= 2604
current loss is: 3.9405465 , acc is: 0.0625 , iter= 2605
current loss is: 4.060592 , acc is: 0.046875 , iter= 2606
current loss is: 4.1244698 , acc is: 0.09375 , iter= 2607
current loss is: 3.8182292 , acc is: 0.125 , iter= 2608
current loss is: 4.169626 , acc is: 0.03125 , iter= 2609
current loss is: 3.8809285 , acc is: 0.078125 , iter= 2610
current loss is: 4.126582 , acc is: 0.03125 , iter= 2611
current loss is: 3.9970074 , acc is: 0.078125 , iter= 2612
current loss is: 4.040882 , acc is: 0.046875 , iter= 2613
current loss is: 4.0486665 , acc is: 0.03125 , iter= 2614
current loss is: 4.063304 , acc is: 0.09375 , iter= 2615
current loss is: 3.9119558 , acc is: 0.0625 , iter= 2616
current loss is: 3.9635808 , acc is: 0.0625 , iter= 2617
current loss is: 4.1083546 , acc is: 0.015625 , iter= 2618
current loss is: 3.9781399 , acc is: 0.046875 , iter= 2619
current loss is: 3.9698915 , acc is: 0.0625 , iter= 2620
current loss is: 4.112234 , acc is: 0.015625 , iter= 2621
current loss is: 3.9191337 , acc is: 0.078125 , iter= 2622
current loss is: 4.1231146 , acc is: 0.015625 , iter= 2623
current loss is: 4.0550184 , acc is: 0.03125 , iter= 2624
current loss is: 3.89876 , acc is: 0.0625 , iter= 2625
current loss is: 4.1536293 , acc is: 0.015625 , iter= 2626
current loss is: 4.408523 , acc is: 0.09375 , iter= 2627
current loss is: 4.021297 , acc is: 0.0625 , iter= 2628
current loss is: 3.933602 , acc is: 0.09375 , iter= 2629
current loss is: 4.171221 , acc is: 0.0 , iter= 2630
current loss is: 3.9456258 , acc is: 0.046875 , iter= 2631
current loss is: 3.9381473 , acc is: 0.0625 , iter= 2632
current loss is: 4.0878563 , acc is: 0.015625 , iter= 2633
current loss is: 4.1029873 , acc is: 0.03125 , iter= 2634
current loss is: 4.099988 , acc is: 0.03125 , iter= 2635
current loss is: 4.0310597 , acc is: 0.0625 , iter= 2636
current loss is: 4.023403 , acc is: 0.046875 , iter= 2637
current loss is: 3.898099 , acc is: 0.09375 , iter= 2638
current loss is: 3.877738 , acc is: 0.0625 , iter= 2639
current loss is: 4.6214833 , acc is: 0.109375 , iter= 2640
current loss is: 4.055273 , acc is: 0.03125 , iter= 2641
current loss is: 3.9413404 , acc is: 0.046875 , iter= 2642
current loss is: 4.181525 , acc is: 0.015625 , iter= 2643
current loss is: 3.996444 , acc is: 0.0625 , iter= 2644
current loss is: 4.0006084 , acc is: 0.046875 , iter= 2645
current loss is: 3.8831422 , acc is: 0.078125 , iter= 2646
current loss is: 4.079176 , acc is: 0.015625 , iter= 2647
current loss is: 4.143363 , acc is: 0.03125 , iter= 2648
current loss is: 3.6994686 , acc is: 0.140625 , iter= 2649
current loss is: 3.9424777 , acc is: 0.046875 , iter= 2650
current loss is: 4.213052 , acc is: 0.015625 , iter= 2651
current loss is: 4.080949 , acc is: 0.046875 , iter= 2652
current loss is: 3.9265218 , acc is: 0.046875 , iter= 2653
current loss is: 3.9931087 , acc is: 0.09375 , iter= 2654
current loss is: 4.0257444 , acc is: 0.03125 , iter= 2655
current loss is: 3.9564645 , acc is: 0.078125 , iter= 2656
current loss is: 3.9792452 , acc is: 0.03125 , iter= 2657
current loss is: 3.9955459 , acc is: 0.046875 , iter= 2658
current loss is: 3.7742443 , acc is: 0.09375 , iter= 2659
current loss is: 5.04602 , acc is: 0.0625 , iter= 2660
current loss is: 3.887323 , acc is: 0.109375 , iter= 2661
current loss is: 4.082492 , acc is: 0.03125 , iter= 2662
current loss is: 4.076411 , acc is: 0.0625 , iter= 2663
current loss is: 4.0514946 , acc is: 0.03125 , iter= 2664
current loss is: 4.148837 , acc is: 0.015625 , iter= 2665
current loss is: 4.2222233 , acc is: 0.03125 , iter= 2666
current loss is: 3.9741294 , acc is: 0.0625 , iter= 2667
current loss is: 4.5990624 , acc is: 0.0625 , iter= 2668
current loss is: 3.9283977 , acc is: 0.09375 , iter= 2669
current loss is: 4.0087605 , acc is: 0.03125 , iter= 2670
current loss is: 4.160019 , acc is: 0.03125 , iter= 2671
current loss is: 4.0891776 , acc is: 0.03125 , iter= 2672
current loss is: 3.9833941 , acc is: 0.046875 , iter= 2673
current loss is: 4.075446 , acc is: 0.046875 , iter= 2674
current loss is: 4.064991 , acc is: 0.03125 , iter= 2675
current loss is: 4.1517916 , acc is: 0.015625 , iter= 2676
current loss is: 3.9567075 , acc is: 0.046875 , iter= 2677
current loss is: 4.054434 , acc is: 0.0625 , iter= 2678
current loss is: 4.117467 , acc is: 0.03125 , iter= 2679
current loss is: 4.0698295 , acc is: 0.0625 , iter= 2680
current loss is: 4.012766 , acc is: 0.03125 , iter= 2681
current loss is: 3.8115294 , acc is: 0.09375 , iter= 2682
current loss is: 3.6891098 , acc is: 0.140625 , iter= 2683
current loss is: 4.0682297 , acc is: 0.078125 , iter= 2684
current loss is: 3.8100486 , acc is: 0.125 , iter= 2685
current loss is: 4.1063137 , acc is: 0.0 , iter= 2686
current loss is: 13.418976 , acc is: 0.0 , iter= 2687
current loss is: 3.842281 , acc is: 0.109375 , iter= 2688
current loss is: 4.1342745 , acc is: 0.015625 , iter= 2689
current loss is: 4.0432863 , acc is: 0.046875 , iter= 2690
current loss is: 4.410201 , acc is: 0.0625 , iter= 2691
current loss is: 4.143528 , acc is: 0.015625 , iter= 2692
current loss is: 3.8550138 , acc is: 0.109375 , iter= 2693
current loss is: 4.148939 , acc is: 0.046875 , iter= 2694
current loss is: 3.8136802 , acc is: 0.078125 , iter= 2695
current loss is: 4.03942 , acc is: 0.03125 , iter= 2696
current loss is: 4.0741434 , acc is: 0.015625 , iter= 2697
current loss is: 3.869869 , acc is: 0.09375 , iter= 2698
current loss is: 3.9901073 , acc is: 0.0625 , iter= 2699
current loss is: 3.966041 , acc is: 0.046875 , iter= 2700
current loss is: 4.0799747 , acc is: 0.015625 , iter= 2701
current loss is: 4.1122575 , acc is: 0.03125 , iter= 2702
current loss is: 4.0190487 , acc is: 0.046875 , iter= 2703
current loss is: 3.9259472 , acc is: 0.0625 , iter= 2704
current loss is: 4.0126944 , acc is: 0.03125 , iter= 2705
current loss is: 3.9228792 , acc is: 0.09375 , iter= 2706
current loss is: 3.8982515 , acc is: 0.0625 , iter= 2707
current loss is: 3.8804471 , acc is: 0.046875 , iter= 2708
current loss is: 4.038183 , acc is: 0.109375 , iter= 2709
current loss is: 3.9034655 , acc is: 0.125 , iter= 2710
current loss is: 4.93064 , acc is: 0.046875 , iter= 2711
current loss is: 3.9596632 , acc is: 0.046875 , iter= 2712
current loss is: 4.008938 , acc is: 0.03125 , iter= 2713
current loss is: 3.685389 , acc is: 0.125 , iter= 2714
current loss is: 3.9427884 , acc is: 0.078125 , iter= 2715
current loss is: 3.8885813 , acc is: 0.078125 , iter= 2716
current loss is: 4.147057 , acc is: 0.03125 , iter= 2717
current loss is: 3.9929361 , acc is: 0.03125 , iter= 2718
current loss is: 3.7014196 , acc is: 0.140625 , iter= 2719
current loss is: 5.4604187 , acc is: 0.109375 , iter= 2720
current loss is: 4.073617 , acc is: 0.0625 , iter= 2721
current loss is: 4.0729403 , acc is: 0.03125 , iter= 2722
current loss is: 3.8758507 , acc is: 0.109375 , iter= 2723
current loss is: 3.882611 , acc is: 0.0625 , iter= 2724
current loss is: 4.1445303 , acc is: 0.03125 , iter= 2725
current loss is: 4.140363 , acc is: 0.03125 , iter= 2726
current loss is: 4.009795 , acc is: 0.0625 , iter= 2727
current loss is: 3.985024 , acc is: 0.03125 , iter= 2728
current loss is: 4.1671815 , acc is: 0.015625 , iter= 2729
current loss is: 4.334837 , acc is: 0.03125 , iter= 2730
current loss is: 4.051711 , acc is: 0.078125 , iter= 2731
current loss is: 5.5725627 , acc is: 0.0625 , iter= 2732
current loss is: 4.0987587 , acc is: 0.046875 , iter= 2733
current loss is: 4.126254 , acc is: 0.015625 , iter= 2734
current loss is: 3.8354843 , acc is: 0.109375 , iter= 2735
current loss is: 4.1168156 , acc is: 0.03125 , iter= 2736
current loss is: 4.065964 , acc is: 0.015625 , iter= 2737
current loss is: 4.0354724 , acc is: 0.03125 , iter= 2738
current loss is: 4.069433 , acc is: 0.03125 , iter= 2739
current loss is: 3.9546113 , acc is: 0.046875 , iter= 2740
current loss is: 6.2513776 , acc is: 0.03125 , iter= 2741
current loss is: 4.021908 , acc is: 0.0625 , iter= 2742
current loss is: 4.024498 , acc is: 0.03125 , iter= 2743
current loss is: 3.9722443 , acc is: 0.046875 , iter= 2744
current loss is: 4.128346 , acc is: 0.03125 , iter= 2745
current loss is: 4.1052904 , acc is: 0.03125 , iter= 2746
current loss is: 4.082036 , acc is: 0.03125 , iter= 2747
current loss is: 4.1744986 , acc is: 0.03125 , iter= 2748
current loss is: 4.0222583 , acc is: 0.0625 , iter= 2749
current loss is: 3.9142323 , acc is: 0.078125 , iter= 2750
current loss is: 4.0100775 , acc is: 0.078125 , iter= 2751
current loss is: 4.1144776 , acc is: 0.03125 , iter= 2752
current loss is: 3.9831166 , acc is: 0.0625 , iter= 2753
current loss is: 4.019949 , acc is: 0.078125 , iter= 2754
current loss is: 3.9332793 , acc is: 0.0625 , iter= 2755
current loss is: 3.9145377 , acc is: 0.109375 , iter= 2756
current loss is: 4.0649767 , acc is: 0.046875 , iter= 2757
current loss is: 4.0344605 , acc is: 0.015625 , iter= 2758
current loss is: 3.9986944 , acc is: 0.078125 , iter= 2759
current loss is: 4.0408096 , acc is: 0.0625 , iter= 2760
current loss is: 4.097716 , acc is: 0.015625 , iter= 2761
current loss is: 3.8835158 , acc is: 0.09375 , iter= 2762
current loss is: 4.070077 , acc is: 0.03125 , iter= 2763
current loss is: 4.111991 , acc is: 0.046875 , iter= 2764
current loss is: 3.9836178 , acc is: 0.0625 , iter= 2765
current loss is: 4.038043 , acc is: 0.046875 , iter= 2766
current loss is: 3.9739738 , acc is: 0.0625 , iter= 2767
current loss is: 4.0643 , acc is: 0.015625 , iter= 2768
current loss is: 3.934547 , acc is: 0.09375 , iter= 2769
current loss is: 3.8288815 , acc is: 0.078125 , iter= 2770
current loss is: 3.984017 , acc is: 0.046875 , iter= 2771
current loss is: 4.0720525 , acc is: 0.0625 , iter= 2772
current loss is: 3.8630085 , acc is: 0.078125 , iter= 2773
current loss is: 4.1114807 , acc is: 0.078125 , iter= 2774
current loss is: 3.9366274 , acc is: 0.0625 , iter= 2775
current loss is: 3.9261348 , acc is: 0.0625 , iter= 2776
current loss is: 4.1005297 , acc is: 0.015625 , iter= 2777
current loss is: 4.019084 , acc is: 0.046875 , iter= 2778
current loss is: 4.0987215 , acc is: 0.046875 , iter= 2779
current loss is: 4.033312 , acc is: 0.03125 , iter= 2780
current loss is: 3.8751688 , acc is: 0.078125 , iter= 2781
current loss is: 3.9490633 , acc is: 0.078125 , iter= 2782
current loss is: 4.029258 , acc is: 0.0625 , iter= 2783
current loss is: 3.805811 , acc is: 0.09375 , iter= 2784
current loss is: 4.130329 , acc is: 0.0625 , iter= 2785
current loss is: 3.8394358 , acc is: 0.0625 , iter= 2786
current loss is: 4.045951 , acc is: 0.015625 , iter= 2787
current loss is: 4.08414 , acc is: 0.015625 , iter= 2788
current loss is: 4.0173135 , acc is: 0.046875 , iter= 2789
current loss is: 4.009842 , acc is: 0.0625 , iter= 2790
current loss is: 4.01298 , acc is: 0.046875 , iter= 2791
current loss is: 6.121886 , acc is: 0.046875 , iter= 2792
current loss is: 3.972433 , acc is: 0.0625 , iter= 2793
current loss is: 3.8443751 , acc is: 0.078125 , iter= 2794
current loss is: 4.107799 , acc is: 0.03125 , iter= 2795
current loss is: 3.9357057 , acc is: 0.078125 , iter= 2796
current loss is: 4.01454 , acc is: 0.046875 , iter= 2797
current loss is: 4.1713705 , acc is: 0.046875 , iter= 2798
current loss is: 3.9456878 , acc is: 0.078125 , iter= 2799
current loss is: 4.1240463 , acc is: 0.015625 , iter= 2800
current loss is: 4.0020523 , acc is: 0.03125 , iter= 2801
current loss is: 4.12237 , acc is: 0.0 , iter= 2802
current loss is: 4.055189 , acc is: 0.046875 , iter= 2803
current loss is: 4.046179 , acc is: 0.09375 , iter= 2804
current loss is: 3.7478 , acc is: 0.09375 , iter= 2805
current loss is: 3.9323168 , acc is: 0.09375 , iter= 2806
current loss is: 3.864897 , acc is: 0.0625 , iter= 2807
current loss is: 3.9514678 , acc is: 0.078125 , iter= 2808
current loss is: 4.5890326 , acc is: 0.078125 , iter= 2809
current loss is: 3.9528556 , acc is: 0.0625 , iter= 2810
current loss is: 5.0932846 , acc is: 0.046875 , iter= 2811
current loss is: 4.0838056 , acc is: 0.046875 , iter= 2812
current loss is: 4.0563025 , acc is: 0.046875 , iter= 2813
current loss is: 3.9426556 , acc is: 0.046875 , iter= 2814
current loss is: 3.9759305 , acc is: 0.046875 , iter= 2815
current loss is: 3.7592654 , acc is: 0.109375 , iter= 2816
current loss is: 4.0510917 , acc is: 0.0625 , iter= 2817
current loss is: 4.0203648 , acc is: 0.046875 , iter= 2818
current loss is: 10.51631 , acc is: 0.0625 , iter= 2819
current loss is: 4.0229383 , acc is: 0.046875 , iter= 2820
current loss is: 3.9009519 , acc is: 0.078125 , iter= 2821
current loss is: 4.05711 , acc is: 0.015625 , iter= 2822
current loss is: 4.2037683 , acc is: 0.078125 , iter= 2823
current loss is: 3.962444 , acc is: 0.078125 , iter= 2824
current loss is: 4.169512 , acc is: 0.015625 , iter= 2825
current loss is: 3.91822 , acc is: 0.09375 , iter= 2826
current loss is: 3.9566512 , acc is: 0.109375 , iter= 2827
current loss is: 3.970196 , acc is: 0.0625 , iter= 2828
current loss is: 4.0300636 , acc is: 0.046875 , iter= 2829
current loss is: 3.9849315 , acc is: 0.046875 , iter= 2830
current loss is: 4.025098 , acc is: 0.0625 , iter= 2831
current loss is: 10.459962 , acc is: 0.015625 , iter= 2832
current loss is: 4.160104 , acc is: 0.0 , iter= 2833
current loss is: 4.0806475 , acc is: 0.046875 , iter= 2834
current loss is: 3.9669368 , acc is: 0.046875 , iter= 2835
current loss is: 4.1462708 , acc is: 0.046875 , iter= 2836
current loss is: 4.003212 , acc is: 0.03125 , iter= 2837
current loss is: 3.8382473 , acc is: 0.09375 , iter= 2838
current loss is: 4.347327 , acc is: 0.0 , iter= 2839
current loss is: 3.930368 , acc is: 0.078125 , iter= 2840
current loss is: 4.0349836 , acc is: 0.046875 , iter= 2841
current loss is: 4.1933584 , acc is: 0.046875 , iter= 2842
current loss is: 5.720822 , acc is: 0.0625 , iter= 2843
current loss is: 6.4564 , acc is: 0.046875 , iter= 2844
current loss is: 3.9718485 , acc is: 0.0625 , iter= 2845
current loss is: 4.0268974 , acc is: 0.0625 , iter= 2846
current loss is: 4.0125623 , acc is: 0.0625 , iter= 2847
current loss is: 3.974835 , acc is: 0.0625 , iter= 2848
current loss is: 3.8906922 , acc is: 0.0625 , iter= 2849
current loss is: 4.0216956 , acc is: 0.0625 , iter= 2850
current loss is: 4.0978756 , acc is: 0.03125 , iter= 2851
current loss is: 4.1750903 , acc is: 0.0 , iter= 2852
current loss is: 3.9749079 , acc is: 0.046875 , iter= 2853
current loss is: 4.1458654 , acc is: 0.015625 , iter= 2854
current loss is: 4.122018 , acc is: 0.046875 , iter= 2855
current loss is: 3.715053 , acc is: 0.171875 , iter= 2856
current loss is: 4.015363 , acc is: 0.0625 , iter= 2857
current loss is: 4.079961 , acc is: 0.0625 , iter= 2858
current loss is: 3.9984078 , acc is: 0.046875 , iter= 2859
current loss is: 4.090789 , acc is: 0.03125 , iter= 2860
current loss is: 3.9094436 , acc is: 0.0625 , iter= 2861
current loss is: 4.040659 , acc is: 0.03125 , iter= 2862
current loss is: 3.8945837 , acc is: 0.09375 , iter= 2863
current loss is: 3.8445563 , acc is: 0.078125 , iter= 2864
current loss is: 4.0394297 , acc is: 0.03125 , iter= 2865
current loss is: 3.8279428 , acc is: 0.09375 , iter= 2866
current loss is: 4.0250645 , acc is: 0.046875 , iter= 2867
current loss is: 4.02824 , acc is: 0.0625 , iter= 2868
current loss is: 3.9786477 , acc is: 0.046875 , iter= 2869
current loss is: 3.8920684 , acc is: 0.09375 , iter= 2870
current loss is: 4.175457 , acc is: 0.046875 , iter= 2871
current loss is: 4.125856 , acc is: 0.0 , iter= 2872
current loss is: 3.9934201 , acc is: 0.09375 , iter= 2873
current loss is: 4.0537653 , acc is: 0.015625 , iter= 2874
current loss is: 3.9490433 , acc is: 0.078125 , iter= 2875
current loss is: 4.0083976 , acc is: 0.046875 , iter= 2876
current loss is: 3.8619852 , acc is: 0.109375 , iter= 2877
current loss is: 4.0579677 , acc is: 0.03125 , iter= 2878
current loss is: 4.1366634 , acc is: 0.03125 , iter= 2879
current loss is: 4.1641254 , acc is: 0.03125 , iter= 2880
current loss is: 3.8934195 , acc is: 0.0625 , iter= 2881
current loss is: 3.9380155 , acc is: 0.09375 , iter= 2882
current loss is: 4.1446857 , acc is: 0.046875 , iter= 2883
current loss is: 4.1107683 , acc is: 0.046875 , iter= 2884
current loss is: 3.9803245 , acc is: 0.03125 , iter= 2885
current loss is: 4.1396747 , acc is: 0.03125 , iter= 2886
current loss is: 3.906767 , acc is: 0.078125 , iter= 2887
current loss is: 3.9386017 , acc is: 0.078125 , iter= 2888
current loss is: 3.9578052 , acc is: 0.046875 , iter= 2889
current loss is: 3.8375144 , acc is: 0.078125 , iter= 2890
current loss is: 4.08101 , acc is: 0.03125 , iter= 2891
current loss is: 4.2551436 , acc is: 0.03125 , iter= 2892
current loss is: 4.0533733 , acc is: 0.046875 , iter= 2893
current loss is: 4.0283794 , acc is: 0.03125 , iter= 2894
current loss is: 4.033474 , acc is: 0.046875 , iter= 2895
current loss is: 4.054185 , acc is: 0.078125 , iter= 2896
current loss is: 4.0477953 , acc is: 0.046875 , iter= 2897
current loss is: 3.9798357 , acc is: 0.046875 , iter= 2898
current loss is: 4.1403847 , acc is: 0.0 , iter= 2899
current loss is: 3.9951925 , acc is: 0.078125 , iter= 2900
current loss is: 4.2489233 , acc is: 0.03125 , iter= 2901
current loss is: 3.9539769 , acc is: 0.046875 , iter= 2902
current loss is: 3.988198 , acc is: 0.03125 , iter= 2903
current loss is: 4.051488 , acc is: 0.03125 , iter= 2904
current loss is: 6.6401 , acc is: 0.0625 , iter= 2905
current loss is: 3.8513746 , acc is: 0.0625 , iter= 2906
current loss is: 4.060176 , acc is: 0.015625 , iter= 2907
current loss is: 3.7132154 , acc is: 0.109375 , iter= 2908
current loss is: 4.0775633 , acc is: 0.03125 , iter= 2909
current loss is: 4.048193 , acc is: 0.015625 , iter= 2910
current loss is: 4.1657724 , acc is: 0.03125 , iter= 2911
current loss is: 4.0788527 , acc is: 0.046875 , iter= 2912
current loss is: 4.0062447 , acc is: 0.0625 , iter= 2913
current loss is: 3.933031 , acc is: 0.09375 , iter= 2914
current loss is: 3.9568686 , acc is: 0.078125 , iter= 2915
current loss is: 4.050082 , acc is: 0.0625 , iter= 2916
current loss is: 4.046769 , acc is: 0.0625 , iter= 2917
current loss is: 4.1818027 , acc is: 0.09375 , iter= 2918
current loss is: 4.03536 , acc is: 0.03125 , iter= 2919
current loss is: 4.017778 , acc is: 0.03125 , iter= 2920
current loss is: 4.1557097 , acc is: 0.0625 , iter= 2921
current loss is: 4.1391726 , acc is: 0.03125 , iter= 2922
current loss is: 4.017113 , acc is: 0.0625 , iter= 2923
current loss is: 3.997307 , acc is: 0.046875 , iter= 2924
current loss is: 4.1550083 , acc is: 0.0 , iter= 2925
current loss is: 4.1142035 , acc is: 0.015625 , iter= 2926
current loss is: 3.624548 , acc is: 0.125 , iter= 2927
current loss is: 4.0467176 , acc is: 0.0625 , iter= 2928
current loss is: 3.9725013 , acc is: 0.0625 , iter= 2929
current loss is: 4.0827875 , acc is: 0.0625 , iter= 2930
current loss is: 4.0644054 , acc is: 0.046875 , iter= 2931
current loss is: 4.027676 , acc is: 0.046875 , iter= 2932
current loss is: 6.482647 , acc is: 0.078125 , iter= 2933
current loss is: 4.039435 , acc is: 0.046875 , iter= 2934
current loss is: 3.977792 , acc is: 0.0625 , iter= 2935
current loss is: 4.0310674 , acc is: 0.046875 , iter= 2936
current loss is: 4.062997 , acc is: 0.03125 , iter= 2937
current loss is: 3.8997424 , acc is: 0.0625 , iter= 2938
current loss is: 4.025979 , acc is: 0.046875 , iter= 2939
current loss is: 3.8639417 , acc is: 0.078125 , iter= 2940
current loss is: 4.0912995 , acc is: 0.046875 , iter= 2941
current loss is: 4.141923 , acc is: 0.03125 , iter= 2942
current loss is: 3.7677422 , acc is: 0.125 , iter= 2943
current loss is: 3.9598782 , acc is: 0.046875 , iter= 2944
current loss is: 4.060072 , acc is: 0.0625 , iter= 2945
current loss is: 3.9619675 , acc is: 0.046875 , iter= 2946
current loss is: 4.0408716 , acc is: 0.03125 , iter= 2947
current loss is: 4.069146 , acc is: 0.03125 , iter= 2948
current loss is: 3.9609637 , acc is: 0.078125 , iter= 2949
current loss is: 3.902941 , acc is: 0.078125 , iter= 2950
current loss is: 4.3083 , acc is: 0.015625 , iter= 2951
current loss is: 4.09228 , acc is: 0.03125 , iter= 2952
current loss is: 4.047817 , acc is: 0.0625 , iter= 2953
current loss is: 4.048925 , acc is: 0.0625 , iter= 2954
current loss is: 5.0631227 , acc is: 0.03125 , iter= 2955
current loss is: 3.868915 , acc is: 0.109375 , iter= 2956
current loss is: 3.9343758 , acc is: 0.046875 , iter= 2957
current loss is: 4.0355773 , acc is: 0.046875 , iter= 2958
current loss is: 3.7688587 , acc is: 0.109375 , iter= 2959
current loss is: 4.111981 , acc is: 0.046875 , iter= 2960
current loss is: 4.0851808 , acc is: 0.046875 , iter= 2961
current loss is: 3.811639 , acc is: 0.09375 , iter= 2962
current loss is: 4.0313306 , acc is: 0.046875 , iter= 2963
current loss is: 3.9714632 , acc is: 0.03125 , iter= 2964
current loss is: 4.1199303 , acc is: 0.03125 , iter= 2965
current loss is: 3.8388703 , acc is: 0.109375 , iter= 2966
current loss is: 16.754333 , acc is: 0.046875 , iter= 2967
current loss is: 4.0718155 , acc is: 0.0625 , iter= 2968
current loss is: 4.010323 , acc is: 0.03125 , iter= 2969
current loss is: 3.9260356 , acc is: 0.046875 , iter= 2970
current loss is: 3.9752119 , acc is: 0.046875 , iter= 2971
current loss is: 4.448646 , acc is: 0.03125 , iter= 2972
current loss is: 4.01805 , acc is: 0.078125 , iter= 2973
current loss is: 3.792758 , acc is: 0.109375 , iter= 2974
current loss is: 4.0066032 , acc is: 0.046875 , iter= 2975
current loss is: 3.9461462 , acc is: 0.078125 , iter= 2976
current loss is: 3.88873 , acc is: 0.09375 , iter= 2977
current loss is: 3.8446977 , acc is: 0.0625 , iter= 2978
current loss is: 5.281732 , acc is: 0.03125 , iter= 2979
current loss is: 4.0435133 , acc is: 0.046875 , iter= 2980
current loss is: 4.022114 , acc is: 0.03125 , iter= 2981
current loss is: 5.4289017 , acc is: 0.078125 , iter= 2982
current loss is: 4.4416037 , acc is: 0.03125 , iter= 2983
current loss is: 4.1795044 , acc is: 0.015625 , iter= 2984
current loss is: 3.9162874 , acc is: 0.078125 , iter= 2985
current loss is: 3.8610406 , acc is: 0.09375 , iter= 2986
current loss is: 4.039174 , acc is: 0.046875 , iter= 2987
current loss is: 3.9337506 , acc is: 0.0625 , iter= 2988
current loss is: 4.023761 , acc is: 0.0625 , iter= 2989
current loss is: 4.0099964 , acc is: 0.046875 , iter= 2990
current loss is: 4.124099 , acc is: 0.03125 , iter= 2991
current loss is: 4.1312475 , acc is: 0.015625 , iter= 2992
current loss is: 4.085144 , acc is: 0.015625 , iter= 2993
current loss is: 3.9394488 , acc is: 0.0625 , iter= 2994
current loss is: 3.9033463 , acc is: 0.078125 , iter= 2995
current loss is: 4.0396347 , acc is: 0.03125 , iter= 2996
current loss is: 3.947862 , acc is: 0.046875 , iter= 2997
current loss is: 4.1561017 , acc is: 0.015625 , iter= 2998
current loss is: 4.077154 , acc is: 0.046875 , iter= 2999
current loss is: 4.0873365 , acc is: 0.015625 , iter= 3000
tot_acc= 20.0 tot_input= 768
current accuracy is: 0.026041666666666668
current loss is: 3.9182925 , acc is: 0.0625 , iter= 3001
current loss is: 3.9599729 , acc is: 0.09375 , iter= 3002
current loss is: 3.8501046 , acc is: 0.078125 , iter= 3003
current loss is: 3.8215232 , acc is: 0.09375 , iter= 3004
current loss is: 3.956611 , acc is: 0.046875 , iter= 3005
current loss is: 3.8325105 , acc is: 0.09375 , iter= 3006
current loss is: 4.178416 , acc is: 0.015625 , iter= 3007
current loss is: 4.1208735 , acc is: 0.015625 , iter= 3008
current loss is: 4.0758805 , acc is: 0.015625 , iter= 3009
current loss is: 4.094887 , acc is: 0.046875 , iter= 3010
current loss is: 4.102687 , acc is: 0.015625 , iter= 3011
current loss is: 4.054745 , acc is: 0.03125 , iter= 3012
current loss is: 4.0707126 , acc is: 0.0625 , iter= 3013
current loss is: 4.1134577 , acc is: 0.0625 , iter= 3014
current loss is: 3.9110236 , acc is: 0.09375 , iter= 3015
current loss is: 3.9570937 , acc is: 0.0625 , iter= 3016
current loss is: 3.9576273 , acc is: 0.046875 , iter= 3017
current loss is: 4.003473 , acc is: 0.046875 , iter= 3018
current loss is: 3.9726396 , acc is: 0.0625 , iter= 3019
current loss is: 4.5159655 , acc is: 0.03125 , iter= 3020
current loss is: 4.0670333 , acc is: 0.03125 , iter= 3021
current loss is: 4.3434925 , acc is: 0.046875 , iter= 3022
current loss is: 3.8693027 , acc is: 0.109375 , iter= 3023
current loss is: 3.9921231 , acc is: 0.03125 , iter= 3024
current loss is: 4.0372005 , acc is: 0.0625 , iter= 3025
current loss is: 4.023534 , acc is: 0.0625 , iter= 3026
current loss is: 4.029557 , acc is: 0.0625 , iter= 3027
current loss is: 3.968124 , acc is: 0.03125 , iter= 3028
current loss is: 3.9300783 , acc is: 0.078125 , iter= 3029
current loss is: 4.0070834 , acc is: 0.0625 , iter= 3030
current loss is: 4.1125784 , acc is: 0.03125 , iter= 3031
current loss is: 4.4614778 , acc is: 0.0 , iter= 3032
current loss is: 3.9446964 , acc is: 0.078125 , iter= 3033
current loss is: 3.9509082 , acc is: 0.078125 , iter= 3034
current loss is: 3.8385756 , acc is: 0.09375 , iter= 3035
current loss is: 3.9361343 , acc is: 0.046875 , iter= 3036
current loss is: 3.8561945 , acc is: 0.09375 , iter= 3037
current loss is: 4.066708 , acc is: 0.03125 , iter= 3038
current loss is: 3.8594785 , acc is: 0.078125 , iter= 3039
current loss is: 4.204589 , acc is: 0.0 , iter= 3040
current loss is: 5.42357 , acc is: 0.03125 , iter= 3041
current loss is: 3.979444 , acc is: 0.0625 , iter= 3042
current loss is: 4.0247645 , acc is: 0.0625 , iter= 3043
current loss is: 4.1731777 , acc is: 0.0625 , iter= 3044
current loss is: 4.130479 , acc is: 0.015625 , iter= 3045
current loss is: 4.177323 , acc is: 0.0 , iter= 3046
current loss is: 4.036255 , acc is: 0.0625 , iter= 3047
current loss is: 3.9909906 , acc is: 0.03125 , iter= 3048
current loss is: 4.1025186 , acc is: 0.015625 , iter= 3049
current loss is: 4.012951 , acc is: 0.078125 , iter= 3050
current loss is: 4.142301 , acc is: 0.0625 , iter= 3051
current loss is: 4.0471873 , acc is: 0.078125 , iter= 3052
current loss is: 4.0259356 , acc is: 0.078125 , iter= 3053
current loss is: 3.8349395 , acc is: 0.09375 , iter= 3054
current loss is: 4.0395975 , acc is: 0.03125 , iter= 3055
current loss is: 4.0756507 , acc is: 0.03125 , iter= 3056
current loss is: 4.1082983 , acc is: 0.03125 , iter= 3057
current loss is: 4.129451 , acc is: 0.046875 , iter= 3058
current loss is: 3.867991 , acc is: 0.09375 , iter= 3059
current loss is: 4.1452665 , acc is: 0.015625 , iter= 3060
current loss is: 4.0804276 , acc is: 0.046875 , iter= 3061
current loss is: 4.1065326 , acc is: 0.0625 , iter= 3062
current loss is: 3.8530564 , acc is: 0.125 , iter= 3063
current loss is: 4.0416427 , acc is: 0.03125 , iter= 3064
current loss is: 4.109265 , acc is: 0.015625 , iter= 3065
current loss is: 4.073841 , acc is: 0.046875 , iter= 3066
current loss is: 4.129611 , acc is: 0.046875 , iter= 3067
current loss is: 3.9802775 , acc is: 0.0625 , iter= 3068
current loss is: 4.071533 , acc is: 0.015625 , iter= 3069
current loss is: 3.930048 , acc is: 0.125 , iter= 3070
current loss is: 4.0528193 , acc is: 0.046875 , iter= 3071
current loss is: 3.948129 , acc is: 0.0625 , iter= 3072
current loss is: 4.119384 , acc is: 0.046875 , iter= 3073
current loss is: 4.1215982 , acc is: 0.03125 , iter= 3074
current loss is: 4.0092564 , acc is: 0.046875 , iter= 3075
current loss is: 3.8701687 , acc is: 0.0625 , iter= 3076
current loss is: 3.9663498 , acc is: 0.03125 , iter= 3077
current loss is: 3.9485483 , acc is: 0.0625 , iter= 3078
current loss is: 3.8969789 , acc is: 0.09375 , iter= 3079
current loss is: 3.9565954 , acc is: 0.046875 , iter= 3080
current loss is: 4.001016 , acc is: 0.03125 , iter= 3081
current loss is: 4.043984 , acc is: 0.046875 , iter= 3082
current loss is: 3.880675 , acc is: 0.078125 , iter= 3083
current loss is: 3.904686 , acc is: 0.078125 , iter= 3084
current loss is: 5.1202583 , acc is: 0.15625 , iter= 3085
current loss is: 4.116832 , acc is: 0.015625 , iter= 3086
current loss is: 3.8382468 , acc is: 0.109375 , iter= 3087
current loss is: 4.4056606 , acc is: 0.03125 , iter= 3088
current loss is: 3.9705472 , acc is: 0.046875 , iter= 3089
current loss is: 3.8963084 , acc is: 0.0625 , iter= 3090
current loss is: 4.0930843 , acc is: 0.03125 , iter= 3091
current loss is: 4.0685687 , acc is: 0.03125 , iter= 3092
current loss is: 4.0782804 , acc is: 0.078125 , iter= 3093
current loss is: 4.0432158 , acc is: 0.015625 , iter= 3094
current loss is: 3.7981079 , acc is: 0.09375 , iter= 3095
current loss is: 4.0859747 , acc is: 0.03125 , iter= 3096
current loss is: 3.9747045 , acc is: 0.046875 , iter= 3097
current loss is: 4.0041056 , acc is: 0.03125 , iter= 3098
current loss is: 4.029339 , acc is: 0.046875 , iter= 3099
current loss is: 3.9444308 , acc is: 0.0625 , iter= 3100
current loss is: 4.035388 , acc is: 0.046875 , iter= 3101
current loss is: 4.0682235 , acc is: 0.046875 , iter= 3102
current loss is: 4.008151 , acc is: 0.03125 , iter= 3103
current loss is: 4.1789045 , acc is: 0.015625 , iter= 3104
current loss is: 4.117545 , acc is: 0.0625 , iter= 3105
current loss is: 3.9258013 , acc is: 0.09375 , iter= 3106
current loss is: 3.9078124 , acc is: 0.09375 , iter= 3107
current loss is: 3.9407725 , acc is: 0.078125 , iter= 3108
current loss is: 3.9531164 , acc is: 0.046875 , iter= 3109
current loss is: 3.8764324 , acc is: 0.109375 , iter= 3110
current loss is: 3.9011369 , acc is: 0.046875 , iter= 3111
current loss is: 4.0867643 , acc is: 0.046875 , iter= 3112
current loss is: 4.001135 , acc is: 0.09375 , iter= 3113
current loss is: 4.0820794 , acc is: 0.03125 , iter= 3114
current loss is: 4.055742 , acc is: 0.0625 , iter= 3115
current loss is: 4.040276 , acc is: 0.03125 , iter= 3116
current loss is: 3.8821702 , acc is: 0.078125 , iter= 3117
current loss is: 3.9265392 , acc is: 0.09375 , iter= 3118
current loss is: 3.8511028 , acc is: 0.0625 , iter= 3119
current loss is: 3.8618212 , acc is: 0.09375 , iter= 3120
current loss is: 4.61743 , acc is: 0.09375 , iter= 3121
current loss is: 4.09133 , acc is: 0.0625 , iter= 3122
current loss is: 4.0759583 , acc is: 0.0625 , iter= 3123
current loss is: 4.0872145 , acc is: 0.03125 , iter= 3124
current loss is: 4.033467 , acc is: 0.046875 , iter= 3125
current loss is: 4.014277 , acc is: 0.0625 , iter= 3126
current loss is: 4.027557 , acc is: 0.109375 , iter= 3127
current loss is: 3.9625323 , acc is: 0.046875 , iter= 3128
current loss is: 4.0445633 , acc is: 0.046875 , iter= 3129
current loss is: 3.9318254 , acc is: 0.0625 , iter= 3130
current loss is: 4.1636114 , acc is: 0.015625 , iter= 3131
current loss is: 4.0315194 , acc is: 0.03125 , iter= 3132
current loss is: 3.8171864 , acc is: 0.09375 , iter= 3133
current loss is: 4.1116486 , acc is: 0.046875 , iter= 3134
current loss is: 3.9206958 , acc is: 0.0625 , iter= 3135
current loss is: 3.9691322 , acc is: 0.046875 , iter= 3136
current loss is: 3.9941945 , acc is: 0.03125 , iter= 3137
current loss is: 4.0671396 , acc is: 0.015625 , iter= 3138
current loss is: 3.9649494 , acc is: 0.0625 , iter= 3139
current loss is: 4.1787696 , acc is: 0.015625 , iter= 3140
current loss is: 4.1136723 , acc is: 0.0625 , iter= 3141
current loss is: 3.7699819 , acc is: 0.09375 , iter= 3142
current loss is: 4.121512 , acc is: 0.015625 , iter= 3143
current loss is: 3.9769902 , acc is: 0.046875 , iter= 3144
current loss is: 4.032049 , acc is: 0.03125 , iter= 3145
current loss is: 4.207963 , acc is: 0.03125 , iter= 3146
current loss is: 4.16256 , acc is: 0.015625 , iter= 3147
current loss is: 3.9016066 , acc is: 0.0625 , iter= 3148
current loss is: 4.4278893 , acc is: 0.0625 , iter= 3149
current loss is: 3.8875554 , acc is: 0.109375 , iter= 3150
current loss is: 4.027318 , acc is: 0.0625 , iter= 3151
current loss is: 4.02472 , acc is: 0.03125 , iter= 3152
current loss is: 3.7193742 , acc is: 0.109375 , iter= 3153
current loss is: 4.027935 , acc is: 0.03125 , iter= 3154
current loss is: 4.0604353 , acc is: 0.0625 , iter= 3155
current loss is: 4.066143 , acc is: 0.078125 , iter= 3156
current loss is: 3.9054015 , acc is: 0.078125 , iter= 3157
current loss is: 3.8235223 , acc is: 0.109375 , iter= 3158
current loss is: 3.892879 , acc is: 0.09375 , iter= 3159
current loss is: 4.044547 , acc is: 0.03125 , iter= 3160
current loss is: 4.1477885 , acc is: 0.0 , iter= 3161
current loss is: 3.889031 , acc is: 0.0625 , iter= 3162
current loss is: 3.997038 , acc is: 0.03125 , iter= 3163
current loss is: 3.8363593 , acc is: 0.078125 , iter= 3164
current loss is: 4.154172 , acc is: 0.015625 , iter= 3165
current loss is: 3.9173644 , acc is: 0.078125 , iter= 3166
current loss is: 3.9797502 , acc is: 0.0625 , iter= 3167
current loss is: 3.9650607 , acc is: 0.0625 , iter= 3168
current loss is: 4.04309 , acc is: 0.03125 , iter= 3169
current loss is: 3.8785224 , acc is: 0.078125 , iter= 3170
current loss is: 3.9785266 , acc is: 0.046875 , iter= 3171
current loss is: 4.0583963 , acc is: 0.03125 , iter= 3172
current loss is: 4.012413 , acc is: 0.09375 , iter= 3173
current loss is: 3.920404 , acc is: 0.078125 , iter= 3174
current loss is: 4.113201 , acc is: 0.015625 , iter= 3175
current loss is: 4.0679035 , acc is: 0.046875 , iter= 3176
current loss is: 3.967216 , acc is: 0.0625 , iter= 3177
current loss is: 3.9825788 , acc is: 0.046875 , iter= 3178
current loss is: 4.156964 , acc is: 0.015625 , iter= 3179
current loss is: 4.1630325 , acc is: 0.015625 , iter= 3180
current loss is: 4.0323453 , acc is: 0.046875 , iter= 3181
current loss is: 3.9936628 , acc is: 0.046875 , iter= 3182
current loss is: 4.0875044 , acc is: 0.015625 , iter= 3183
current loss is: 3.794613 , acc is: 0.078125 , iter= 3184
current loss is: 3.7778945 , acc is: 0.09375 , iter= 3185
current loss is: 4.063505 , acc is: 0.03125 , iter= 3186
current loss is: 4.0884843 , acc is: 0.046875 , iter= 3187
current loss is: 4.1053667 , acc is: 0.046875 , iter= 3188
current loss is: 4.028333 , acc is: 0.046875 , iter= 3189
current loss is: 4.0726995 , acc is: 0.015625 , iter= 3190
current loss is: 3.9314537 , acc is: 0.046875 , iter= 3191
current loss is: 4.0621576 , acc is: 0.03125 , iter= 3192
current loss is: 3.9776368 , acc is: 0.046875 , iter= 3193
current loss is: 4.0402117 , acc is: 0.03125 , iter= 3194
current loss is: 3.9064178 , acc is: 0.078125 , iter= 3195
current loss is: 4.047503 , acc is: 0.046875 , iter= 3196
current loss is: 3.9360065 , acc is: 0.09375 , iter= 3197
current loss is: 4.061474 , acc is: 0.0625 , iter= 3198
current loss is: 4.1274915 , acc is: 0.015625 , iter= 3199
current loss is: 4.038465 , acc is: 0.03125 , iter= 3200
current loss is: 4.1104236 , acc is: 0.046875 , iter= 3201
current loss is: 4.0406704 , acc is: 0.015625 , iter= 3202
current loss is: 3.980332 , acc is: 0.078125 , iter= 3203
current loss is: 4.1034393 , acc is: 0.03125 , iter= 3204
current loss is: 4.1342287 , acc is: 0.0 , iter= 3205
current loss is: 3.8216505 , acc is: 0.078125 , iter= 3206
current loss is: 3.945292 , acc is: 0.078125 , iter= 3207
current loss is: 4.128121 , acc is: 0.015625 , iter= 3208
current loss is: 4.005722 , acc is: 0.046875 , iter= 3209
current loss is: 4.0178375 , acc is: 0.078125 , iter= 3210
current loss is: 4.0311723 , acc is: 0.0625 , iter= 3211
current loss is: 3.890355 , acc is: 0.09375 , iter= 3212
current loss is: 4.12529 , acc is: 0.015625 , iter= 3213
current loss is: 3.891636 , acc is: 0.09375 , iter= 3214
current loss is: 3.8338628 , acc is: 0.078125 , iter= 3215
current loss is: 4.1302967 , acc is: 0.015625 , iter= 3216
current loss is: 4.0041537 , acc is: 0.03125 , iter= 3217
current loss is: 4.6934175 , acc is: 0.078125 , iter= 3218
current loss is: 4.1103897 , acc is: 0.03125 , iter= 3219
current loss is: 4.0840306 , acc is: 0.03125 , iter= 3220
current loss is: 4.271223 , acc is: 0.03125 , iter= 3221
current loss is: 4.0397635 , acc is: 0.0625 , iter= 3222
current loss is: 3.8004558 , acc is: 0.0625 , iter= 3223
current loss is: 4.0921493 , acc is: 0.03125 , iter= 3224
current loss is: 4.0129104 , acc is: 0.046875 , iter= 3225
current loss is: 3.872633 , acc is: 0.109375 , iter= 3226
current loss is: 4.0719323 , acc is: 0.0625 , iter= 3227
current loss is: 4.037355 , acc is: 0.03125 , iter= 3228
current loss is: 3.9202602 , acc is: 0.09375 , iter= 3229
current loss is: 3.9975176 , acc is: 0.09375 , iter= 3230
current loss is: 4.012294 , acc is: 0.046875 , iter= 3231
current loss is: 3.9368439 , acc is: 0.078125 , iter= 3232
current loss is: 4.0209312 , acc is: 0.046875 , iter= 3233
current loss is: 4.1518545 , acc is: 0.046875 , iter= 3234
current loss is: 3.942811 , acc is: 0.046875 , iter= 3235
current loss is: 4.45652 , acc is: 0.0625 , iter= 3236
current loss is: 3.910942 , acc is: 0.0625 , iter= 3237
current loss is: 4.0884333 , acc is: 0.015625 , iter= 3238
current loss is: 3.8852315 , acc is: 0.078125 , iter= 3239
current loss is: 4.039237 , acc is: 0.0625 , iter= 3240
current loss is: 4.155613 , acc is: 0.03125 , iter= 3241
current loss is: 3.9074202 , acc is: 0.0625 , iter= 3242
current loss is: 4.009985 , acc is: 0.0625 , iter= 3243
current loss is: 3.8467917 , acc is: 0.078125 , iter= 3244
current loss is: 3.9295728 , acc is: 0.078125 , iter= 3245
current loss is: 4.0318995 , acc is: 0.046875 , iter= 3246
current loss is: 4.2174587 , acc is: 0.09375 , iter= 3247
current loss is: 4.180416 , acc is: 0.015625 , iter= 3248
current loss is: 4.100852 , acc is: 0.09375 , iter= 3249
current loss is: 4.0853252 , acc is: 0.046875 , iter= 3250
current loss is: 4.086589 , acc is: 0.0625 , iter= 3251
current loss is: 3.8442674 , acc is: 0.078125 , iter= 3252
current loss is: 4.0437255 , acc is: 0.03125 , iter= 3253
current loss is: 3.98251 , acc is: 0.0625 , iter= 3254
current loss is: 4.087589 , acc is: 0.015625 , iter= 3255
current loss is: 3.9483652 , acc is: 0.0625 , iter= 3256
current loss is: 3.933265 , acc is: 0.078125 , iter= 3257
current loss is: 3.933077 , acc is: 0.109375 , iter= 3258
current loss is: 4.1203465 , acc is: 0.03125 , iter= 3259
current loss is: 3.7748713 , acc is: 0.109375 , iter= 3260
current loss is: 3.9369454 , acc is: 0.0625 , iter= 3261
current loss is: 4.6140337 , acc is: 0.109375 , iter= 3262
current loss is: 4.172862 , acc is: 0.046875 , iter= 3263
current loss is: 4.0902815 , acc is: 0.03125 , iter= 3264
current loss is: 4.0033655 , acc is: 0.09375 , iter= 3265
current loss is: 4.0272713 , acc is: 0.046875 , iter= 3266
current loss is: 4.0320683 , acc is: 0.03125 , iter= 3267
current loss is: 4.143205 , acc is: 0.015625 , iter= 3268
current loss is: 3.8622663 , acc is: 0.0625 , iter= 3269
current loss is: 3.8521419 , acc is: 0.109375 , iter= 3270
current loss is: 3.9220655 , acc is: 0.046875 , iter= 3271
current loss is: 4.089917 , acc is: 0.03125 , iter= 3272
current loss is: 4.0782413 , acc is: 0.046875 , iter= 3273
current loss is: 4.1249948 , acc is: 0.046875 , iter= 3274
current loss is: 3.969061 , acc is: 0.0625 , iter= 3275
current loss is: 4.0940604 , acc is: 0.03125 , iter= 3276
current loss is: 4.2981834 , acc is: 0.015625 , iter= 3277
current loss is: 3.9010932 , acc is: 0.078125 , iter= 3278
current loss is: 4.1710043 , acc is: 0.03125 , iter= 3279
current loss is: 4.0197163 , acc is: 0.046875 , iter= 3280
current loss is: 4.1664104 , acc is: 0.03125 , iter= 3281
current loss is: 3.7651088 , acc is: 0.109375 , iter= 3282
current loss is: 4.1162567 , acc is: 0.03125 , iter= 3283
current loss is: 4.520507 , acc is: 0.03125 , iter= 3284
current loss is: 4.1148343 , acc is: 0.046875 , iter= 3285
current loss is: 4.067979 , acc is: 0.078125 , iter= 3286
current loss is: 4.0533986 , acc is: 0.03125 , iter= 3287
current loss is: 3.8161883 , acc is: 0.109375 , iter= 3288
current loss is: 4.045559 , acc is: 0.03125 , iter= 3289
current loss is: 3.9744978 , acc is: 0.046875 , iter= 3290
current loss is: 4.0278816 , acc is: 0.046875 , iter= 3291
current loss is: 3.9937217 , acc is: 0.09375 , iter= 3292
current loss is: 4.0218477 , acc is: 0.046875 , iter= 3293
current loss is: 3.9759889 , acc is: 0.078125 , iter= 3294
current loss is: 4.147777 , acc is: 0.015625 , iter= 3295
current loss is: 3.8660545 , acc is: 0.078125 , iter= 3296
current loss is: 4.016499 , acc is: 0.03125 , iter= 3297
current loss is: 4.112164 , acc is: 0.03125 , iter= 3298
current loss is: 3.8112285 , acc is: 0.09375 , iter= 3299
current loss is: 4.03295 , acc is: 0.046875 , iter= 3300
current loss is: 4.089184 , acc is: 0.03125 , iter= 3301
current loss is: 4.0809283 , acc is: 0.03125 , iter= 3302
current loss is: 3.8688853 , acc is: 0.0625 , iter= 3303
current loss is: 3.9533315 , acc is: 0.078125 , iter= 3304
current loss is: 3.9567459 , acc is: 0.0625 , iter= 3305
current loss is: 4.117564 , acc is: 0.015625 , iter= 3306
current loss is: 3.874949 , acc is: 0.078125 , iter= 3307
current loss is: 4.131835 , acc is: 0.03125 , iter= 3308
current loss is: 3.8843687 , acc is: 0.125 , iter= 3309
current loss is: 4.1386404 , acc is: 0.03125 , iter= 3310
current loss is: 3.8324442 , acc is: 0.078125 , iter= 3311
current loss is: 3.9649568 , acc is: 0.078125 , iter= 3312
current loss is: 3.9550767 , acc is: 0.046875 , iter= 3313
current loss is: 3.9712822 , acc is: 0.109375 , iter= 3314
current loss is: 3.8502746 , acc is: 0.078125 , iter= 3315
current loss is: 4.0143547 , acc is: 0.0625 , iter= 3316
current loss is: 3.8705742 , acc is: 0.125 , iter= 3317
current loss is: 4.058977 , acc is: 0.03125 , iter= 3318
current loss is: 4.048939 , acc is: 0.0625 , iter= 3319
current loss is: 3.9324374 , acc is: 0.078125 , iter= 3320
current loss is: 3.80098 , acc is: 0.09375 , iter= 3321
current loss is: 3.9653702 , acc is: 0.0625 , iter= 3322
current loss is: 4.116166 , acc is: 0.046875 , iter= 3323
current loss is: 4.031482 , acc is: 0.078125 , iter= 3324
current loss is: 4.040781 , acc is: 0.015625 , iter= 3325
current loss is: 3.970446 , acc is: 0.0625 , iter= 3326
current loss is: 4.129852 , acc is: 0.015625 , iter= 3327
current loss is: 4.0361433 , acc is: 0.046875 , iter= 3328
current loss is: 4.1089067 , acc is: 0.015625 , iter= 3329
current loss is: 3.988011 , acc is: 0.0625 , iter= 3330
current loss is: 3.9861717 , acc is: 0.046875 , iter= 3331
current loss is: 4.1410713 , acc is: 0.03125 , iter= 3332
current loss is: 3.8318224 , acc is: 0.125 , iter= 3333
current loss is: 4.0670424 , acc is: 0.03125 , iter= 3334
current loss is: 4.1023645 , acc is: 0.015625 , iter= 3335
current loss is: 4.0049186 , acc is: 0.046875 , iter= 3336
current loss is: 4.06796 , acc is: 0.015625 , iter= 3337
current loss is: 3.8654323 , acc is: 0.09375 , iter= 3338
current loss is: 4.0046225 , acc is: 0.0625 , iter= 3339
current loss is: 4.1178894 , acc is: 0.0 , iter= 3340
current loss is: 3.9606647 , acc is: 0.078125 , iter= 3341
current loss is: 3.834448 , acc is: 0.078125 , iter= 3342
current loss is: 4.0133944 , acc is: 0.0625 , iter= 3343
current loss is: 3.9021864 , acc is: 0.0625 , iter= 3344
current loss is: 4.9226303 , acc is: 0.046875 , iter= 3345
current loss is: 4.09698 , acc is: 0.0625 , iter= 3346
current loss is: 4.151808 , acc is: 0.0 , iter= 3347
current loss is: 4.003568 , acc is: 0.03125 , iter= 3348
current loss is: 4.0421615 , acc is: 0.03125 , iter= 3349
current loss is: 4.010746 , acc is: 0.03125 , iter= 3350
current loss is: 4.0865335 , acc is: 0.015625 , iter= 3351
current loss is: 4.0470104 , acc is: 0.0625 , iter= 3352
current loss is: 4.005175 , acc is: 0.046875 , iter= 3353
current loss is: 3.945551 , acc is: 0.078125 , iter= 3354
current loss is: 3.8618343 , acc is: 0.078125 , iter= 3355
current loss is: 3.8687234 , acc is: 0.125 , iter= 3356
current loss is: 4.030757 , acc is: 0.046875 , iter= 3357
current loss is: 5.326065 , acc is: 0.03125 , iter= 3358
current loss is: 4.2567716 , acc is: 0.046875 , iter= 3359
current loss is: 3.9679453 , acc is: 0.0625 , iter= 3360
current loss is: 4.110936 , acc is: 0.015625 , iter= 3361
current loss is: 3.8298965 , acc is: 0.078125 , iter= 3362
current loss is: 4.1228504 , acc is: 0.03125 , iter= 3363
current loss is: 4.029579 , acc is: 0.046875 , iter= 3364
current loss is: 4.030078 , acc is: 0.03125 , iter= 3365
current loss is: 3.818175 , acc is: 0.09375 , iter= 3366
current loss is: 3.8359158 , acc is: 0.09375 , iter= 3367
current loss is: 3.938248 , acc is: 0.0625 , iter= 3368
current loss is: 3.9324257 , acc is: 0.0625 , iter= 3369
current loss is: 4.105186 , acc is: 0.03125 , iter= 3370
current loss is: 4.431492 , acc is: 0.046875 , iter= 3371
current loss is: 4.1153126 , acc is: 0.03125 , iter= 3372
current loss is: 4.09232 , acc is: 0.03125 , iter= 3373
current loss is: 4.044467 , acc is: 0.03125 , iter= 3374
current loss is: 4.1003704 , acc is: 0.0 , iter= 3375
current loss is: 3.856709 , acc is: 0.109375 , iter= 3376
current loss is: 4.022607 , acc is: 0.046875 , iter= 3377
current loss is: 4.014431 , acc is: 0.0625 , iter= 3378
current loss is: 4.140437 , acc is: 0.015625 , iter= 3379
current loss is: 4.0772095 , acc is: 0.0625 , iter= 3380
current loss is: 3.92976 , acc is: 0.078125 , iter= 3381
current loss is: 3.803866 , acc is: 0.09375 , iter= 3382
current loss is: 3.9072719 , acc is: 0.09375 , iter= 3383
current loss is: 4.121561 , acc is: 0.015625 , iter= 3384
current loss is: 4.062449 , acc is: 0.015625 , iter= 3385
current loss is: 3.8979445 , acc is: 0.09375 , iter= 3386
current loss is: 4.0493784 , acc is: 0.046875 , iter= 3387
current loss is: 4.21392 , acc is: 0.0 , iter= 3388
current loss is: 4.036464 , acc is: 0.015625 , iter= 3389
current loss is: 6.2196035 , acc is: 0.0625 , iter= 3390
current loss is: 4.044253 , acc is: 0.0625 , iter= 3391
current loss is: 4.016256 , acc is: 0.078125 , iter= 3392
current loss is: 4.0373363 , acc is: 0.046875 , iter= 3393
current loss is: 3.9415193 , acc is: 0.046875 , iter= 3394
current loss is: 4.0709615 , acc is: 0.03125 , iter= 3395
current loss is: 3.9200737 , acc is: 0.078125 , iter= 3396
current loss is: 3.7941463 , acc is: 0.078125 , iter= 3397
current loss is: 4.0531936 , acc is: 0.046875 , iter= 3398
current loss is: 4.0500765 , acc is: 0.03125 , iter= 3399
current loss is: 4.096283 , acc is: 0.0625 , iter= 3400
current loss is: 4.0331087 , acc is: 0.046875 , iter= 3401
current loss is: 3.9985518 , acc is: 0.0625 , iter= 3402
current loss is: 4.343624 , acc is: 0.046875 , iter= 3403
current loss is: 4.549524 , acc is: 0.09375 , iter= 3404
current loss is: 3.8984313 , acc is: 0.09375 , iter= 3405
current loss is: 3.8412333 , acc is: 0.09375 , iter= 3406
current loss is: 3.727151 , acc is: 0.109375 , iter= 3407
current loss is: 3.8665247 , acc is: 0.09375 , iter= 3408
current loss is: 3.9880047 , acc is: 0.09375 , iter= 3409
current loss is: 3.9022508 , acc is: 0.078125 , iter= 3410
current loss is: 4.6476583 , acc is: 0.03125 , iter= 3411
current loss is: 4.152656 , acc is: 0.015625 , iter= 3412
current loss is: 4.0960884 , acc is: 0.03125 , iter= 3413
current loss is: 4.022979 , acc is: 0.046875 , iter= 3414
current loss is: 3.8319194 , acc is: 0.09375 , iter= 3415
current loss is: 5.6292458 , acc is: 0.015625 , iter= 3416
current loss is: 4.0996923 , acc is: 0.09375 , iter= 3417
current loss is: 4.058659 , acc is: 0.078125 , iter= 3418
current loss is: 4.2080083 , acc is: 0.0625 , iter= 3419
current loss is: 4.0790873 , acc is: 0.03125 , iter= 3420
current loss is: 3.962676 , acc is: 0.0625 , iter= 3421
current loss is: 4.0789433 , acc is: 0.015625 , iter= 3422
current loss is: 3.8045588 , acc is: 0.078125 , iter= 3423
current loss is: 5.2673817 , acc is: 0.046875 , iter= 3424
current loss is: 3.97232 , acc is: 0.09375 , iter= 3425
current loss is: 4.111866 , acc is: 0.03125 , iter= 3426
current loss is: 4.0185385 , acc is: 0.0625 , iter= 3427
current loss is: 4.049789 , acc is: 0.046875 , iter= 3428
current loss is: 3.965016 , acc is: 0.0625 , iter= 3429
current loss is: 3.9446259 , acc is: 0.078125 , iter= 3430
current loss is: 4.098195 , acc is: 0.015625 , iter= 3431
current loss is: 4.1170745 , acc is: 0.015625 , iter= 3432
current loss is: 4.0071297 , acc is: 0.046875 , iter= 3433
current loss is: 4.1288495 , acc is: 0.015625 , iter= 3434
current loss is: 3.8677158 , acc is: 0.078125 , iter= 3435
current loss is: 4.1605453 , acc is: 0.0 , iter= 3436
current loss is: 4.186286 , acc is: 0.0 , iter= 3437
current loss is: 4.013048 , acc is: 0.078125 , iter= 3438
current loss is: 4.149605 , acc is: 0.0 , iter= 3439
current loss is: 3.949974 , acc is: 0.0625 , iter= 3440
current loss is: 3.9770403 , acc is: 0.046875 , iter= 3441
current loss is: 3.9941244 , acc is: 0.046875 , iter= 3442
current loss is: 3.9847093 , acc is: 0.078125 , iter= 3443
current loss is: 4.6181684 , acc is: 0.0625 , iter= 3444
current loss is: 8.385044 , acc is: 0.015625 , iter= 3445
current loss is: 4.094988 , acc is: 0.03125 , iter= 3446
current loss is: 4.0718174 , acc is: 0.046875 , iter= 3447
current loss is: 4.1775594 , acc is: 0.0 , iter= 3448
current loss is: 4.0676985 , acc is: 0.046875 , iter= 3449
current loss is: 3.9925184 , acc is: 0.03125 , iter= 3450
current loss is: 4.0828958 , acc is: 0.015625 , iter= 3451
current loss is: 3.7906196 , acc is: 0.109375 , iter= 3452
current loss is: 4.057527 , acc is: 0.046875 , iter= 3453
current loss is: 3.9142241 , acc is: 0.078125 , iter= 3454
current loss is: 3.9837716 , acc is: 0.0625 , iter= 3455
current loss is: 5.8905582 , acc is: 0.0625 , iter= 3456
current loss is: 7.269085 , acc is: 0.0625 , iter= 3457
current loss is: 4.022624 , acc is: 0.03125 , iter= 3458
current loss is: 4.107541 , acc is: 0.03125 , iter= 3459
current loss is: 4.1927834 , acc is: 0.0 , iter= 3460
current loss is: 3.966161 , acc is: 0.078125 , iter= 3461
current loss is: 4.468069 , acc is: 0.046875 , iter= 3462
current loss is: 4.058401 , acc is: 0.03125 , iter= 3463
current loss is: 3.9895897 , acc is: 0.078125 , iter= 3464
current loss is: 3.6876554 , acc is: 0.140625 , iter= 3465
current loss is: 4.1700573 , acc is: 0.0 , iter= 3466
current loss is: 3.9601035 , acc is: 0.0625 , iter= 3467
current loss is: 5.552657 , acc is: 0.0625 , iter= 3468
current loss is: 4.0546656 , acc is: 0.03125 , iter= 3469
current loss is: 3.9782658 , acc is: 0.046875 , iter= 3470
current loss is: 3.9970617 , acc is: 0.0625 , iter= 3471
current loss is: 4.043743 , acc is: 0.046875 , iter= 3472
current loss is: 3.9145699 , acc is: 0.046875 , iter= 3473
current loss is: 5.779846 , acc is: 0.03125 , iter= 3474
current loss is: 4.0605736 , acc is: 0.015625 , iter= 3475
current loss is: 4.165788 , acc is: 0.0 , iter= 3476
current loss is: 4.05548 , acc is: 0.015625 , iter= 3477
current loss is: 5.324035 , acc is: 0.046875 , iter= 3478
current loss is: 4.1179485 , acc is: 0.0625 , iter= 3479
current loss is: 4.030014 , acc is: 0.0625 , iter= 3480
current loss is: 4.0442123 , acc is: 0.046875 , iter= 3481
current loss is: 4.012785 , acc is: 0.0625 , iter= 3482
current loss is: 3.9428349 , acc is: 0.078125 , iter= 3483
current loss is: 3.9392827 , acc is: 0.078125 , iter= 3484
current loss is: 3.8294637 , acc is: 0.109375 , iter= 3485
current loss is: 4.045338 , acc is: 0.03125 , iter= 3486
current loss is: 4.2177925 , acc is: 0.078125 , iter= 3487
current loss is: 4.163947 , acc is: 0.0 , iter= 3488
current loss is: 4.0833626 , acc is: 0.03125 , iter= 3489
current loss is: 4.0528107 , acc is: 0.03125 , iter= 3490
current loss is: 4.11042 , acc is: 0.03125 , iter= 3491
current loss is: 6.6420836 , acc is: 0.0 , iter= 3492
current loss is: 4.1367435 , acc is: 0.046875 , iter= 3493
current loss is: 4.1085744 , acc is: 0.0625 , iter= 3494
current loss is: 4.1281643 , acc is: 0.03125 , iter= 3495
current loss is: 3.9437509 , acc is: 0.078125 , iter= 3496
current loss is: 4.1247854 , acc is: 0.03125 , iter= 3497
current loss is: 4.052436 , acc is: 0.03125 , iter= 3498
current loss is: 4.1189337 , acc is: 0.03125 , iter= 3499
current loss is: 4.1427894 , acc is: 0.03125 , iter= 3500
current loss is: 3.996778 , acc is: 0.046875 , iter= 3501
current loss is: 4.0557346 , acc is: 0.09375 , iter= 3502
current loss is: 4.0524063 , acc is: 0.046875 , iter= 3503
current loss is: 3.7041955 , acc is: 0.125 , iter= 3504
current loss is: 4.456532 , acc is: 0.015625 , iter= 3505
current loss is: 4.018545 , acc is: 0.03125 , iter= 3506
current loss is: 3.962883 , acc is: 0.046875 , iter= 3507
current loss is: 3.9234905 , acc is: 0.078125 , iter= 3508
current loss is: 3.9822268 , acc is: 0.078125 , iter= 3509
current loss is: 4.001367 , acc is: 0.0625 , iter= 3510
current loss is: 4.1388526 , acc is: 0.0625 , iter= 3511
current loss is: 3.9070008 , acc is: 0.046875 , iter= 3512
current loss is: 3.9739459 , acc is: 0.0625 , iter= 3513
current loss is: 4.168538 , acc is: 0.046875 , iter= 3514
current loss is: 4.0945373 , acc is: 0.03125 , iter= 3515
current loss is: 4.063742 , acc is: 0.03125 , iter= 3516
current loss is: 4.008729 , acc is: 0.03125 , iter= 3517
current loss is: 6.5369525 , acc is: 0.0 , iter= 3518
current loss is: 3.964129 , acc is: 0.09375 , iter= 3519
current loss is: 4.062258 , acc is: 0.03125 , iter= 3520
current loss is: 7.051781 , acc is: 0.0625 , iter= 3521
current loss is: 4.00478 , acc is: 0.0625 , iter= 3522
current loss is: 4.1480246 , acc is: 0.015625 , iter= 3523
current loss is: 3.939866 , acc is: 0.0625 , iter= 3524
current loss is: 4.335209 , acc is: 0.0 , iter= 3525
current loss is: 4.011055 , acc is: 0.0625 , iter= 3526
current loss is: 4.0829663 , acc is: 0.0625 , iter= 3527
current loss is: 4.0226474 , acc is: 0.03125 , iter= 3528
current loss is: 4.123742 , acc is: 0.03125 , iter= 3529
current loss is: 3.9581475 , acc is: 0.0625 , iter= 3530
current loss is: 4.103913 , acc is: 0.015625 , iter= 3531
current loss is: 4.0932193 , acc is: 0.046875 , iter= 3532
current loss is: 4.019087 , acc is: 0.046875 , iter= 3533
current loss is: 4.122864 , acc is: 0.015625 , iter= 3534
current loss is: 3.9529812 , acc is: 0.078125 , iter= 3535
current loss is: 3.9906619 , acc is: 0.078125 , iter= 3536
current loss is: 4.066389 , acc is: 0.0625 , iter= 3537
current loss is: 4.1482897 , acc is: 0.03125 , iter= 3538
current loss is: 3.9379034 , acc is: 0.0625 , iter= 3539
current loss is: 3.930257 , acc is: 0.0625 , iter= 3540
current loss is: 3.8964846 , acc is: 0.09375 , iter= 3541
current loss is: 4.0665927 , acc is: 0.03125 , iter= 3542
current loss is: 4.833726 , acc is: 0.015625 , iter= 3543
current loss is: 3.9252148 , acc is: 0.0625 , iter= 3544
current loss is: 3.9671316 , acc is: 0.0625 , iter= 3545
current loss is: 4.125466 , acc is: 0.0625 , iter= 3546
current loss is: 4.2608376 , acc is: 0.09375 , iter= 3547
current loss is: 4.0327387 , acc is: 0.03125 , iter= 3548
current loss is: 4.084567 , acc is: 0.03125 , iter= 3549
current loss is: 4.3103523 , acc is: 0.0625 , iter= 3550
current loss is: 4.86997 , acc is: 0.046875 , iter= 3551
current loss is: 4.0826383 , acc is: 0.03125 , iter= 3552
current loss is: 3.973856 , acc is: 0.0625 , iter= 3553
current loss is: 4.0317087 , acc is: 0.03125 , iter= 3554
current loss is: 3.8276236 , acc is: 0.09375 , iter= 3555
current loss is: 4.0989895 , acc is: 0.09375 , iter= 3556
current loss is: 6.029572 , acc is: 0.03125 , iter= 3557
current loss is: 4.0417705 , acc is: 0.03125 , iter= 3558
current loss is: 4.1646013 , acc is: 0.0 , iter= 3559
current loss is: 3.9776993 , acc is: 0.0625 , iter= 3560
current loss is: 4.1342955 , acc is: 0.015625 , iter= 3561
current loss is: 3.7986474 , acc is: 0.125 , iter= 3562
current loss is: 4.243656 , acc is: 0.046875 , iter= 3563
current loss is: 3.9031553 , acc is: 0.09375 , iter= 3564
current loss is: 4.028079 , acc is: 0.09375 , iter= 3565
current loss is: 4.130401 , acc is: 0.03125 , iter= 3566
current loss is: 6.0860753 , acc is: 0.015625 , iter= 3567
current loss is: 4.089866 , acc is: 0.015625 , iter= 3568
current loss is: 4.091611 , acc is: 0.0625 , iter= 3569
current loss is: 4.109069 , acc is: 0.046875 , iter= 3570
current loss is: 4.065881 , acc is: 0.03125 , iter= 3571
current loss is: 3.8862638 , acc is: 0.078125 , iter= 3572
current loss is: 4.133113 , acc is: 0.0 , iter= 3573
current loss is: 4.038727 , acc is: 0.03125 , iter= 3574
current loss is: 4.0331087 , acc is: 0.0625 , iter= 3575
current loss is: 5.1074443 , acc is: 0.046875 , iter= 3576
current loss is: 4.019807 , acc is: 0.078125 , iter= 3577
current loss is: 3.9728408 , acc is: 0.046875 , iter= 3578
current loss is: 4.0673122 , acc is: 0.03125 , iter= 3579
current loss is: 3.9734821 , acc is: 0.0625 , iter= 3580
current loss is: 4.0451345 , acc is: 0.03125 , iter= 3581
current loss is: 4.110459 , acc is: 0.0 , iter= 3582
current loss is: 4.0212293 , acc is: 0.03125 , iter= 3583
current loss is: 4.107486 , acc is: 0.078125 , iter= 3584
current loss is: 3.894384 , acc is: 0.078125 , iter= 3585
current loss is: 4.2100925 , acc is: 0.03125 , iter= 3586
current loss is: 4.0590944 , acc is: 0.046875 , iter= 3587
current loss is: 4.921395 , acc is: 0.046875 , iter= 3588
current loss is: 5.080718 , acc is: 0.0625 , iter= 3589
current loss is: 4.162731 , acc is: 0.0 , iter= 3590
current loss is: 4.051975 , acc is: 0.078125 , iter= 3591
current loss is: 4.15204 , acc is: 0.0 , iter= 3592
current loss is: 4.096242 , acc is: 0.03125 , iter= 3593
current loss is: 8.825635 , acc is: 0.046875 , iter= 3594
current loss is: 3.9018104 , acc is: 0.09375 , iter= 3595
current loss is: 3.8581333 , acc is: 0.0625 , iter= 3596
current loss is: 4.113355 , acc is: 0.0 , iter= 3597
current loss is: 4.1262474 , acc is: 0.046875 , iter= 3598
current loss is: 4.1435356 , acc is: 0.015625 , iter= 3599
current loss is: 3.9306545 , acc is: 0.0625 , iter= 3600
current loss is: 3.9721963 , acc is: 0.0625 , iter= 3601
current loss is: 3.979472 , acc is: 0.03125 , iter= 3602
current loss is: 3.9977522 , acc is: 0.078125 , iter= 3603
current loss is: 4.076138 , acc is: 0.03125 , iter= 3604
current loss is: 4.0771585 , acc is: 0.015625 , iter= 3605
current loss is: 4.216806 , acc is: 0.015625 , iter= 3606
current loss is: 4.076275 , acc is: 0.078125 , iter= 3607
current loss is: 3.9419007 , acc is: 0.0625 , iter= 3608
current loss is: 3.9705706 , acc is: 0.03125 , iter= 3609
current loss is: 4.081803 , acc is: 0.03125 , iter= 3610
current loss is: 4.1347146 , acc is: 0.015625 , iter= 3611
current loss is: 3.948346 , acc is: 0.046875 , iter= 3612
current loss is: 4.043054 , acc is: 0.046875 , iter= 3613
current loss is: 4.1646748 , acc is: 0.015625 , iter= 3614
current loss is: 3.9332423 , acc is: 0.078125 , iter= 3615
current loss is: 4.0320163 , acc is: 0.015625 , iter= 3616
current loss is: 4.098768 , acc is: 0.015625 , iter= 3617
current loss is: 4.1010675 , acc is: 0.03125 , iter= 3618
current loss is: 3.8775363 , acc is: 0.078125 , iter= 3619
current loss is: 4.0727396 , acc is: 0.078125 , iter= 3620
current loss is: 4.129862 , acc is: 0.0 , iter= 3621
current loss is: 4.044753 , acc is: 0.03125 , iter= 3622
current loss is: 3.9003925 , acc is: 0.09375 , iter= 3623
current loss is: 4.1190987 , acc is: 0.015625 , iter= 3624
current loss is: 4.065126 , acc is: 0.046875 , iter= 3625
current loss is: 3.9610157 , acc is: 0.0625 , iter= 3626
current loss is: 3.9796991 , acc is: 0.09375 , iter= 3627
current loss is: 4.0514274 , acc is: 0.078125 , iter= 3628
current loss is: 3.9317183 , acc is: 0.0625 , iter= 3629
current loss is: 4.099869 , acc is: 0.03125 , iter= 3630
current loss is: 4.0743933 , acc is: 0.03125 , iter= 3631
current loss is: 5.0859694 , acc is: 0.03125 , iter= 3632
current loss is: 4.1533737 , acc is: 0.015625 , iter= 3633
current loss is: 3.9179504 , acc is: 0.0625 , iter= 3634
current loss is: 4.086843 , acc is: 0.0625 , iter= 3635
current loss is: 4.032549 , acc is: 0.046875 , iter= 3636
current loss is: 4.082924 , acc is: 0.03125 , iter= 3637
current loss is: 4.051368 , acc is: 0.09375 , iter= 3638
current loss is: 4.1408052 , acc is: 0.015625 , iter= 3639
current loss is: 4.028614 , acc is: 0.03125 , iter= 3640
current loss is: 4.0769033 , acc is: 0.015625 , iter= 3641
current loss is: 4.6782475 , acc is: 0.0 , iter= 3642
current loss is: 4.118759 , acc is: 0.0625 , iter= 3643
current loss is: 3.9559195 , acc is: 0.0625 , iter= 3644
current loss is: 4.5485864 , acc is: 0.0625 , iter= 3645
current loss is: 4.1063776 , acc is: 0.0625 , iter= 3646
current loss is: 4.0196877 , acc is: 0.0625 , iter= 3647
current loss is: 3.9299598 , acc is: 0.078125 , iter= 3648
current loss is: 3.9099555 , acc is: 0.046875 , iter= 3649
current loss is: 4.0378475 , acc is: 0.046875 , iter= 3650
current loss is: 3.9638822 , acc is: 0.0625 , iter= 3651
current loss is: 3.9456923 , acc is: 0.078125 , iter= 3652
current loss is: 4.0662856 , acc is: 0.03125 , iter= 3653
current loss is: 4.1284328 , acc is: 0.03125 , iter= 3654
current loss is: 4.299117 , acc is: 0.015625 , iter= 3655
current loss is: 5.0352983 , acc is: 0.046875 , iter= 3656
current loss is: 4.049455 , acc is: 0.0625 , iter= 3657
current loss is: 4.08508 , acc is: 0.046875 , iter= 3658
current loss is: 4.1448236 , acc is: 0.046875 , iter= 3659
current loss is: 4.0811315 , acc is: 0.03125 , iter= 3660
current loss is: 3.9685116 , acc is: 0.03125 , iter= 3661
current loss is: 3.980071 , acc is: 0.0625 , iter= 3662
current loss is: 4.1435995 , acc is: 0.015625 , iter= 3663
current loss is: 4.0082836 , acc is: 0.03125 , iter= 3664
current loss is: 4.635785 , acc is: 0.015625 , iter= 3665
current loss is: 3.9493241 , acc is: 0.0625 , iter= 3666
current loss is: 5.410909 , acc is: 0.03125 , iter= 3667
current loss is: 4.1188326 , acc is: 0.078125 , iter= 3668
current loss is: 3.903652 , acc is: 0.0625 , iter= 3669
current loss is: 3.9383793 , acc is: 0.078125 , iter= 3670
current loss is: 3.907419 , acc is: 0.0625 , iter= 3671
current loss is: 4.1116 , acc is: 0.046875 , iter= 3672
current loss is: 4.043515 , acc is: 0.078125 , iter= 3673
current loss is: 4.01379 , acc is: 0.0625 , iter= 3674
current loss is: 3.9616466 , acc is: 0.0625 , iter= 3675
current loss is: 4.046869 , acc is: 0.03125 , iter= 3676
current loss is: 4.054017 , acc is: 0.03125 , iter= 3677
current loss is: 4.0697927 , acc is: 0.015625 , iter= 3678
current loss is: 4.0670505 , acc is: 0.015625 , iter= 3679
current loss is: 4.1107516 , acc is: 0.03125 , iter= 3680
current loss is: 4.1673064 , acc is: 0.0 , iter= 3681
current loss is: 4.3296113 , acc is: 0.046875 , iter= 3682
current loss is: 3.879625 , acc is: 0.09375 , iter= 3683
current loss is: 5.0078807 , acc is: 0.046875 , iter= 3684
current loss is: 4.0182223 , acc is: 0.046875 , iter= 3685
current loss is: 4.1002307 , acc is: 0.046875 , iter= 3686
current loss is: 4.083951 , acc is: 0.046875 , iter= 3687
current loss is: 4.070673 , acc is: 0.03125 , iter= 3688
current loss is: 4.0361805 , acc is: 0.0625 , iter= 3689
current loss is: 3.8469286 , acc is: 0.0625 , iter= 3690
current loss is: 3.9958038 , acc is: 0.046875 , iter= 3691
current loss is: 4.0040627 , acc is: 0.046875 , iter= 3692
current loss is: 4.091591 , acc is: 0.046875 , iter= 3693
current loss is: 4.8683214 , acc is: 0.0625 , iter= 3694
current loss is: 4.0767703 , acc is: 0.0625 , iter= 3695
current loss is: 3.9878058 , acc is: 0.0625 , iter= 3696
current loss is: 5.725717 , acc is: 0.046875 , iter= 3697
current loss is: 4.0547376 , acc is: 0.0625 , iter= 3698
current loss is: 4.1956663 , acc is: 0.015625 , iter= 3699
current loss is: 4.1446247 , acc is: 0.046875 , iter= 3700
current loss is: 4.277875 , acc is: 0.046875 , iter= 3701
current loss is: 3.820361 , acc is: 0.09375 , iter= 3702
current loss is: 4.1210384 , acc is: 0.015625 , iter= 3703
current loss is: 4.1143093 , acc is: 0.015625 , iter= 3704
current loss is: 4.08232 , acc is: 0.046875 , iter= 3705
current loss is: 4.087355 , acc is: 0.03125 , iter= 3706
current loss is: 3.936639 , acc is: 0.046875 , iter= 3707
current loss is: 4.0111275 , acc is: 0.046875 , iter= 3708
current loss is: 4.029109 , acc is: 0.046875 , iter= 3709
current loss is: 4.9039297 , acc is: 0.03125 , iter= 3710
current loss is: 4.1115303 , acc is: 0.03125 , iter= 3711
current loss is: 4.156431 , acc is: 0.015625 , iter= 3712
current loss is: 4.8592267 , acc is: 0.0625 , iter= 3713
current loss is: 4.0851583 , acc is: 0.03125 , iter= 3714
current loss is: 3.953401 , acc is: 0.078125 , iter= 3715
current loss is: 3.9855525 , acc is: 0.0625 , iter= 3716
current loss is: 4.128372 , acc is: 0.015625 , iter= 3717
current loss is: 4.124277 , acc is: 0.03125 , iter= 3718
current loss is: 4.140526 , acc is: 0.0 , iter= 3719
current loss is: 3.6816823 , acc is: 0.125 , iter= 3720
current loss is: 4.120255 , acc is: 0.015625 , iter= 3721
current loss is: 4.164809 , acc is: 0.046875 , iter= 3722
current loss is: 4.1142097 , acc is: 0.0 , iter= 3723
current loss is: 3.9979315 , acc is: 0.046875 , iter= 3724
current loss is: 4.0069075 , acc is: 0.0625 , iter= 3725
current loss is: 3.9154294 , acc is: 0.078125 , iter= 3726
current loss is: 4.1359415 , acc is: 0.03125 , iter= 3727
current loss is: 4.0580783 , acc is: 0.046875 , iter= 3728
current loss is: 4.1405306 , acc is: 0.03125 , iter= 3729
current loss is: 4.063014 , acc is: 0.03125 , iter= 3730
current loss is: 3.9986467 , acc is: 0.0625 , iter= 3731
current loss is: 4.7777357 , acc is: 0.046875 , iter= 3732
current loss is: 4.0278535 , acc is: 0.03125 , iter= 3733
current loss is: 4.130476 , acc is: 0.015625 , iter= 3734
current loss is: 4.038113 , acc is: 0.078125 , iter= 3735
current loss is: 3.9567747 , acc is: 0.046875 , iter= 3736
current loss is: 4.0416603 , acc is: 0.046875 , iter= 3737
current loss is: 4.0139313 , acc is: 0.03125 , iter= 3738
current loss is: 4.0635567 , acc is: 0.015625 , iter= 3739
current loss is: 3.952506 , acc is: 0.0625 , iter= 3740
current loss is: 4.0278077 , acc is: 0.046875 , iter= 3741
current loss is: 4.0919046 , acc is: 0.0 , iter= 3742
current loss is: 4.082822 , acc is: 0.015625 , iter= 3743
current loss is: 4.0333643 , acc is: 0.015625 , iter= 3744
current loss is: 4.1641383 , acc is: 0.03125 , iter= 3745
current loss is: 3.9914954 , acc is: 0.046875 , iter= 3746
current loss is: 4.0254993 , acc is: 0.0625 , iter= 3747
current loss is: 4.0069866 , acc is: 0.0625 , iter= 3748
current loss is: 4.130546 , acc is: 0.046875 , iter= 3749
current loss is: 4.07548 , acc is: 0.046875 , iter= 3750
current loss is: 3.9983056 , acc is: 0.0625 , iter= 3751
current loss is: 4.1068287 , acc is: 0.0 , iter= 3752
current loss is: 4.086121 , acc is: 0.03125 , iter= 3753
current loss is: 3.9222507 , acc is: 0.0625 , iter= 3754
current loss is: 4.389983 , acc is: 0.09375 , iter= 3755
current loss is: 4.063144 , acc is: 0.015625 , iter= 3756
current loss is: 4.0632877 , acc is: 0.046875 , iter= 3757
current loss is: 4.093013 , acc is: 0.046875 , iter= 3758
current loss is: 3.9921412 , acc is: 0.09375 , iter= 3759
current loss is: 4.079854 , acc is: 0.015625 , iter= 3760
current loss is: 4.1633267 , acc is: 0.0 , iter= 3761
current loss is: 3.9333801 , acc is: 0.046875 , iter= 3762
current loss is: 3.9750795 , acc is: 0.09375 , iter= 3763
current loss is: 4.1223764 , acc is: 0.015625 , iter= 3764
current loss is: 4.2006073 , acc is: 0.046875 , iter= 3765
current loss is: 4.1037836 , acc is: 0.03125 , iter= 3766
current loss is: 4.1353383 , acc is: 0.015625 , iter= 3767
current loss is: 4.1205435 , acc is: 0.015625 , iter= 3768
current loss is: 4.0463367 , acc is: 0.0625 , iter= 3769
current loss is: 4.1783075 , acc is: 0.046875 , iter= 3770
current loss is: 3.969954 , acc is: 0.109375 , iter= 3771
current loss is: 4.0502005 , acc is: 0.09375 , iter= 3772
current loss is: 4.0924788 , acc is: 0.078125 , iter= 3773
current loss is: 4.0088587 , acc is: 0.0625 , iter= 3774
current loss is: 4.029151 , acc is: 0.03125 , iter= 3775
current loss is: 4.130255 , acc is: 0.03125 , iter= 3776
current loss is: 4.055307 , acc is: 0.046875 , iter= 3777
current loss is: 3.9834692 , acc is: 0.03125 , iter= 3778
current loss is: 4.2277803 , acc is: 0.015625 , iter= 3779
current loss is: 4.179116 , acc is: 0.0 , iter= 3780
current loss is: 4.1479015 , acc is: 0.03125 , iter= 3781
current loss is: 4.140044 , acc is: 0.015625 , iter= 3782
current loss is: 4.0958214 , acc is: 0.03125 , iter= 3783
current loss is: 4.0955906 , acc is: 0.03125 , iter= 3784
current loss is: 4.9748087 , acc is: 0.0 , iter= 3785
current loss is: 4.065378 , acc is: 0.03125 , iter= 3786
current loss is: 4.0885763 , acc is: 0.03125 , iter= 3787
current loss is: 3.9200068 , acc is: 0.078125 , iter= 3788
current loss is: 4.0171094 , acc is: 0.0625 , iter= 3789
current loss is: 4.480323 , acc is: 0.078125 , iter= 3790
current loss is: 3.968404 , acc is: 0.0625 , iter= 3791
current loss is: 5.6435413 , acc is: 0.0625 , iter= 3792
current loss is: 4.4562063 , acc is: 0.0625 , iter= 3793
current loss is: 3.8142502 , acc is: 0.140625 , iter= 3794
current loss is: 3.7725453 , acc is: 0.140625 , iter= 3795
current loss is: 4.8367357 , acc is: 0.03125 , iter= 3796
current loss is: 4.682706 , acc is: 0.046875 , iter= 3797
current loss is: 3.958396 , acc is: 0.046875 , iter= 3798
current loss is: 4.150882 , acc is: 0.015625 , iter= 3799
current loss is: 4.0864086 , acc is: 0.0625 , iter= 3800
current loss is: 4.0337305 , acc is: 0.0625 , iter= 3801
current loss is: 4.0332828 , acc is: 0.046875 , iter= 3802
current loss is: 4.150752 , acc is: 0.015625 , iter= 3803
current loss is: 3.9830005 , acc is: 0.046875 , iter= 3804
current loss is: 4.022208 , acc is: 0.078125 , iter= 3805
current loss is: 4.1508694 , acc is: 0.046875 , iter= 3806
current loss is: 3.9182785 , acc is: 0.0625 , iter= 3807
current loss is: 14.84765 , acc is: 0.03125 , iter= 3808
current loss is: 3.7677684 , acc is: 0.078125 , iter= 3809
current loss is: 4.1055794 , acc is: 0.0 , iter= 3810
current loss is: 4.1372886 , acc is: 0.03125 , iter= 3811
current loss is: 4.0774684 , acc is: 0.046875 , iter= 3812
current loss is: 4.187044 , acc is: 0.0 , iter= 3813
current loss is: 4.0331287 , acc is: 0.046875 , iter= 3814
current loss is: 4.0328445 , acc is: 0.0625 , iter= 3815
current loss is: 4.0843306 , acc is: 0.03125 , iter= 3816
current loss is: 3.9108992 , acc is: 0.046875 , iter= 3817
current loss is: 4.0426145 , acc is: 0.03125 , iter= 3818
current loss is: 4.48121 , acc is: 0.046875 , iter= 3819
current loss is: 4.0424786 , acc is: 0.0625 , iter= 3820
current loss is: 4.1521673 , acc is: 0.0 , iter= 3821
current loss is: 4.157205 , acc is: 0.0 , iter= 3822
current loss is: 4.089776 , acc is: 0.046875 , iter= 3823
current loss is: 3.9941566 , acc is: 0.078125 , iter= 3824
current loss is: 4.031035 , acc is: 0.03125 , iter= 3825
current loss is: 4.08255 , acc is: 0.0625 , iter= 3826
current loss is: 4.0428467 , acc is: 0.046875 , iter= 3827
current loss is: 3.9937177 , acc is: 0.078125 , iter= 3828
current loss is: 4.0331483 , acc is: 0.046875 , iter= 3829
current loss is: 3.9798968 , acc is: 0.078125 , iter= 3830
current loss is: 4.1169596 , acc is: 0.03125 , iter= 3831
current loss is: 4.1584883 , acc is: 0.015625 , iter= 3832
current loss is: 4.2325277 , acc is: 0.0625 , iter= 3833
current loss is: 4.1156 , acc is: 0.03125 , iter= 3834
current loss is: 4.121582 , acc is: 0.015625 , iter= 3835
current loss is: 4.0103135 , acc is: 0.015625 , iter= 3836
current loss is: 4.021343 , acc is: 0.046875 , iter= 3837
current loss is: 4.0259156 , acc is: 0.0625 , iter= 3838
current loss is: 3.9857736 , acc is: 0.078125 , iter= 3839
current loss is: 3.9289129 , acc is: 0.078125 , iter= 3840
current loss is: 4.155043 , acc is: 0.03125 , iter= 3841
current loss is: 4.1160803 , acc is: 0.046875 , iter= 3842
current loss is: 4.113231 , acc is: 0.015625 , iter= 3843
current loss is: 4.0928392 , acc is: 0.015625 , iter= 3844
current loss is: 4.0944886 , acc is: 0.046875 , iter= 3845
current loss is: 4.090008 , acc is: 0.046875 , iter= 3846
current loss is: 3.9454231 , acc is: 0.0625 , iter= 3847
current loss is: 3.9300349 , acc is: 0.046875 , iter= 3848
current loss is: 4.065612 , acc is: 0.03125 , iter= 3849
current loss is: 4.0599604 , acc is: 0.09375 , iter= 3850
current loss is: 3.9593592 , acc is: 0.0625 , iter= 3851
current loss is: 3.9447055 , acc is: 0.0625 , iter= 3852
current loss is: 4.0423594 , acc is: 0.03125 , iter= 3853
current loss is: 4.0691657 , acc is: 0.03125 , iter= 3854
current loss is: 4.214858 , acc is: 0.0 , iter= 3855
current loss is: 3.9750142 , acc is: 0.078125 , iter= 3856
current loss is: 3.8903413 , acc is: 0.078125 , iter= 3857
current loss is: 4.03466 , acc is: 0.0625 , iter= 3858
current loss is: 4.0359526 , acc is: 0.03125 , iter= 3859
current loss is: 4.087842 , acc is: 0.015625 , iter= 3860
current loss is: 4.14692 , acc is: 0.015625 , iter= 3861
current loss is: 3.957047 , acc is: 0.0625 , iter= 3862
current loss is: 4.1153417 , acc is: 0.015625 , iter= 3863
current loss is: 4.043895 , acc is: 0.0 , iter= 3864
current loss is: 4.0383997 , acc is: 0.078125 , iter= 3865
current loss is: 4.115142 , acc is: 0.0625 , iter= 3866
current loss is: 4.035374 , acc is: 0.03125 , iter= 3867
current loss is: 4.009643 , acc is: 0.046875 , iter= 3868
current loss is: 4.12652 , acc is: 0.03125 , iter= 3869
current loss is: 4.1321445 , acc is: 0.03125 , iter= 3870
current loss is: 4.038686 , acc is: 0.046875 , iter= 3871
current loss is: 4.1308975 , acc is: 0.015625 , iter= 3872
current loss is: 3.9724817 , acc is: 0.078125 , iter= 3873
current loss is: 4.071637 , acc is: 0.015625 , iter= 3874
current loss is: 4.133915 , acc is: 0.0 , iter= 3875
current loss is: 4.0872474 , acc is: 0.046875 , iter= 3876
current loss is: 3.8977315 , acc is: 0.078125 , iter= 3877
current loss is: 3.9414523 , acc is: 0.0625 , iter= 3878
current loss is: 4.085198 , acc is: 0.0625 , iter= 3879
current loss is: 4.1237545 , acc is: 0.046875 , iter= 3880
current loss is: 4.032495 , acc is: 0.03125 , iter= 3881
current loss is: 4.0230255 , acc is: 0.03125 , iter= 3882
current loss is: 4.000251 , acc is: 0.0625 , iter= 3883
current loss is: 4.1580014 , acc is: 0.0 , iter= 3884
current loss is: 6.174251 , acc is: 0.046875 , iter= 3885
current loss is: 4.1378 , acc is: 0.015625 , iter= 3886
current loss is: 4.090177 , acc is: 0.046875 , iter= 3887
current loss is: 4.073111 , acc is: 0.015625 , iter= 3888
current loss is: 4.063488 , acc is: 0.015625 , iter= 3889
current loss is: 4.123721 , acc is: 0.046875 , iter= 3890
current loss is: 4.038288 , acc is: 0.046875 , iter= 3891
current loss is: 4.0139456 , acc is: 0.0625 , iter= 3892
current loss is: 4.0025363 , acc is: 0.078125 , iter= 3893
current loss is: 4.065684 , acc is: 0.015625 , iter= 3894
current loss is: 4.2328825 , acc is: 0.046875 , iter= 3895
current loss is: 4.1748466 , acc is: 0.03125 , iter= 3896
current loss is: 4.135489 , acc is: 0.09375 , iter= 3897
current loss is: 4.0590115 , acc is: 0.046875 , iter= 3898
current loss is: 4.1180787 , acc is: 0.046875 , iter= 3899
current loss is: 4.107461 , acc is: 0.015625 , iter= 3900
current loss is: 4.0986156 , acc is: 0.046875 , iter= 3901
current loss is: 3.9344916 , acc is: 0.109375 , iter= 3902
current loss is: 4.007703 , acc is: 0.046875 , iter= 3903
current loss is: 4.094848 , acc is: 0.015625 , iter= 3904
current loss is: 4.138871 , acc is: 0.03125 , iter= 3905
current loss is: 4.057559 , acc is: 0.03125 , iter= 3906
current loss is: 4.109695 , acc is: 0.046875 , iter= 3907
current loss is: 4.159251 , acc is: 0.015625 , iter= 3908
current loss is: 4.0966144 , acc is: 0.03125 , iter= 3909
current loss is: 3.9281287 , acc is: 0.0625 , iter= 3910
current loss is: 3.9692907 , acc is: 0.078125 , iter= 3911
current loss is: 4.051627 , acc is: 0.046875 , iter= 3912
current loss is: 4.0985737 , acc is: 0.03125 , iter= 3913
current loss is: 4.263483 , acc is: 0.0625 , iter= 3914
current loss is: 4.1928024 , acc is: 0.015625 , iter= 3915
current loss is: 4.14884 , acc is: 0.03125 , iter= 3916
current loss is: 3.9695778 , acc is: 0.0625 , iter= 3917
current loss is: 4.100028 , acc is: 0.015625 , iter= 3918
current loss is: 4.1697826 , acc is: 0.015625 , iter= 3919
current loss is: 4.160791 , acc is: 0.03125 , iter= 3920
current loss is: 4.0985475 , acc is: 0.0625 , iter= 3921
current loss is: 4.0127025 , acc is: 0.0625 , iter= 3922
current loss is: 4.1136613 , acc is: 0.015625 , iter= 3923
current loss is: 4.1810484 , acc is: 0.0625 , iter= 3924
current loss is: 3.9804351 , acc is: 0.046875 , iter= 3925
current loss is: 3.9482632 , acc is: 0.0625 , iter= 3926
current loss is: 3.8595676 , acc is: 0.09375 , iter= 3927
current loss is: 4.0857024 , acc is: 0.03125 , iter= 3928
current loss is: 4.103077 , acc is: 0.03125 , iter= 3929
current loss is: 4.0668755 , acc is: 0.046875 , iter= 3930
current loss is: 3.9771812 , acc is: 0.0625 , iter= 3931
current loss is: 3.9961593 , acc is: 0.0625 , iter= 3932
current loss is: 4.050804 , acc is: 0.046875 , iter= 3933
current loss is: 4.812054 , acc is: 0.0625 , iter= 3934
current loss is: 3.99631 , acc is: 0.109375 , iter= 3935
current loss is: 4.5427594 , acc is: 0.046875 , iter= 3936
current loss is: 4.0843096 , acc is: 0.03125 , iter= 3937
current loss is: 4.1493697 , acc is: 0.046875 , iter= 3938
current loss is: 4.0140758 , acc is: 0.046875 , iter= 3939
current loss is: 4.038969 , acc is: 0.046875 , iter= 3940
current loss is: 4.1797776 , acc is: 0.0 , iter= 3941
current loss is: 3.955142 , acc is: 0.0625 , iter= 3942
current loss is: 4.1704874 , acc is: 0.015625 , iter= 3943
current loss is: 4.0365925 , acc is: 0.046875 , iter= 3944
current loss is: 3.9905963 , acc is: 0.0625 , iter= 3945
current loss is: 3.860989 , acc is: 0.109375 , iter= 3946
current loss is: 3.973843 , acc is: 0.046875 , iter= 3947
current loss is: 4.0345936 , acc is: 0.046875 , iter= 3948
current loss is: 4.156994 , acc is: 0.0 , iter= 3949
current loss is: 4.124613 , acc is: 0.0625 , iter= 3950
current loss is: 3.9446988 , acc is: 0.0625 , iter= 3951
current loss is: 4.1281056 , acc is: 0.015625 , iter= 3952
current loss is: 3.9799943 , acc is: 0.0625 , iter= 3953
current loss is: 4.0674653 , acc is: 0.046875 , iter= 3954
current loss is: 4.6289387 , acc is: 0.046875 , iter= 3955
current loss is: 4.0601115 , acc is: 0.046875 , iter= 3956
current loss is: 4.222865 , acc is: 0.03125 , iter= 3957
current loss is: 4.274326 , acc is: 0.0625 , iter= 3958
current loss is: 3.9278593 , acc is: 0.078125 , iter= 3959
current loss is: 3.9231567 , acc is: 0.078125 , iter= 3960
current loss is: 4.0168767 , acc is: 0.046875 , iter= 3961
current loss is: 3.9096773 , acc is: 0.09375 , iter= 3962
current loss is: 4.067237 , acc is: 0.046875 , iter= 3963
current loss is: 3.9610102 , acc is: 0.046875 , iter= 3964
current loss is: 3.962889 , acc is: 0.03125 , iter= 3965
current loss is: 4.1318583 , acc is: 0.015625 , iter= 3966
current loss is: 3.9991229 , acc is: 0.0625 , iter= 3967
current loss is: 4.0383472 , acc is: 0.046875 , iter= 3968
current loss is: 4.006832 , acc is: 0.046875 , iter= 3969
current loss is: 4.0408506 , acc is: 0.0625 , iter= 3970
current loss is: 3.9579954 , acc is: 0.09375 , iter= 3971
current loss is: 4.143506 , acc is: 0.03125 , iter= 3972
current loss is: 4.2102633 , acc is: 0.015625 , iter= 3973
current loss is: 4.003646 , acc is: 0.03125 , iter= 3974
current loss is: 4.0403585 , acc is: 0.03125 , iter= 3975
current loss is: 4.064497 , acc is: 0.03125 , iter= 3976
current loss is: 4.0551243 , acc is: 0.046875 , iter= 3977
current loss is: 4.105235 , acc is: 0.0625 , iter= 3978
current loss is: 4.1248984 , acc is: 0.0625 , iter= 3979
current loss is: 4.072821 , acc is: 0.046875 , iter= 3980
current loss is: 4.1940928 , acc is: 0.015625 , iter= 3981
current loss is: 4.085515 , acc is: 0.046875 , iter= 3982
current loss is: 4.0324836 , acc is: 0.046875 , iter= 3983
current loss is: 4.131759 , acc is: 0.015625 , iter= 3984
current loss is: 4.0488715 , acc is: 0.046875 , iter= 3985
current loss is: 4.000699 , acc is: 0.046875 , iter= 3986
current loss is: 3.9824505 , acc is: 0.109375 , iter= 3987
current loss is: 4.0075 , acc is: 0.046875 , iter= 3988
current loss is: 4.1330595 , acc is: 0.078125 , iter= 3989
current loss is: 4.1224256 , acc is: 0.03125 , iter= 3990
current loss is: 4.119602 , acc is: 0.03125 , iter= 3991
current loss is: 4.0384655 , acc is: 0.046875 , iter= 3992
current loss is: 4.0166917 , acc is: 0.03125 , iter= 3993
current loss is: 3.9805198 , acc is: 0.0625 , iter= 3994
current loss is: 4.094018 , acc is: 0.0 , iter= 3995
current loss is: 4.0921836 , acc is: 0.03125 , iter= 3996
current loss is: 4.047394 , acc is: 0.078125 , iter= 3997
current loss is: 4.0183845 , acc is: 0.078125 , iter= 3998
current loss is: 4.076828 , acc is: 0.0625 , iter= 3999
current loss is: 4.1481147 , acc is: 0.046875 , iter= 4000
tot_acc= 19.0 tot_input= 768
current accuracy is: 0.024739583333333332
current loss is: 4.0334554 , acc is: 0.046875 , iter= 4001
current loss is: 4.180907 , acc is: 0.015625 , iter= 4002
current loss is: 3.9781508 , acc is: 0.09375 , iter= 4003
current loss is: 4.1251087 , acc is: 0.015625 , iter= 4004
current loss is: 3.9944859 , acc is: 0.03125 , iter= 4005
current loss is: 3.937623 , acc is: 0.046875 , iter= 4006
current loss is: 3.9750803 , acc is: 0.0625 , iter= 4007
current loss is: 4.0864916 , acc is: 0.078125 , iter= 4008
current loss is: 4.1953716 , acc is: 0.078125 , iter= 4009
current loss is: 3.887451 , acc is: 0.0625 , iter= 4010
current loss is: 4.011445 , acc is: 0.078125 , iter= 4011
current loss is: 4.1786222 , acc is: 0.015625 , iter= 4012
current loss is: 4.157593 , acc is: 0.015625 , iter= 4013
current loss is: 4.1676064 , acc is: 0.015625 , iter= 4014
current loss is: 4.111389 , acc is: 0.03125 , iter= 4015
current loss is: 3.9303498 , acc is: 0.15625 , iter= 4016
current loss is: 4.0321054 , acc is: 0.046875 , iter= 4017
current loss is: 3.8595796 , acc is: 0.078125 , iter= 4018
current loss is: 4.117269 , acc is: 0.046875 , iter= 4019
current loss is: 4.0649247 , acc is: 0.015625 , iter= 4020
current loss is: 4.0656085 , acc is: 0.0625 , iter= 4021
current loss is: 4.038714 , acc is: 0.03125 , iter= 4022
current loss is: 4.0486298 , acc is: 0.046875 , iter= 4023
current loss is: 4.077031 , acc is: 0.03125 , iter= 4024
current loss is: 3.9862957 , acc is: 0.078125 , iter= 4025
current loss is: 4.072731 , acc is: 0.046875 , iter= 4026
current loss is: 4.0420446 , acc is: 0.0625 , iter= 4027
current loss is: 4.0791016 , acc is: 0.03125 , iter= 4028
current loss is: 3.8026567 , acc is: 0.109375 , iter= 4029
current loss is: 4.041959 , acc is: 0.046875 , iter= 4030
current loss is: 4.1474752 , acc is: 0.046875 , iter= 4031
current loss is: 4.179949 , acc is: 0.015625 , iter= 4032
current loss is: 4.1184874 , acc is: 0.015625 , iter= 4033
current loss is: 3.8950393 , acc is: 0.09375 , iter= 4034
current loss is: 4.1739492 , acc is: 0.0 , iter= 4035
current loss is: 4.183122 , acc is: 0.0 , iter= 4036
current loss is: 4.146004 , acc is: 0.015625 , iter= 4037
current loss is: 4.111388 , acc is: 0.015625 , iter= 4038
current loss is: 3.7913094 , acc is: 0.125 , iter= 4039
current loss is: 3.894415 , acc is: 0.109375 , iter= 4040
current loss is: 4.041526 , acc is: 0.046875 , iter= 4041
current loss is: 3.9411676 , acc is: 0.0625 , iter= 4042
current loss is: 3.959264 , acc is: 0.03125 , iter= 4043
current loss is: 4.141539 , acc is: 0.015625 , iter= 4044
current loss is: 4.1145515 , acc is: 0.03125 , iter= 4045
current loss is: 4.19558 , acc is: 0.03125 , iter= 4046
current loss is: 4.0634084 , acc is: 0.015625 , iter= 4047
current loss is: 4.077189 , acc is: 0.015625 , iter= 4048
current loss is: 4.014195 , acc is: 0.0625 , iter= 4049
current loss is: 3.972769 , acc is: 0.078125 , iter= 4050
current loss is: 4.121076 , acc is: 0.0 , iter= 4051
current loss is: 4.069042 , acc is: 0.015625 , iter= 4052
current loss is: 4.044941 , acc is: 0.046875 , iter= 4053
current loss is: 4.031523 , acc is: 0.046875 , iter= 4054
current loss is: 4.0949073 , acc is: 0.046875 , iter= 4055
current loss is: 4.0659466 , acc is: 0.03125 , iter= 4056
current loss is: 3.9888756 , acc is: 0.046875 , iter= 4057
current loss is: 3.9389017 , acc is: 0.078125 , iter= 4058
current loss is: 4.0323334 , acc is: 0.0625 , iter= 4059
current loss is: 4.1811285 , acc is: 0.015625 , iter= 4060
current loss is: 3.9126859 , acc is: 0.078125 , iter= 4061
current loss is: 4.1103716 , acc is: 0.015625 , iter= 4062
current loss is: 4.149732 , acc is: 0.015625 , iter= 4063
current loss is: 4.0360775 , acc is: 0.09375 , iter= 4064
current loss is: 3.9655857 , acc is: 0.0625 , iter= 4065
current loss is: 4.31142 , acc is: 0.0625 , iter= 4066
current loss is: 4.0327206 , acc is: 0.046875 , iter= 4067
current loss is: 3.989239 , acc is: 0.078125 , iter= 4068
current loss is: 3.9455333 , acc is: 0.078125 , iter= 4069
current loss is: 4.1017666 , acc is: 0.03125 , iter= 4070
current loss is: 4.3054037 , acc is: 0.0625 , iter= 4071
current loss is: 4.012793 , acc is: 0.03125 , iter= 4072
current loss is: 3.992052 , acc is: 0.09375 , iter= 4073
current loss is: 4.0835195 , acc is: 0.046875 , iter= 4074
current loss is: 4.1842356 , acc is: 0.015625 , iter= 4075
current loss is: 4.095171 , acc is: 0.0625 , iter= 4076
current loss is: 4.1174746 , acc is: 0.046875 , iter= 4077
current loss is: 4.014248 , acc is: 0.0625 , iter= 4078
current loss is: 3.9998975 , acc is: 0.046875 , iter= 4079
current loss is: 4.1910434 , acc is: 0.015625 , iter= 4080
current loss is: 4.008399 , acc is: 0.0625 , iter= 4081
current loss is: 4.1670103 , acc is: 0.0 , iter= 4082
current loss is: 4.1059227 , acc is: 0.03125 , iter= 4083
current loss is: 3.9570732 , acc is: 0.078125 , iter= 4084
current loss is: 4.0757923 , acc is: 0.03125 , iter= 4085
current loss is: 4.0618134 , acc is: 0.03125 , iter= 4086
current loss is: 3.9444351 , acc is: 0.0625 , iter= 4087
current loss is: 3.930641 , acc is: 0.0625 , iter= 4088
current loss is: 4.005828 , acc is: 0.046875 , iter= 4089
current loss is: 4.1403575 , acc is: 0.03125 , iter= 4090
current loss is: 4.1869965 , acc is: 0.03125 , iter= 4091
current loss is: 4.1652565 , acc is: 0.0 , iter= 4092
current loss is: 4.1275096 , acc is: 0.015625 , iter= 4093
current loss is: 3.9969358 , acc is: 0.03125 , iter= 4094
current loss is: 4.020212 , acc is: 0.046875 , iter= 4095
current loss is: 4.0332136 , acc is: 0.046875 , iter= 4096
current loss is: 4.0851955 , acc is: 0.015625 , iter= 4097
current loss is: 3.9739616 , acc is: 0.0625 , iter= 4098
current loss is: 4.0505733 , acc is: 0.03125 , iter= 4099
current loss is: 4.1103973 , acc is: 0.0625 , iter= 4100
current loss is: 4.1187267 , acc is: 0.0625 , iter= 4101
current loss is: 4.0066967 , acc is: 0.078125 , iter= 4102
current loss is: 3.9681623 , acc is: 0.0625 , iter= 4103
current loss is: 3.85908 , acc is: 0.09375 , iter= 4104
current loss is: 4.058859 , acc is: 0.046875 , iter= 4105
current loss is: 4.030447 , acc is: 0.03125 , iter= 4106
current loss is: 4.0888634 , acc is: 0.046875 , iter= 4107
current loss is: 4.0315933 , acc is: 0.078125 , iter= 4108
current loss is: 4.073536 , acc is: 0.03125 , iter= 4109
current loss is: 4.0642624 , acc is: 0.078125 , iter= 4110
current loss is: 4.0010357 , acc is: 0.046875 , iter= 4111
current loss is: 3.9257045 , acc is: 0.078125 , iter= 4112
current loss is: 3.8334725 , acc is: 0.109375 , iter= 4113
current loss is: 4.0557976 , acc is: 0.03125 , iter= 4114
current loss is: 3.9024305 , acc is: 0.078125 , iter= 4115
current loss is: 4.1555357 , acc is: 0.015625 , iter= 4116
current loss is: 4.0399947 , acc is: 0.0625 , iter= 4117
current loss is: 4.1511755 , acc is: 0.0 , iter= 4118
current loss is: 4.140051 , acc is: 0.03125 , iter= 4119
current loss is: 3.857459 , acc is: 0.109375 , iter= 4120
current loss is: 3.976798 , acc is: 0.09375 , iter= 4121
current loss is: 4.076109 , acc is: 0.03125 , iter= 4122
current loss is: 4.084049 , acc is: 0.046875 , iter= 4123
current loss is: 4.0052786 , acc is: 0.078125 , iter= 4124
current loss is: 4.01742 , acc is: 0.046875 , iter= 4125
current loss is: 4.0620036 , acc is: 0.015625 , iter= 4126
current loss is: 4.04488 , acc is: 0.046875 , iter= 4127
current loss is: 4.0426435 , acc is: 0.03125 , iter= 4128
current loss is: 4.1877747 , acc is: 0.015625 , iter= 4129
current loss is: 4.1021414 , acc is: 0.0 , iter= 4130
current loss is: 4.1355934 , acc is: 0.015625 , iter= 4131
current loss is: 4.0030665 , acc is: 0.03125 , iter= 4132
current loss is: 4.153832 , acc is: 0.015625 , iter= 4133
current loss is: 4.1351876 , acc is: 0.015625 , iter= 4134
current loss is: 4.060804 , acc is: 0.03125 , iter= 4135
current loss is: 4.03293 , acc is: 0.03125 , iter= 4136
current loss is: 4.120403 , acc is: 0.03125 , iter= 4137
current loss is: 3.994532 , acc is: 0.046875 , iter= 4138
current loss is: 5.935216 , acc is: 0.03125 , iter= 4139
current loss is: 3.9597433 , acc is: 0.0625 , iter= 4140
current loss is: 4.1568575 , acc is: 0.03125 , iter= 4141
current loss is: 4.1926 , acc is: 0.0 , iter= 4142
current loss is: 4.144912 , acc is: 0.015625 , iter= 4143
current loss is: 4.205161 , acc is: 0.0 , iter= 4144
current loss is: 3.9928522 , acc is: 0.046875 , iter= 4145
current loss is: 3.9483871 , acc is: 0.046875 , iter= 4146
current loss is: 4.1427574 , acc is: 0.046875 , iter= 4147
current loss is: 3.919138 , acc is: 0.078125 , iter= 4148
current loss is: 3.9875705 , acc is: 0.078125 , iter= 4149
current loss is: 3.887344 , acc is: 0.078125 , iter= 4150
current loss is: 4.0078616 , acc is: 0.078125 , iter= 4151
current loss is: 4.154876 , acc is: 0.03125 , iter= 4152
current loss is: 4.4606385 , acc is: 0.046875 , iter= 4153
current loss is: 4.09542 , acc is: 0.03125 , iter= 4154
current loss is: 4.0971494 , acc is: 0.0625 , iter= 4155
current loss is: 4.116064 , acc is: 0.015625 , iter= 4156
current loss is: 4.019767 , acc is: 0.03125 , iter= 4157
current loss is: 3.9381976 , acc is: 0.03125 , iter= 4158
current loss is: 3.877457 , acc is: 0.109375 , iter= 4159
current loss is: 4.132972 , acc is: 0.046875 , iter= 4160
current loss is: 3.9882872 , acc is: 0.046875 , iter= 4161
current loss is: 4.0597453 , acc is: 0.0625 , iter= 4162
current loss is: 3.9200091 , acc is: 0.046875 , iter= 4163
current loss is: 4.0635624 , acc is: 0.046875 , iter= 4164
current loss is: 4.0417547 , acc is: 0.03125 , iter= 4165
current loss is: 4.034029 , acc is: 0.0625 , iter= 4166
current loss is: 4.484603 , acc is: 0.09375 , iter= 4167
current loss is: 4.06076 , acc is: 0.0625 , iter= 4168
current loss is: 3.903348 , acc is: 0.0625 , iter= 4169
current loss is: 4.0666323 , acc is: 0.015625 , iter= 4170
current loss is: 4.108412 , acc is: 0.03125 , iter= 4171
current loss is: 4.060042 , acc is: 0.03125 , iter= 4172
current loss is: 6.0256233 , acc is: 0.0 , iter= 4173
current loss is: 4.1470394 , acc is: 0.046875 , iter= 4174
current loss is: 5.3268147 , acc is: 0.046875 , iter= 4175
current loss is: 4.1286793 , acc is: 0.03125 , iter= 4176
current loss is: 4.164478 , acc is: 0.015625 , iter= 4177
current loss is: 4.198399 , acc is: 0.015625 , iter= 4178
current loss is: 4.0213585 , acc is: 0.0625 , iter= 4179
current loss is: 4.0500317 , acc is: 0.046875 , iter= 4180
current loss is: 4.0896935 , acc is: 0.03125 , iter= 4181
current loss is: 4.086299 , acc is: 0.015625 , iter= 4182
current loss is: 4.0108824 , acc is: 0.0625 , iter= 4183
current loss is: 3.9880433 , acc is: 0.046875 , iter= 4184
current loss is: 4.2038574 , acc is: 0.015625 , iter= 4185
current loss is: 4.078931 , acc is: 0.078125 , iter= 4186
current loss is: 3.9599934 , acc is: 0.0625 , iter= 4187
current loss is: 4.123502 , acc is: 0.015625 , iter= 4188
current loss is: 3.9700637 , acc is: 0.03125 , iter= 4189
current loss is: 4.0615544 , acc is: 0.03125 , iter= 4190
current loss is: 3.9531727 , acc is: 0.0625 , iter= 4191
current loss is: 4.123863 , acc is: 0.0 , iter= 4192
current loss is: 3.9867015 , acc is: 0.109375 , iter= 4193
current loss is: 4.101519 , acc is: 0.046875 , iter= 4194
current loss is: 4.1885376 , acc is: 0.0 , iter= 4195
current loss is: 4.156825 , acc is: 0.0 , iter= 4196
current loss is: 3.8185716 , acc is: 0.078125 , iter= 4197
current loss is: 4.0053296 , acc is: 0.03125 , iter= 4198
current loss is: 3.9143286 , acc is: 0.0625 , iter= 4199
current loss is: 4.087969 , acc is: 0.046875 , iter= 4200
current loss is: 4.0292563 , acc is: 0.03125 , iter= 4201
current loss is: 4.1077356 , acc is: 0.03125 , iter= 4202
current loss is: 3.9192603 , acc is: 0.0625 , iter= 4203
current loss is: 4.0456295 , acc is: 0.0625 , iter= 4204
current loss is: 4.766075 , acc is: 0.046875 , iter= 4205
current loss is: 3.88297 , acc is: 0.078125 , iter= 4206
current loss is: 4.0979166 , acc is: 0.0625 , iter= 4207
current loss is: 4.016383 , acc is: 0.09375 , iter= 4208
current loss is: 4.046444 , acc is: 0.03125 , iter= 4209
current loss is: 3.975586 , acc is: 0.09375 , iter= 4210
current loss is: 3.9855626 , acc is: 0.0625 , iter= 4211
current loss is: 4.1362906 , acc is: 0.0 , iter= 4212
current loss is: 3.9585538 , acc is: 0.078125 , iter= 4213
current loss is: 4.0199842 , acc is: 0.03125 , iter= 4214
current loss is: 4.101412 , acc is: 0.03125 , iter= 4215
current loss is: 4.1613016 , acc is: 0.0 , iter= 4216
current loss is: 3.9741032 , acc is: 0.078125 , iter= 4217
current loss is: 3.8781438 , acc is: 0.0625 , iter= 4218
current loss is: 4.160487 , acc is: 0.046875 , iter= 4219
current loss is: 4.147607 , acc is: 0.046875 , iter= 4220
current loss is: 3.9363956 , acc is: 0.078125 , iter= 4221
current loss is: 4.0798483 , acc is: 0.03125 , iter= 4222
current loss is: 4.0295105 , acc is: 0.03125 , iter= 4223
current loss is: 4.1275625 , acc is: 0.015625 , iter= 4224
current loss is: 4.0295677 , acc is: 0.0625 , iter= 4225
current loss is: 4.1207385 , acc is: 0.0625 , iter= 4226
current loss is: 4.0622005 , acc is: 0.046875 , iter= 4227
current loss is: 3.9327807 , acc is: 0.0625 , iter= 4228
current loss is: 4.0524187 , acc is: 0.03125 , iter= 4229
current loss is: 4.0738335 , acc is: 0.03125 , iter= 4230
current loss is: 4.06043 , acc is: 0.03125 , iter= 4231
current loss is: 4.0125437 , acc is: 0.078125 , iter= 4232
current loss is: 4.1167407 , acc is: 0.03125 , iter= 4233
current loss is: 4.0363154 , acc is: 0.03125 , iter= 4234
current loss is: 4.146128 , acc is: 0.015625 , iter= 4235
current loss is: 4.035923 , acc is: 0.03125 , iter= 4236
current loss is: 4.0042267 , acc is: 0.078125 , iter= 4237
current loss is: 4.242171 , acc is: 0.0625 , iter= 4238
current loss is: 4.0711823 , acc is: 0.046875 , iter= 4239
current loss is: 4.185499 , acc is: 0.0 , iter= 4240
current loss is: 4.221718 , acc is: 0.0 , iter= 4241
current loss is: 4.1827545 , acc is: 0.0 , iter= 4242
current loss is: 4.0930386 , acc is: 0.046875 , iter= 4243
current loss is: 3.9199135 , acc is: 0.078125 , iter= 4244
current loss is: 4.002705 , acc is: 0.09375 , iter= 4245
current loss is: 3.9955275 , acc is: 0.0625 , iter= 4246
current loss is: 4.180398 , acc is: 0.015625 , iter= 4247
current loss is: 4.114461 , acc is: 0.03125 , iter= 4248
current loss is: 4.146207 , acc is: 0.0 , iter= 4249
current loss is: 4.077714 , acc is: 0.03125 , iter= 4250
current loss is: 3.9436054 , acc is: 0.09375 , iter= 4251
current loss is: 4.1316094 , acc is: 0.015625 , iter= 4252
current loss is: 5.1020164 , acc is: 0.0625 , iter= 4253
current loss is: 4.0633354 , acc is: 0.03125 , iter= 4254
current loss is: 4.0095487 , acc is: 0.03125 , iter= 4255
current loss is: 4.0857654 , acc is: 0.0625 , iter= 4256
current loss is: 4.1130733 , acc is: 0.015625 , iter= 4257
current loss is: 4.0592623 , acc is: 0.046875 , iter= 4258
current loss is: 4.087783 , acc is: 0.03125 , iter= 4259
current loss is: 4.0973654 , acc is: 0.046875 , iter= 4260
current loss is: 4.012972 , acc is: 0.046875 , iter= 4261
current loss is: 4.0854692 , acc is: 0.046875 , iter= 4262
current loss is: 3.9752727 , acc is: 0.046875 , iter= 4263
current loss is: 3.9924078 , acc is: 0.03125 , iter= 4264
current loss is: 4.0975637 , acc is: 0.03125 , iter= 4265
current loss is: 4.087918 , acc is: 0.078125 , iter= 4266
current loss is: 4.101481 , acc is: 0.015625 , iter= 4267
current loss is: 4.0721054 , acc is: 0.03125 , iter= 4268
current loss is: 4.1062164 , acc is: 0.046875 , iter= 4269
current loss is: 4.053089 , acc is: 0.015625 , iter= 4270
current loss is: 4.011566 , acc is: 0.03125 , iter= 4271
current loss is: 4.053063 , acc is: 0.015625 , iter= 4272
current loss is: 3.9790816 , acc is: 0.078125 , iter= 4273
current loss is: 3.8907995 , acc is: 0.078125 , iter= 4274
current loss is: 4.0428667 , acc is: 0.03125 , iter= 4275
current loss is: 4.067358 , acc is: 0.03125 , iter= 4276
current loss is: 4.10262 , acc is: 0.03125 , iter= 4277
current loss is: 4.0471506 , acc is: 0.03125 , iter= 4278
current loss is: 4.156742 , acc is: 0.03125 , iter= 4279
current loss is: 4.0503244 , acc is: 0.015625 , iter= 4280
current loss is: 3.8103375 , acc is: 0.109375 , iter= 4281
current loss is: 3.8894174 , acc is: 0.078125 , iter= 4282
current loss is: 4.1458526 , acc is: 0.0 , iter= 4283
current loss is: 4.068898 , acc is: 0.03125 , iter= 4284
current loss is: 4.1670833 , acc is: 0.046875 , iter= 4285
current loss is: 3.904893 , acc is: 0.078125 , iter= 4286
current loss is: 4.0752773 , acc is: 0.015625 , iter= 4287
current loss is: 4.0390797 , acc is: 0.03125 , iter= 4288
current loss is: 3.9670565 , acc is: 0.0625 , iter= 4289
current loss is: 4.049633 , acc is: 0.015625 , iter= 4290
current loss is: 4.070774 , acc is: 0.0625 , iter= 4291
current loss is: 3.9486349 , acc is: 0.046875 , iter= 4292
current loss is: 4.104476 , acc is: 0.03125 , iter= 4293
current loss is: 4.0412345 , acc is: 0.046875 , iter= 4294
current loss is: 4.013695 , acc is: 0.046875 , iter= 4295
current loss is: 4.1567116 , acc is: 0.0 , iter= 4296
current loss is: 4.1283884 , acc is: 0.015625 , iter= 4297
current loss is: 4.1060505 , acc is: 0.0625 , iter= 4298
current loss is: 4.169521 , acc is: 0.0 , iter= 4299
current loss is: 4.1383805 , acc is: 0.0 , iter= 4300
current loss is: 4.0441575 , acc is: 0.015625 , iter= 4301
current loss is: 4.045318 , acc is: 0.015625 , iter= 4302
current loss is: 3.978096 , acc is: 0.09375 , iter= 4303
current loss is: 4.020933 , acc is: 0.03125 , iter= 4304
current loss is: 4.09534 , acc is: 0.03125 , iter= 4305
current loss is: 3.9992657 , acc is: 0.046875 , iter= 4306
current loss is: 3.865758 , acc is: 0.078125 , iter= 4307
current loss is: 3.915122 , acc is: 0.078125 , iter= 4308
current loss is: 4.148096 , acc is: 0.046875 , iter= 4309
current loss is: 4.005228 , acc is: 0.0625 , iter= 4310
current loss is: 4.0799336 , acc is: 0.015625 , iter= 4311
current loss is: 4.1387577 , acc is: 0.03125 , iter= 4312
current loss is: 3.9478068 , acc is: 0.046875 , iter= 4313
current loss is: 3.9010415 , acc is: 0.078125 , iter= 4314
current loss is: 4.104185 , acc is: 0.03125 , iter= 4315
current loss is: 4.166296 , acc is: 0.015625 , iter= 4316
current loss is: 4.0184135 , acc is: 0.015625 , iter= 4317
current loss is: 3.8846662 , acc is: 0.0625 , iter= 4318
current loss is: 4.167242 , acc is: 0.03125 , iter= 4319
current loss is: 4.025419 , acc is: 0.046875 , iter= 4320
current loss is: 4.130217 , acc is: 0.015625 , iter= 4321
current loss is: 4.0597906 , acc is: 0.03125 , iter= 4322
current loss is: 4.209366 , acc is: 0.0 , iter= 4323
current loss is: 4.128292 , acc is: 0.0 , iter= 4324
current loss is: 3.9928887 , acc is: 0.0625 , iter= 4325
current loss is: 4.0720587 , acc is: 0.03125 , iter= 4326
current loss is: 4.037772 , acc is: 0.0625 , iter= 4327
current loss is: 3.98789 , acc is: 0.0625 , iter= 4328
current loss is: 4.0043507 , acc is: 0.0625 , iter= 4329
current loss is: 4.1924324 , acc is: 0.03125 , iter= 4330
current loss is: 3.9623597 , acc is: 0.09375 , iter= 4331
current loss is: 4.045665 , acc is: 0.0625 , iter= 4332
current loss is: 4.06678 , acc is: 0.03125 , iter= 4333
current loss is: 3.9308634 , acc is: 0.046875 , iter= 4334
current loss is: 4.1505613 , acc is: 0.046875 , iter= 4335
current loss is: 4.136114 , acc is: 0.015625 , iter= 4336
current loss is: 4.037217 , acc is: 0.03125 , iter= 4337
current loss is: 4.087813 , acc is: 0.015625 , iter= 4338
current loss is: 4.0201616 , acc is: 0.0625 , iter= 4339
current loss is: 3.8533006 , acc is: 0.09375 , iter= 4340
current loss is: 4.134373 , acc is: 0.0625 , iter= 4341
current loss is: 4.057041 , acc is: 0.046875 , iter= 4342
current loss is: 4.0188417 , acc is: 0.0625 , iter= 4343
current loss is: 4.066292 , acc is: 0.03125 , iter= 4344
current loss is: 4.144497 , acc is: 0.015625 , iter= 4345
current loss is: 4.104766 , acc is: 0.0 , iter= 4346
current loss is: 4.100635 , acc is: 0.015625 , iter= 4347
current loss is: 4.0291605 , acc is: 0.0625 , iter= 4348
current loss is: 4.0543585 , acc is: 0.015625 , iter= 4349
current loss is: 4.15564 , acc is: 0.015625 , iter= 4350
current loss is: 4.1050253 , acc is: 0.03125 , iter= 4351
current loss is: 4.0951552 , acc is: 0.046875 , iter= 4352
current loss is: 4.1917963 , acc is: 0.0 , iter= 4353
current loss is: 4.0216174 , acc is: 0.0625 , iter= 4354
current loss is: 3.9916496 , acc is: 0.09375 , iter= 4355
current loss is: 4.0081906 , acc is: 0.09375 , iter= 4356
current loss is: 3.9808748 , acc is: 0.046875 , iter= 4357
current loss is: 4.068055 , acc is: 0.046875 , iter= 4358
current loss is: 4.044103 , acc is: 0.03125 , iter= 4359
current loss is: 4.0774117 , acc is: 0.046875 , iter= 4360
current loss is: 4.0899305 , acc is: 0.03125 , iter= 4361
current loss is: 3.9856 , acc is: 0.046875 , iter= 4362
current loss is: 4.1919317 , acc is: 0.0 , iter= 4363
current loss is: 4.0212483 , acc is: 0.0625 , iter= 4364
current loss is: 4.1020756 , acc is: 0.0625 , iter= 4365
current loss is: 3.8538418 , acc is: 0.09375 , iter= 4366
current loss is: 4.0431175 , acc is: 0.015625 , iter= 4367
current loss is: 3.9266758 , acc is: 0.078125 , iter= 4368
current loss is: 3.9391046 , acc is: 0.078125 , iter= 4369
current loss is: 4.1101217 , acc is: 0.046875 , iter= 4370
current loss is: 4.133567 , acc is: 0.015625 , iter= 4371
current loss is: 3.9887838 , acc is: 0.09375 , iter= 4372
current loss is: 4.0987644 , acc is: 0.03125 , iter= 4373
current loss is: 5.5975122 , acc is: 0.015625 , iter= 4374
current loss is: 3.9767756 , acc is: 0.046875 , iter= 4375
current loss is: 3.8965712 , acc is: 0.078125 , iter= 4376
current loss is: 4.1064835 , acc is: 0.015625 , iter= 4377
current loss is: 4.033666 , acc is: 0.046875 , iter= 4378
current loss is: 3.95474 , acc is: 0.078125 , iter= 4379
current loss is: 4.158225 , acc is: 0.03125 , iter= 4380
current loss is: 4.0882807 , acc is: 0.078125 , iter= 4381
current loss is: 4.080576 , acc is: 0.015625 , iter= 4382
current loss is: 4.0060825 , acc is: 0.046875 , iter= 4383
current loss is: 4.0662622 , acc is: 0.03125 , iter= 4384
current loss is: 4.009073 , acc is: 0.078125 , iter= 4385
current loss is: 4.1096535 , acc is: 0.03125 , iter= 4386
current loss is: 4.015133 , acc is: 0.0625 , iter= 4387
current loss is: 4.098131 , acc is: 0.046875 , iter= 4388
current loss is: 4.0240555 , acc is: 0.03125 , iter= 4389
current loss is: 4.025469 , acc is: 0.03125 , iter= 4390
current loss is: 3.9699283 , acc is: 0.078125 , iter= 4391
current loss is: 3.9880786 , acc is: 0.03125 , iter= 4392
current loss is: 4.1546383 , acc is: 0.0 , iter= 4393
current loss is: 4.0369287 , acc is: 0.0625 , iter= 4394
current loss is: 4.182007 , acc is: 0.015625 , iter= 4395
current loss is: 4.059865 , acc is: 0.03125 , iter= 4396
current loss is: 3.9066012 , acc is: 0.046875 , iter= 4397
current loss is: 4.072508 , acc is: 0.03125 , iter= 4398
current loss is: 3.9735224 , acc is: 0.046875 , iter= 4399
current loss is: 4.101099 , acc is: 0.015625 , iter= 4400
current loss is: 4.029948 , acc is: 0.03125 , iter= 4401
current loss is: 4.1021757 , acc is: 0.03125 , iter= 4402
current loss is: 4.000596 , acc is: 0.046875 , iter= 4403
current loss is: 4.0377135 , acc is: 0.078125 , iter= 4404
current loss is: 4.0476637 , acc is: 0.015625 , iter= 4405
current loss is: 4.0419836 , acc is: 0.03125 , iter= 4406
current loss is: 4.020187 , acc is: 0.03125 , iter= 4407
current loss is: 4.1108093 , acc is: 0.015625 , iter= 4408
current loss is: 4.0471406 , acc is: 0.09375 , iter= 4409
current loss is: 4.1259375 , acc is: 0.03125 , iter= 4410
current loss is: 3.983851 , acc is: 0.046875 , iter= 4411
current loss is: 4.106945 , acc is: 0.03125 , iter= 4412
current loss is: 4.000511 , acc is: 0.078125 , iter= 4413
current loss is: 3.859623 , acc is: 0.109375 , iter= 4414
current loss is: 3.915638 , acc is: 0.0625 , iter= 4415
current loss is: 4.1221294 , acc is: 0.03125 , iter= 4416
current loss is: 3.986241 , acc is: 0.046875 , iter= 4417
current loss is: 4.3149614 , acc is: 0.015625 , iter= 4418
current loss is: 4.0988555 , acc is: 0.0625 , iter= 4419
current loss is: 4.124236 , acc is: 0.03125 , iter= 4420
current loss is: 4.0238576 , acc is: 0.03125 , iter= 4421
current loss is: 4.0405474 , acc is: 0.03125 , iter= 4422
current loss is: 4.05803 , acc is: 0.03125 , iter= 4423
current loss is: 4.0552654 , acc is: 0.046875 , iter= 4424
current loss is: 4.060004 , acc is: 0.046875 , iter= 4425
current loss is: 4.075448 , acc is: 0.03125 , iter= 4426
current loss is: 3.9328861 , acc is: 0.078125 , iter= 4427
current loss is: 4.105851 , acc is: 0.03125 , iter= 4428
current loss is: 3.976407 , acc is: 0.078125 , iter= 4429
current loss is: 3.9621801 , acc is: 0.078125 , iter= 4430
current loss is: 4.1183863 , acc is: 0.015625 , iter= 4431
current loss is: 4.094635 , acc is: 0.03125 , iter= 4432
current loss is: 4.11012 , acc is: 0.03125 , iter= 4433
current loss is: 3.9454541 , acc is: 0.125 , iter= 4434
current loss is: 4.1619806 , acc is: 0.015625 , iter= 4435
current loss is: 4.1513934 , acc is: 0.015625 , iter= 4436
current loss is: 4.037627 , acc is: 0.078125 , iter= 4437
current loss is: 3.8820562 , acc is: 0.0625 , iter= 4438
current loss is: 4.0280776 , acc is: 0.03125 , iter= 4439
current loss is: 4.0735884 , acc is: 0.03125 , iter= 4440
current loss is: 4.010869 , acc is: 0.078125 , iter= 4441
current loss is: 4.011408 , acc is: 0.046875 , iter= 4442
current loss is: 4.868558 , acc is: 0.0 , iter= 4443
current loss is: 4.1392527 , acc is: 0.015625 , iter= 4444
current loss is: 4.1475267 , acc is: 0.015625 , iter= 4445
current loss is: 4.1290703 , acc is: 0.03125 , iter= 4446
current loss is: 4.1802063 , acc is: 0.03125 , iter= 4447
current loss is: 3.9851818 , acc is: 0.078125 , iter= 4448
current loss is: 4.0803094 , acc is: 0.046875 , iter= 4449
current loss is: 4.0055766 , acc is: 0.03125 , iter= 4450
current loss is: 4.1016893 , acc is: 0.03125 , iter= 4451
current loss is: 4.171928 , acc is: 0.015625 , iter= 4452
current loss is: 4.031345 , acc is: 0.046875 , iter= 4453
current loss is: 3.973668 , acc is: 0.0625 , iter= 4454
current loss is: 4.171993 , acc is: 0.0 , iter= 4455
current loss is: 3.9350832 , acc is: 0.09375 , iter= 4456
current loss is: 4.145672 , acc is: 0.0 , iter= 4457
current loss is: 4.1866508 , acc is: 0.0625 , iter= 4458
current loss is: 3.8500054 , acc is: 0.109375 , iter= 4459
current loss is: 3.9734364 , acc is: 0.078125 , iter= 4460
current loss is: 4.0923257 , acc is: 0.0 , iter= 4461
current loss is: 4.1019325 , acc is: 0.09375 , iter= 4462
current loss is: 4.1198006 , acc is: 0.015625 , iter= 4463
current loss is: 3.915646 , acc is: 0.078125 , iter= 4464
current loss is: 4.060517 , acc is: 0.03125 , iter= 4465
current loss is: 4.05404 , acc is: 0.046875 , iter= 4466
current loss is: 4.0106497 , acc is: 0.046875 , iter= 4467
current loss is: 4.009392 , acc is: 0.046875 , iter= 4468
current loss is: 3.9876986 , acc is: 0.078125 , iter= 4469
current loss is: 4.185566 , acc is: 0.0625 , iter= 4470
current loss is: 3.978705 , acc is: 0.046875 , iter= 4471
current loss is: 4.100178 , acc is: 0.03125 , iter= 4472
current loss is: 4.0973988 , acc is: 0.0 , iter= 4473
current loss is: 4.0956755 , acc is: 0.015625 , iter= 4474
current loss is: 3.9305966 , acc is: 0.078125 , iter= 4475
current loss is: 4.042308 , acc is: 0.046875 , iter= 4476
current loss is: 4.17601 , acc is: 0.015625 , iter= 4477
current loss is: 4.035224 , acc is: 0.078125 , iter= 4478
current loss is: 4.0509815 , acc is: 0.046875 , iter= 4479
current loss is: 4.072205 , acc is: 0.03125 , iter= 4480
current loss is: 4.0143614 , acc is: 0.0625 , iter= 4481
current loss is: 4.0671024 , acc is: 0.046875 , iter= 4482
current loss is: 3.9667673 , acc is: 0.046875 , iter= 4483
current loss is: 4.0314474 , acc is: 0.03125 , iter= 4484
current loss is: 4.1467953 , acc is: 0.046875 , iter= 4485
current loss is: 4.0538898 , acc is: 0.03125 , iter= 4486
current loss is: 4.0431013 , acc is: 0.078125 , iter= 4487
current loss is: 4.0477905 , acc is: 0.046875 , iter= 4488
current loss is: 4.101489 , acc is: 0.015625 , iter= 4489
current loss is: 4.016753 , acc is: 0.046875 , iter= 4490
current loss is: 4.062566 , acc is: 0.015625 , iter= 4491
current loss is: 3.947676 , acc is: 0.046875 , iter= 4492
current loss is: 4.056125 , acc is: 0.015625 , iter= 4493
current loss is: 4.0792017 , acc is: 0.03125 , iter= 4494
current loss is: 4.0350757 , acc is: 0.046875 , iter= 4495
current loss is: 4.072854 , acc is: 0.03125 , iter= 4496
current loss is: 4.0075765 , acc is: 0.015625 , iter= 4497
current loss is: 4.1188545 , acc is: 0.015625 , iter= 4498
current loss is: 4.1525807 , acc is: 0.0 , iter= 4499
current loss is: 4.11339 , acc is: 0.015625 , iter= 4500
current loss is: 4.116206 , acc is: 0.015625 , iter= 4501
current loss is: 4.186656 , acc is: 0.0 , iter= 4502
current loss is: 4.0522623 , acc is: 0.046875 , iter= 4503
current loss is: 4.2154293 , acc is: 0.0625 , iter= 4504
current loss is: 3.893942 , acc is: 0.078125 , iter= 4505
current loss is: 4.015457 , acc is: 0.0625 , iter= 4506
current loss is: 3.9546497 , acc is: 0.0625 , iter= 4507
current loss is: 4.13591 , acc is: 0.09375 , iter= 4508
current loss is: 4.012336 , acc is: 0.03125 , iter= 4509
current loss is: 4.134319 , acc is: 0.015625 , iter= 4510
current loss is: 4.1541247 , acc is: 0.046875 , iter= 4511
current loss is: 3.9777853 , acc is: 0.046875 , iter= 4512
current loss is: 4.0017285 , acc is: 0.078125 , iter= 4513
current loss is: 4.127365 , acc is: 0.03125 , iter= 4514
current loss is: 4.1623163 , acc is: 0.046875 , iter= 4515
current loss is: 4.094256 , acc is: 0.0625 , iter= 4516
current loss is: 4.0146475 , acc is: 0.0625 , iter= 4517
current loss is: 4.1146717 , acc is: 0.015625 , iter= 4518
current loss is: 4.040966 , acc is: 0.03125 , iter= 4519
current loss is: 4.1654053 , acc is: 0.0 , iter= 4520
current loss is: 5.279105 , acc is: 0.046875 , iter= 4521
current loss is: 4.030162 , acc is: 0.046875 , iter= 4522
current loss is: 4.149085 , acc is: 0.0 , iter= 4523
current loss is: 3.9987388 , acc is: 0.078125 , iter= 4524
current loss is: 4.095981 , acc is: 0.0 , iter= 4525
current loss is: 4.0640373 , acc is: 0.046875 , iter= 4526
current loss is: 3.9963365 , acc is: 0.0625 , iter= 4527
current loss is: 4.038266 , acc is: 0.046875 , iter= 4528
current loss is: 4.082081 , acc is: 0.03125 , iter= 4529
current loss is: 3.9884212 , acc is: 0.03125 , iter= 4530
current loss is: 3.9614031 , acc is: 0.046875 , iter= 4531
current loss is: 4.153144 , acc is: 0.015625 , iter= 4532
current loss is: 3.9020622 , acc is: 0.078125 , iter= 4533
current loss is: 4.156725 , acc is: 0.03125 , iter= 4534
current loss is: 4.148494 , acc is: 0.0 , iter= 4535
current loss is: 3.9561634 , acc is: 0.0625 , iter= 4536
current loss is: 5.3508034 , acc is: 0.046875 , iter= 4537
current loss is: 4.088131 , acc is: 0.03125 , iter= 4538
current loss is: 3.9141598 , acc is: 0.046875 , iter= 4539
current loss is: 4.13048 , acc is: 0.0 , iter= 4540
current loss is: 4.0706615 , acc is: 0.046875 , iter= 4541
current loss is: 4.1143827 , acc is: 0.046875 , iter= 4542
current loss is: 4.0807505 , acc is: 0.046875 , iter= 4543
current loss is: 4.097348 , acc is: 0.046875 , iter= 4544
current loss is: 4.153602 , acc is: 0.03125 , iter= 4545
current loss is: 4.0466166 , acc is: 0.03125 , iter= 4546
current loss is: 4.006052 , acc is: 0.046875 , iter= 4547
current loss is: 3.9692566 , acc is: 0.078125 , iter= 4548
current loss is: 4.1453586 , acc is: 0.015625 , iter= 4549
current loss is: 4.0708947 , acc is: 0.0625 , iter= 4550
current loss is: 3.988293 , acc is: 0.046875 , iter= 4551
current loss is: 4.023733 , acc is: 0.0625 , iter= 4552
current loss is: 4.5268745 , acc is: 0.015625 , iter= 4553
current loss is: 4.0246086 , acc is: 0.03125 , iter= 4554
current loss is: 4.0079184 , acc is: 0.03125 , iter= 4555
current loss is: 4.1044874 , acc is: 0.03125 , iter= 4556
current loss is: 4.0368323 , acc is: 0.046875 , iter= 4557
current loss is: 4.053029 , acc is: 0.046875 , iter= 4558
current loss is: 4.1634493 , acc is: 0.0 , iter= 4559
current loss is: 4.0048313 , acc is: 0.0625 , iter= 4560
current loss is: 4.077453 , acc is: 0.015625 , iter= 4561
current loss is: 4.165885 , acc is: 0.015625 , iter= 4562
current loss is: 3.9606752 , acc is: 0.078125 , iter= 4563
current loss is: 4.0079384 , acc is: 0.078125 , iter= 4564
current loss is: 4.055559 , acc is: 0.015625 , iter= 4565
current loss is: 4.0735226 , acc is: 0.03125 , iter= 4566
current loss is: 4.0827713 , acc is: 0.046875 , iter= 4567
current loss is: 4.0233455 , acc is: 0.046875 , iter= 4568
current loss is: 4.053857 , acc is: 0.015625 , iter= 4569
current loss is: 4.1652727 , acc is: 0.015625 , iter= 4570
current loss is: 4.1312804 , acc is: 0.046875 , iter= 4571
current loss is: 4.055419 , acc is: 0.0625 , iter= 4572
current loss is: 4.083452 , acc is: 0.046875 , iter= 4573
current loss is: 4.762023 , acc is: 0.03125 , iter= 4574
current loss is: 4.0985503 , acc is: 0.015625 , iter= 4575
current loss is: 3.9404042 , acc is: 0.0625 , iter= 4576
current loss is: 4.609297 , acc is: 0.0 , iter= 4577
current loss is: 4.122186 , acc is: 0.015625 , iter= 4578
current loss is: 4.189722 , acc is: 0.015625 , iter= 4579
current loss is: 4.0253735 , acc is: 0.046875 , iter= 4580
current loss is: 4.159759 , acc is: 0.0 , iter= 4581
current loss is: 4.0129485 , acc is: 0.03125 , iter= 4582
current loss is: 4.187559 , acc is: 0.015625 , iter= 4583
current loss is: 4.8281603 , acc is: 0.078125 , iter= 4584
current loss is: 4.1231537 , acc is: 0.046875 , iter= 4585
current loss is: 4.1672554 , acc is: 0.015625 , iter= 4586
current loss is: 3.98731 , acc is: 0.0625 , iter= 4587
current loss is: 3.964324 , acc is: 0.078125 , iter= 4588
current loss is: 4.1563196 , acc is: 0.03125 , iter= 4589
current loss is: 3.9689143 , acc is: 0.0625 , iter= 4590
current loss is: 4.1090736 , acc is: 0.03125 , iter= 4591
current loss is: 3.9721646 , acc is: 0.03125 , iter= 4592
current loss is: 4.108497 , acc is: 0.03125 , iter= 4593
current loss is: 3.9752967 , acc is: 0.0625 , iter= 4594
current loss is: 3.8331676 , acc is: 0.09375 , iter= 4595
current loss is: 4.0763617 , acc is: 0.078125 , iter= 4596
current loss is: 3.9235 , acc is: 0.078125 , iter= 4597
current loss is: 4.078907 , acc is: 0.015625 , iter= 4598
current loss is: 4.133492 , acc is: 0.0625 , iter= 4599
current loss is: 3.947933 , acc is: 0.09375 , iter= 4600
current loss is: 4.0178547 , acc is: 0.0625 , iter= 4601
current loss is: 4.080224 , acc is: 0.046875 , iter= 4602
current loss is: 4.1036487 , acc is: 0.046875 , iter= 4603
current loss is: 4.142882 , acc is: 0.0 , iter= 4604
current loss is: 4.152437 , acc is: 0.03125 , iter= 4605
current loss is: 4.1557713 , acc is: 0.015625 , iter= 4606
current loss is: 3.986859 , acc is: 0.046875 , iter= 4607
current loss is: 4.151133 , acc is: 0.015625 , iter= 4608
current loss is: 3.9860415 , acc is: 0.046875 , iter= 4609
current loss is: 4.1444025 , acc is: 0.046875 , iter= 4610
current loss is: 4.0020046 , acc is: 0.0625 , iter= 4611
current loss is: 4.120078 , acc is: 0.0 , iter= 4612
current loss is: 4.126554 , acc is: 0.0 , iter= 4613
current loss is: 4.136653 , acc is: 0.015625 , iter= 4614
current loss is: 4.115979 , acc is: 0.015625 , iter= 4615
current loss is: 3.982044 , acc is: 0.078125 , iter= 4616
current loss is: 3.9725275 , acc is: 0.046875 , iter= 4617
current loss is: 4.1476507 , acc is: 0.0625 , iter= 4618
current loss is: 4.1573896 , acc is: 0.03125 , iter= 4619
current loss is: 4.17912 , acc is: 0.0 , iter= 4620
current loss is: 4.109707 , acc is: 0.03125 , iter= 4621
current loss is: 4.0520115 , acc is: 0.046875 , iter= 4622
current loss is: 4.0598755 , acc is: 0.046875 , iter= 4623
current loss is: 4.024637 , acc is: 0.078125 , iter= 4624
current loss is: 4.1215324 , acc is: 0.015625 , iter= 4625
current loss is: 4.0765276 , acc is: 0.03125 , iter= 4626
current loss is: 3.67946 , acc is: 0.109375 , iter= 4627
current loss is: 4.0594487 , acc is: 0.046875 , iter= 4628
current loss is: 4.0421853 , acc is: 0.046875 , iter= 4629
current loss is: 4.078702 , acc is: 0.0625 , iter= 4630
current loss is: 4.0688267 , acc is: 0.046875 , iter= 4631
current loss is: 4.0392575 , acc is: 0.03125 , iter= 4632
current loss is: 3.908731 , acc is: 0.0625 , iter= 4633
current loss is: 4.1915207 , acc is: 0.0 , iter= 4634
current loss is: 4.0303907 , acc is: 0.015625 , iter= 4635
current loss is: 3.8641272 , acc is: 0.0625 , iter= 4636
current loss is: 4.000563 , acc is: 0.0625 , iter= 4637
current loss is: 4.317732 , acc is: 0.0 , iter= 4638
current loss is: 4.0750704 , acc is: 0.046875 , iter= 4639
current loss is: 4.027666 , acc is: 0.046875 , iter= 4640
current loss is: 4.0889125 , acc is: 0.03125 , iter= 4641
current loss is: 4.0528984 , acc is: 0.015625 , iter= 4642
current loss is: 4.058647 , acc is: 0.03125 , iter= 4643
current loss is: 4.0907936 , acc is: 0.015625 , iter= 4644
current loss is: 3.956392 , acc is: 0.0625 , iter= 4645
current loss is: 3.9950523 , acc is: 0.0625 , iter= 4646
current loss is: 4.2294025 , acc is: 0.0625 , iter= 4647
current loss is: 4.0845776 , acc is: 0.03125 , iter= 4648
current loss is: 4.472797 , acc is: 0.015625 , iter= 4649
current loss is: 4.0715637 , acc is: 0.0625 , iter= 4650
current loss is: 6.137384 , acc is: 0.046875 , iter= 4651
current loss is: 4.1187563 , acc is: 0.03125 , iter= 4652
current loss is: 3.941335 , acc is: 0.078125 , iter= 4653
current loss is: 4.0331583 , acc is: 0.0625 , iter= 4654
current loss is: 4.0655975 , acc is: 0.03125 , iter= 4655
current loss is: 4.2103386 , acc is: 0.015625 , iter= 4656
current loss is: 3.8092625 , acc is: 0.109375 , iter= 4657
current loss is: 4.0374765 , acc is: 0.03125 , iter= 4658
current loss is: 4.118502 , acc is: 0.03125 , iter= 4659
current loss is: 4.0859737 , acc is: 0.03125 , iter= 4660
current loss is: 3.9108632 , acc is: 0.078125 , iter= 4661
current loss is: 4.0691695 , acc is: 0.015625 , iter= 4662
current loss is: 4.1556225 , acc is: 0.0 , iter= 4663
current loss is: 3.99515 , acc is: 0.078125 , iter= 4664
current loss is: 4.040244 , acc is: 0.046875 , iter= 4665
current loss is: 4.0274076 , acc is: 0.046875 , iter= 4666
current loss is: 4.7306733 , acc is: 0.046875 , iter= 4667
current loss is: 4.08119 , acc is: 0.046875 , iter= 4668
current loss is: 4.1026897 , acc is: 0.03125 , iter= 4669
current loss is: 4.089604 , acc is: 0.03125 , iter= 4670
current loss is: 4.0856304 , acc is: 0.03125 , iter= 4671
current loss is: 3.9088366 , acc is: 0.0625 , iter= 4672
current loss is: 3.9467168 , acc is: 0.046875 , iter= 4673
current loss is: 4.1703053 , acc is: 0.046875 , iter= 4674
current loss is: 4.0393534 , acc is: 0.0625 , iter= 4675
current loss is: 4.035558 , acc is: 0.046875 , iter= 4676
current loss is: 4.073049 , acc is: 0.03125 , iter= 4677
current loss is: 4.0204744 , acc is: 0.046875 , iter= 4678
current loss is: 4.0045123 , acc is: 0.0625 , iter= 4679
current loss is: 4.092821 , acc is: 0.03125 , iter= 4680
current loss is: 4.057282 , acc is: 0.046875 , iter= 4681
current loss is: 4.008052 , acc is: 0.03125 , iter= 4682
current loss is: 4.205302 , acc is: 0.015625 , iter= 4683
current loss is: 4.0792646 , acc is: 0.046875 , iter= 4684
current loss is: 4.0836363 , acc is: 0.046875 , iter= 4685
current loss is: 4.156377 , acc is: 0.046875 , iter= 4686
current loss is: 3.9327786 , acc is: 0.09375 , iter= 4687
current loss is: 4.216289 , acc is: 0.0 , iter= 4688
current loss is: 4.0303593 , acc is: 0.03125 , iter= 4689
current loss is: 4.1813865 , acc is: 0.03125 , iter= 4690
current loss is: 3.9703128 , acc is: 0.03125 , iter= 4691
current loss is: 8.651004 , acc is: 0.046875 , iter= 4692
current loss is: 4.1556563 , acc is: 0.0 , iter= 4693
current loss is: 4.030103 , acc is: 0.046875 , iter= 4694
current loss is: 4.0182514 , acc is: 0.015625 , iter= 4695
current loss is: 3.8874576 , acc is: 0.078125 , iter= 4696
current loss is: 4.013798 , acc is: 0.046875 , iter= 4697
current loss is: 4.024178 , acc is: 0.046875 , iter= 4698
current loss is: 4.13177 , acc is: 0.0625 , iter= 4699
current loss is: 4.1165767 , acc is: 0.078125 , iter= 4700
current loss is: 3.9452577 , acc is: 0.046875 , iter= 4701
current loss is: 4.1214037 , acc is: 0.015625 , iter= 4702
current loss is: 4.1336246 , acc is: 0.03125 , iter= 4703
current loss is: 4.093131 , acc is: 0.046875 , iter= 4704
current loss is: 4.0781846 , acc is: 0.03125 , iter= 4705
current loss is: 4.0044823 , acc is: 0.046875 , iter= 4706
current loss is: 4.177128 , acc is: 0.015625 , iter= 4707
current loss is: 3.9150546 , acc is: 0.078125 , iter= 4708
current loss is: 4.144435 , acc is: 0.0 , iter= 4709
current loss is: 4.003767 , acc is: 0.09375 , iter= 4710
current loss is: 4.1794505 , acc is: 0.03125 , iter= 4711
current loss is: 4.029075 , acc is: 0.046875 , iter= 4712
current loss is: 4.0326304 , acc is: 0.015625 , iter= 4713
current loss is: 4.0744247 , acc is: 0.046875 , iter= 4714
current loss is: 4.0473804 , acc is: 0.046875 , iter= 4715
current loss is: 4.0406313 , acc is: 0.046875 , iter= 4716
current loss is: 3.9569914 , acc is: 0.0625 , iter= 4717
current loss is: 4.166351 , acc is: 0.015625 , iter= 4718
current loss is: 4.0616627 , acc is: 0.03125 , iter= 4719
current loss is: 4.121336 , acc is: 0.0 , iter= 4720
current loss is: 4.0783443 , acc is: 0.046875 , iter= 4721
current loss is: 4.0823884 , acc is: 0.03125 , iter= 4722
current loss is: 4.0089855 , acc is: 0.046875 , iter= 4723
current loss is: 3.8770928 , acc is: 0.0625 , iter= 4724
current loss is: 3.9865394 , acc is: 0.046875 , iter= 4725
current loss is: 4.0831833 , acc is: 0.015625 , iter= 4726
current loss is: 4.086027 , acc is: 0.046875 , iter= 4727
current loss is: 4.094198 , acc is: 0.015625 , iter= 4728
current loss is: 4.0278497 , acc is: 0.0625 , iter= 4729
current loss is: 4.0575314 , acc is: 0.03125 , iter= 4730
current loss is: 4.009715 , acc is: 0.046875 , iter= 4731
current loss is: 4.1576123 , acc is: 0.0625 , iter= 4732
current loss is: 3.9457092 , acc is: 0.09375 , iter= 4733
current loss is: 4.193005 , acc is: 0.0 , iter= 4734
current loss is: 3.944283 , acc is: 0.0625 , iter= 4735
current loss is: 4.0254273 , acc is: 0.046875 , iter= 4736
current loss is: 4.1951933 , acc is: 0.0 , iter= 4737
current loss is: 4.115236 , acc is: 0.03125 , iter= 4738
current loss is: 4.199316 , acc is: 0.0 , iter= 4739
current loss is: 3.8010204 , acc is: 0.078125 , iter= 4740
current loss is: 3.9765158 , acc is: 0.03125 , iter= 4741
current loss is: 4.187639 , acc is: 0.03125 , iter= 4742
current loss is: 4.201886 , acc is: 0.0 , iter= 4743
current loss is: 4.0879526 , acc is: 0.015625 , iter= 4744
current loss is: 3.9842057 , acc is: 0.046875 , iter= 4745
current loss is: 4.1510177 , acc is: 0.015625 , iter= 4746
current loss is: 4.0708933 , acc is: 0.046875 , iter= 4747
current loss is: 3.972471 , acc is: 0.0625 , iter= 4748
current loss is: 3.9010093 , acc is: 0.109375 , iter= 4749
current loss is: 3.986414 , acc is: 0.046875 , iter= 4750
current loss is: 4.1530457 , acc is: 0.03125 , iter= 4751
current loss is: 4.1245008 , acc is: 0.046875 , iter= 4752
current loss is: 3.9927173 , acc is: 0.046875 , iter= 4753
current loss is: 4.119851 , acc is: 0.015625 , iter= 4754
current loss is: 4.0363703 , acc is: 0.015625 , iter= 4755
current loss is: 3.9421892 , acc is: 0.046875 , iter= 4756
current loss is: 3.9941633 , acc is: 0.078125 , iter= 4757
current loss is: 4.1308036 , acc is: 0.046875 , iter= 4758
current loss is: 3.9261122 , acc is: 0.0625 , iter= 4759
current loss is: 4.0943623 , acc is: 0.015625 , iter= 4760
current loss is: 4.0289483 , acc is: 0.046875 , iter= 4761
current loss is: 3.9584627 , acc is: 0.078125 , iter= 4762
current loss is: 4.06306 , acc is: 0.015625 , iter= 4763
current loss is: 3.9889703 , acc is: 0.078125 , iter= 4764
current loss is: 4.0912046 , acc is: 0.015625 , iter= 4765
current loss is: 4.0648274 , acc is: 0.0625 , iter= 4766
current loss is: 3.9251726 , acc is: 0.0625 , iter= 4767
current loss is: 4.0897794 , acc is: 0.03125 , iter= 4768
current loss is: 4.1641083 , acc is: 0.0 , iter= 4769
current loss is: 4.09379 , acc is: 0.0 , iter= 4770
current loss is: 4.037826 , acc is: 0.03125 , iter= 4771
current loss is: 4.1685815 , acc is: 0.03125 , iter= 4772
current loss is: 7.40592 , acc is: 0.109375 , iter= 4773
current loss is: 4.0012617 , acc is: 0.046875 , iter= 4774
current loss is: 3.9156537 , acc is: 0.0625 , iter= 4775
current loss is: 4.1057415 , acc is: 0.03125 , iter= 4776
current loss is: 4.728306 , acc is: 0.046875 , iter= 4777
current loss is: 4.1554675 , acc is: 0.0 , iter= 4778
current loss is: 4.1367817 , acc is: 0.015625 , iter= 4779
current loss is: 4.116101 , acc is: 0.03125 , iter= 4780
current loss is: 4.0470953 , acc is: 0.046875 , iter= 4781
current loss is: 4.1550083 , acc is: 0.03125 , iter= 4782
current loss is: 3.9250553 , acc is: 0.0625 , iter= 4783
current loss is: 4.142358 , acc is: 0.015625 , iter= 4784
current loss is: 4.96587 , acc is: 0.03125 , iter= 4785
current loss is: 4.0350327 , acc is: 0.03125 , iter= 4786
current loss is: 4.0672703 , acc is: 0.046875 , iter= 4787
current loss is: 5.540962 , acc is: 0.03125 , iter= 4788
current loss is: 3.9894738 , acc is: 0.046875 , iter= 4789
current loss is: 4.1622066 , acc is: 0.03125 , iter= 4790
current loss is: 4.711982 , acc is: 0.03125 , iter= 4791
current loss is: 4.1595407 , acc is: 0.015625 , iter= 4792
current loss is: 4.043804 , acc is: 0.015625 , iter= 4793
current loss is: 4.126688 , acc is: 0.0625 , iter= 4794
current loss is: 4.086381 , acc is: 0.03125 , iter= 4795
current loss is: 4.017433 , acc is: 0.046875 , iter= 4796
current loss is: 4.0252867 , acc is: 0.109375 , iter= 4797
current loss is: 3.9430423 , acc is: 0.09375 , iter= 4798
current loss is: 4.066516 , acc is: 0.03125 , iter= 4799
current loss is: 4.110936 , acc is: 0.03125 , iter= 4800
current loss is: 4.1481752 , acc is: 0.015625 , iter= 4801
current loss is: 4.0491376 , acc is: 0.03125 , iter= 4802
current loss is: 4.083617 , acc is: 0.03125 , iter= 4803
current loss is: 3.8831623 , acc is: 0.109375 , iter= 4804
current loss is: 5.084936 , acc is: 0.03125 , iter= 4805
current loss is: 4.1105146 , acc is: 0.046875 , iter= 4806
current loss is: 4.152629 , acc is: 0.03125 , iter= 4807
current loss is: 4.076194 , acc is: 0.0625 , iter= 4808
current loss is: 4.1291094 , acc is: 0.046875 , iter= 4809
current loss is: 4.060836 , acc is: 0.046875 , iter= 4810
current loss is: 4.05089 , acc is: 0.015625 , iter= 4811
current loss is: 3.996246 , acc is: 0.0625 , iter= 4812
current loss is: 4.0259905 , acc is: 0.03125 , iter= 4813
current loss is: 4.1215944 , acc is: 0.0 , iter= 4814
current loss is: 4.0884476 , acc is: 0.03125 , iter= 4815
current loss is: 4.10826 , acc is: 0.015625 , iter= 4816
current loss is: 12.08808 , acc is: 0.0625 , iter= 4817
current loss is: 4.0256557 , acc is: 0.046875 , iter= 4818
current loss is: 3.9757354 , acc is: 0.0625 , iter= 4819
current loss is: 4.0644073 , acc is: 0.078125 , iter= 4820
current loss is: 4.025444 , acc is: 0.0625 , iter= 4821
current loss is: 4.7980194 , acc is: 0.03125 , iter= 4822
current loss is: 4.141574 , acc is: 0.046875 , iter= 4823
current loss is: 4.1855254 , acc is: 0.03125 , iter= 4824
current loss is: 4.1199255 , acc is: 0.03125 , iter= 4825
current loss is: 3.999771 , acc is: 0.046875 , iter= 4826
current loss is: 4.0830717 , acc is: 0.015625 , iter= 4827
current loss is: 4.072171 , acc is: 0.046875 , iter= 4828
current loss is: 3.8875918 , acc is: 0.078125 , iter= 4829
current loss is: 4.1350884 , acc is: 0.015625 , iter= 4830
current loss is: 4.016956 , acc is: 0.0625 , iter= 4831
current loss is: 7.8620133 , acc is: 0.015625 , iter= 4832
current loss is: 4.202162 , acc is: 0.015625 , iter= 4833
current loss is: 3.9190288 , acc is: 0.078125 , iter= 4834
current loss is: 3.9287083 , acc is: 0.109375 , iter= 4835
current loss is: 4.0205626 , acc is: 0.0625 , iter= 4836
current loss is: 3.864946 , acc is: 0.078125 , iter= 4837
current loss is: 4.0313263 , acc is: 0.046875 , iter= 4838
current loss is: 4.107707 , acc is: 0.03125 , iter= 4839
current loss is: 4.180175 , acc is: 0.046875 , iter= 4840
current loss is: 4.0394177 , acc is: 0.015625 , iter= 4841
current loss is: 4.114601 , acc is: 0.078125 , iter= 4842
current loss is: 4.1050243 , acc is: 0.0625 , iter= 4843
current loss is: 4.157392 , acc is: 0.0 , iter= 4844
current loss is: 4.079705 , acc is: 0.03125 , iter= 4845
current loss is: 4.3515873 , acc is: 0.015625 , iter= 4846
current loss is: 4.1746125 , acc is: 0.046875 , iter= 4847
current loss is: 3.9715042 , acc is: 0.0625 , iter= 4848
current loss is: 4.150981 , acc is: 0.015625 , iter= 4849
current loss is: 4.03931 , acc is: 0.046875 , iter= 4850
current loss is: 4.0983386 , acc is: 0.015625 , iter= 4851
current loss is: 4.1906257 , acc is: 0.046875 , iter= 4852
current loss is: 4.0830064 , acc is: 0.03125 , iter= 4853
current loss is: 4.0612564 , acc is: 0.046875 , iter= 4854
current loss is: 4.1409073 , acc is: 0.015625 , iter= 4855
current loss is: 3.934825 , acc is: 0.078125 , iter= 4856
current loss is: 4.07909 , acc is: 0.0625 , iter= 4857
current loss is: 3.984239 , acc is: 0.0625 , iter= 4858
current loss is: 4.1379232 , acc is: 0.03125 , iter= 4859
current loss is: 4.101034 , acc is: 0.03125 , iter= 4860
current loss is: 4.0537624 , acc is: 0.046875 , iter= 4861
current loss is: 4.521252 , acc is: 0.03125 , iter= 4862
current loss is: 4.140476 , acc is: 0.015625 , iter= 4863
current loss is: 5.317152 , acc is: 0.078125 , iter= 4864
current loss is: 4.2951527 , acc is: 0.078125 , iter= 4865
current loss is: 4.1167774 , acc is: 0.046875 , iter= 4866
current loss is: 4.1151257 , acc is: 0.015625 , iter= 4867
current loss is: 3.9767795 , acc is: 0.125 , iter= 4868
current loss is: 4.080043 , acc is: 0.03125 , iter= 4869
current loss is: 4.1473713 , acc is: 0.03125 , iter= 4870
current loss is: 4.145546 , acc is: 0.03125 , iter= 4871
current loss is: 3.9705396 , acc is: 0.09375 , iter= 4872
current loss is: 3.927891 , acc is: 0.0625 , iter= 4873
current loss is: 4.086467 , acc is: 0.015625 , iter= 4874
current loss is: 4.0789886 , acc is: 0.03125 , iter= 4875
current loss is: 4.156193 , acc is: 0.03125 , iter= 4876
current loss is: 4.021391 , acc is: 0.046875 , iter= 4877
current loss is: 3.9987674 , acc is: 0.03125 , iter= 4878
current loss is: 4.1190166 , acc is: 0.046875 , iter= 4879
current loss is: 4.124048 , acc is: 0.015625 , iter= 4880
current loss is: 3.881717 , acc is: 0.09375 , iter= 4881
current loss is: 4.0645423 , acc is: 0.03125 , iter= 4882
current loss is: 4.1016273 , acc is: 0.046875 , iter= 4883
current loss is: 4.038538 , acc is: 0.03125 , iter= 4884
current loss is: 4.1553907 , acc is: 0.0 , iter= 4885
current loss is: 3.999515 , acc is: 0.046875 , iter= 4886
current loss is: 4.520938 , acc is: 0.046875 , iter= 4887
current loss is: 4.158051 , acc is: 0.03125 , iter= 4888
current loss is: 4.1145153 , acc is: 0.015625 , iter= 4889
current loss is: 4.1107535 , acc is: 0.0625 , iter= 4890
current loss is: 4.143976 , acc is: 0.015625 , iter= 4891
current loss is: 4.06266 , acc is: 0.03125 , iter= 4892
current loss is: 4.082423 , acc is: 0.015625 , iter= 4893
current loss is: 4.1087737 , acc is: 0.03125 , iter= 4894
current loss is: 4.142168 , acc is: 0.03125 , iter= 4895
current loss is: 4.087471 , acc is: 0.03125 , iter= 4896
current loss is: 4.000601 , acc is: 0.0625 , iter= 4897
current loss is: 4.0224466 , acc is: 0.046875 , iter= 4898
current loss is: 4.003636 , acc is: 0.046875 , iter= 4899
current loss is: 4.0001855 , acc is: 0.0625 , iter= 4900
current loss is: 4.183782 , acc is: 0.015625 , iter= 4901
current loss is: 4.065431 , acc is: 0.015625 , iter= 4902
current loss is: 4.0786686 , acc is: 0.03125 , iter= 4903
current loss is: 4.21842 , acc is: 0.0 , iter= 4904
current loss is: 4.121085 , acc is: 0.015625 , iter= 4905
current loss is: 4.1120234 , acc is: 0.0625 , iter= 4906
current loss is: 4.0255747 , acc is: 0.046875 , iter= 4907
current loss is: 4.2318063 , acc is: 0.09375 , iter= 4908
current loss is: 4.0420413 , acc is: 0.015625 , iter= 4909
current loss is: 4.0826283 , acc is: 0.03125 , iter= 4910
current loss is: 3.916061 , acc is: 0.046875 , iter= 4911
current loss is: 4.04671 , acc is: 0.046875 , iter= 4912
current loss is: 4.100724 , acc is: 0.015625 , iter= 4913
current loss is: 4.086931 , acc is: 0.046875 , iter= 4914
current loss is: 4.256115 , acc is: 0.03125 , iter= 4915
current loss is: 13.955806 , acc is: 0.015625 , iter= 4916
current loss is: 3.890719 , acc is: 0.109375 , iter= 4917
current loss is: 3.8806338 , acc is: 0.09375 , iter= 4918
current loss is: 14.782574 , acc is: 0.046875 , iter= 4919
current loss is: 4.1450644 , acc is: 0.015625 , iter= 4920
current loss is: 3.9747949 , acc is: 0.125 , iter= 4921
current loss is: 4.1029367 , acc is: 0.046875 , iter= 4922
current loss is: 4.0635214 , acc is: 0.0625 , iter= 4923
current loss is: 4.0785084 , acc is: 0.015625 , iter= 4924
current loss is: 4.0299387 , acc is: 0.046875 , iter= 4925
current loss is: 4.0283294 , acc is: 0.0625 , iter= 4926
current loss is: 3.9803386 , acc is: 0.03125 , iter= 4927
current loss is: 4.125844 , acc is: 0.03125 , iter= 4928
current loss is: 4.1211567 , acc is: 0.03125 , iter= 4929
current loss is: 4.051436 , acc is: 0.03125 , iter= 4930
current loss is: 4.202121 , acc is: 0.03125 , iter= 4931
current loss is: 4.0411305 , acc is: 0.046875 , iter= 4932
current loss is: 4.054189 , acc is: 0.015625 , iter= 4933
current loss is: 4.1083775 , acc is: 0.03125 , iter= 4934
current loss is: 4.17247 , acc is: 0.03125 , iter= 4935
current loss is: 4.1366124 , acc is: 0.015625 , iter= 4936
current loss is: 4.0153785 , acc is: 0.0625 , iter= 4937
current loss is: 4.0131164 , acc is: 0.046875 , iter= 4938
current loss is: 4.135105 , acc is: 0.015625 , iter= 4939
current loss is: 4.090675 , acc is: 0.015625 , iter= 4940
current loss is: 5.348323 , acc is: 0.03125 , iter= 4941
current loss is: 3.9868217 , acc is: 0.03125 , iter= 4942
current loss is: 4.054309 , acc is: 0.046875 , iter= 4943
current loss is: 4.151182 , acc is: 0.015625 , iter= 4944
current loss is: 4.042857 , acc is: 0.046875 , iter= 4945
current loss is: 4.0142193 , acc is: 0.046875 , iter= 4946
current loss is: 4.1331415 , acc is: 0.015625 , iter= 4947
current loss is: 4.135769 , acc is: 0.03125 , iter= 4948
current loss is: 4.094529 , acc is: 0.046875 , iter= 4949
current loss is: 3.9628527 , acc is: 0.09375 , iter= 4950
current loss is: 4.1453524 , acc is: 0.0 , iter= 4951
current loss is: 4.0572395 , acc is: 0.078125 , iter= 4952
current loss is: 4.1754217 , acc is: 0.0 , iter= 4953
current loss is: 4.054469 , acc is: 0.0625 , iter= 4954
current loss is: 4.130977 , acc is: 0.046875 , iter= 4955
current loss is: 4.067133 , acc is: 0.046875 , iter= 4956
current loss is: 4.114511 , acc is: 0.0 , iter= 4957
current loss is: 4.025704 , acc is: 0.078125 , iter= 4958
current loss is: 4.033989 , acc is: 0.03125 , iter= 4959
current loss is: 4.231988 , acc is: 0.015625 , iter= 4960
current loss is: 4.205622 , acc is: 0.0 , iter= 4961
current loss is: 4.037222 , acc is: 0.03125 , iter= 4962
current loss is: 4.0806417 , acc is: 0.03125 , iter= 4963
current loss is: 4.1126547 , acc is: 0.046875 , iter= 4964
current loss is: 4.0442944 , acc is: 0.046875 , iter= 4965
current loss is: 4.0300665 , acc is: 0.0625 , iter= 4966
current loss is: 4.1405373 , acc is: 0.03125 , iter= 4967
current loss is: 4.208858 , acc is: 0.015625 , iter= 4968
current loss is: 4.065934 , acc is: 0.03125 , iter= 4969
current loss is: 4.051653 , acc is: 0.03125 , iter= 4970
current loss is: 4.073346 , acc is: 0.046875 , iter= 4971
current loss is: 3.9906018 , acc is: 0.09375 , iter= 4972
current loss is: 4.0903535 , acc is: 0.015625 , iter= 4973
current loss is: 4.1349497 , acc is: 0.03125 , iter= 4974
current loss is: 4.051996 , acc is: 0.03125 , iter= 4975
current loss is: 3.9561708 , acc is: 0.09375 , iter= 4976
current loss is: 4.0874987 , acc is: 0.03125 , iter= 4977
current loss is: 4.008159 , acc is: 0.0625 , iter= 4978
current loss is: 3.9654837 , acc is: 0.046875 , iter= 4979
current loss is: 4.043556 , acc is: 0.0625 , iter= 4980
current loss is: 3.99541 , acc is: 0.0625 , iter= 4981
current loss is: 4.0517416 , acc is: 0.078125 , iter= 4982
current loss is: 4.177535 , acc is: 0.03125 , iter= 4983
current loss is: 4.0896826 , acc is: 0.03125 , iter= 4984
current loss is: 4.054995 , acc is: 0.046875 , iter= 4985
current loss is: 4.0002356 , acc is: 0.0625 , iter= 4986
current loss is: 4.072943 , acc is: 0.046875 , iter= 4987
current loss is: 4.0713186 , acc is: 0.046875 , iter= 4988
current loss is: 3.9988525 , acc is: 0.078125 , iter= 4989
current loss is: 4.1157885 , acc is: 0.03125 , iter= 4990
current loss is: 4.1187086 , acc is: 0.0625 , iter= 4991
current loss is: 4.084653 , acc is: 0.046875 , iter= 4992
current loss is: 4.0993185 , acc is: 0.03125 , iter= 4993
current loss is: 4.135271 , acc is: 0.0 , iter= 4994
current loss is: 4.119062 , acc is: 0.015625 , iter= 4995
current loss is: 4.0908213 , acc is: 0.046875 , iter= 4996
current loss is: 4.002835 , acc is: 0.03125 , iter= 4997
current loss is: 4.105507 , acc is: 0.03125 , iter= 4998
current loss is: 4.048863 , acc is: 0.046875 , iter= 4999
current loss is: 3.976029 , acc is: 0.078125 , iter= 5000
tot_acc= 19.0 tot_input= 768
current accuracy is: 0.024739583333333332
current loss is: 3.9499407 , acc is: 0.109375 , iter= 5001
current loss is: 4.0870504 , acc is: 0.03125 , iter= 5002
current loss is: 3.8635037 , acc is: 0.078125 , iter= 5003
current loss is: 3.9324884 , acc is: 0.046875 , iter= 5004
current loss is: 4.0141125 , acc is: 0.0625 , iter= 5005
current loss is: 4.096452 , acc is: 0.046875 , iter= 5006
current loss is: 4.125088 , acc is: 0.0625 , iter= 5007
current loss is: 4.056653 , acc is: 0.0625 , iter= 5008
current loss is: 4.0786242 , acc is: 0.03125 , iter= 5009
current loss is: 4.128788 , acc is: 0.015625 , iter= 5010
current loss is: 4.0618286 , acc is: 0.046875 , iter= 5011
current loss is: 4.039026 , acc is: 0.0625 , iter= 5012
current loss is: 4.1260843 , acc is: 0.0 , iter= 5013
current loss is: 3.9646273 , acc is: 0.0625 , iter= 5014
current loss is: 4.11265 , acc is: 0.046875 , iter= 5015
current loss is: 4.154361 , acc is: 0.015625 , iter= 5016
current loss is: 3.954039 , acc is: 0.046875 , iter= 5017
current loss is: 4.1287184 , acc is: 0.046875 , iter= 5018
current loss is: 4.0434365 , acc is: 0.03125 , iter= 5019
current loss is: 4.1000175 , acc is: 0.015625 , iter= 5020
current loss is: 4.274327 , acc is: 0.03125 , iter= 5021
current loss is: 4.11705 , acc is: 0.015625 , iter= 5022
current loss is: 4.041548 , acc is: 0.015625 , iter= 5023
current loss is: 4.1247654 , acc is: 0.0 , iter= 5024
current loss is: 4.1961284 , acc is: 0.0 , iter= 5025
current loss is: 4.09686 , acc is: 0.03125 , iter= 5026
current loss is: 4.1242976 , acc is: 0.015625 , iter= 5027
current loss is: 4.126299 , acc is: 0.046875 , iter= 5028
current loss is: 4.060335 , acc is: 0.046875 , iter= 5029
current loss is: 4.15326 , acc is: 0.015625 , iter= 5030
current loss is: 4.079725 , acc is: 0.015625 , iter= 5031
current loss is: 4.084119 , acc is: 0.046875 , iter= 5032
current loss is: 4.1527467 , acc is: 0.0 , iter= 5033
current loss is: 3.9569964 , acc is: 0.0625 , iter= 5034
current loss is: 4.0820966 , acc is: 0.046875 , iter= 5035
current loss is: 4.0846186 , acc is: 0.03125 , iter= 5036
current loss is: 4.094659 , acc is: 0.046875 , iter= 5037
current loss is: 4.0184383 , acc is: 0.078125 , iter= 5038
current loss is: 4.2185135 , acc is: 0.0 , iter= 5039
current loss is: 4.0929847 , acc is: 0.046875 , iter= 5040
current loss is: 3.9690824 , acc is: 0.078125 , iter= 5041
current loss is: 4.0433373 , acc is: 0.03125 , iter= 5042
current loss is: 3.9082277 , acc is: 0.0625 , iter= 5043
current loss is: 4.0950956 , acc is: 0.03125 , iter= 5044
current loss is: 4.190671 , acc is: 0.0 , iter= 5045
current loss is: 4.047126 , acc is: 0.046875 , iter= 5046
current loss is: 4.1560802 , acc is: 0.015625 , iter= 5047
current loss is: 4.0897703 , acc is: 0.046875 , iter= 5048
current loss is: 4.01759 , acc is: 0.046875 , iter= 5049
current loss is: 3.9295042 , acc is: 0.078125 , iter= 5050
current loss is: 3.8592026 , acc is: 0.09375 , iter= 5051
current loss is: 4.1330776 , acc is: 0.0 , iter= 5052
current loss is: 3.962172 , acc is: 0.0625 , iter= 5053
current loss is: 4.1547713 , acc is: 0.0 , iter= 5054
current loss is: 4.1008377 , acc is: 0.046875 , iter= 5055
current loss is: 4.088739 , acc is: 0.015625 , iter= 5056
current loss is: 4.042078 , acc is: 0.0625 , iter= 5057
current loss is: 4.0877523 , acc is: 0.0625 , iter= 5058
current loss is: 4.0706215 , acc is: 0.03125 , iter= 5059
current loss is: 3.9578393 , acc is: 0.078125 , iter= 5060
current loss is: 4.04609 , acc is: 0.03125 , iter= 5061
current loss is: 4.0051045 , acc is: 0.0625 , iter= 5062
current loss is: 4.0329595 , acc is: 0.078125 , iter= 5063
current loss is: 4.051237 , acc is: 0.03125 , iter= 5064
current loss is: 4.0830693 , acc is: 0.03125 , iter= 5065
current loss is: 4.183032 , acc is: 0.0 , iter= 5066
current loss is: 4.1290426 , acc is: 0.03125 , iter= 5067
current loss is: 4.0741625 , acc is: 0.03125 , iter= 5068
current loss is: 4.137873 , acc is: 0.03125 , iter= 5069
current loss is: 4.104373 , acc is: 0.03125 , iter= 5070
current loss is: 4.064821 , acc is: 0.03125 , iter= 5071
current loss is: 3.9574294 , acc is: 0.0625 , iter= 5072
current loss is: 4.0049067 , acc is: 0.0625 , iter= 5073
current loss is: 4.149511 , acc is: 0.03125 , iter= 5074
current loss is: 4.06163 , acc is: 0.015625 , iter= 5075
current loss is: 4.1493196 , acc is: 0.015625 , iter= 5076
current loss is: 4.1720505 , acc is: 0.0 , iter= 5077
current loss is: 4.1016703 , acc is: 0.03125 , iter= 5078
current loss is: 4.016959 , acc is: 0.03125 , iter= 5079
current loss is: 4.1191764 , acc is: 0.015625 , iter= 5080
current loss is: 4.1120505 , acc is: 0.0 , iter= 5081
current loss is: 4.010973 , acc is: 0.03125 , iter= 5082
current loss is: 3.9991512 , acc is: 0.078125 , iter= 5083
current loss is: 4.05295 , acc is: 0.015625 , iter= 5084
current loss is: 4.1036377 , acc is: 0.03125 , iter= 5085
current loss is: 4.115615 , acc is: 0.015625 , iter= 5086
current loss is: 4.0723124 , acc is: 0.046875 , iter= 5087
current loss is: 4.1262445 , acc is: 0.03125 , iter= 5088
current loss is: 4.0056667 , acc is: 0.0625 , iter= 5089
current loss is: 4.152507 , acc is: 0.015625 , iter= 5090
current loss is: 4.1484356 , acc is: 0.046875 , iter= 5091
current loss is: 3.892068 , acc is: 0.0625 , iter= 5092
current loss is: 4.0725174 , acc is: 0.03125 , iter= 5093
current loss is: 4.085888 , acc is: 0.046875 , iter= 5094
current loss is: 4.1012278 , acc is: 0.046875 , iter= 5095
current loss is: 4.1554685 , acc is: 0.03125 , iter= 5096
current loss is: 4.09095 , acc is: 0.078125 , iter= 5097
current loss is: 4.1467223 , acc is: 0.046875 , iter= 5098
current loss is: 4.0231385 , acc is: 0.0625 , iter= 5099
current loss is: 4.110649 , acc is: 0.03125 , iter= 5100
current loss is: 4.0393043 , acc is: 0.03125 , iter= 5101
current loss is: 3.8788943 , acc is: 0.0625 , iter= 5102
current loss is: 4.093566 , acc is: 0.015625 , iter= 5103
current loss is: 4.144044 , acc is: 0.015625 , iter= 5104
current loss is: 4.103554 , acc is: 0.046875 , iter= 5105
current loss is: 3.9792101 , acc is: 0.03125 , iter= 5106
current loss is: 4.125186 , acc is: 0.03125 , iter= 5107
current loss is: 4.038687 , acc is: 0.03125 , iter= 5108
current loss is: 4.0387416 , acc is: 0.03125 , iter= 5109
current loss is: 4.138426 , acc is: 0.015625 , iter= 5110
current loss is: 4.181222 , acc is: 0.03125 , iter= 5111
current loss is: 4.138183 , acc is: 0.03125 , iter= 5112
current loss is: 4.091306 , acc is: 0.0 , iter= 5113
current loss is: 4.0212393 , acc is: 0.0625 , iter= 5114
current loss is: 3.9986863 , acc is: 0.03125 , iter= 5115
current loss is: 4.1728053 , acc is: 0.0625 , iter= 5116
current loss is: 4.1786776 , acc is: 0.0 , iter= 5117
current loss is: 3.9538665 , acc is: 0.078125 , iter= 5118
current loss is: 3.9870012 , acc is: 0.03125 , iter= 5119
current loss is: 4.0554686 , acc is: 0.046875 , iter= 5120
current loss is: 4.0903387 , acc is: 0.03125 , iter= 5121
current loss is: 4.128045 , acc is: 0.015625 , iter= 5122
current loss is: 4.121593 , acc is: 0.03125 , iter= 5123
current loss is: 4.0995703 , acc is: 0.046875 , iter= 5124
current loss is: 4.056959 , acc is: 0.015625 , iter= 5125
current loss is: 3.9689126 , acc is: 0.03125 , iter= 5126
current loss is: 4.0792723 , acc is: 0.046875 , iter= 5127
current loss is: 4.1054716 , acc is: 0.015625 , iter= 5128
current loss is: 4.1966896 , acc is: 0.015625 , iter= 5129
current loss is: 4.0214686 , acc is: 0.0625 , iter= 5130
current loss is: 4.059232 , acc is: 0.03125 , iter= 5131
current loss is: 4.001095 , acc is: 0.03125 , iter= 5132
current loss is: 4.177327 , acc is: 0.0 , iter= 5133
current loss is: 4.0626945 , acc is: 0.078125 , iter= 5134
current loss is: 3.910957 , acc is: 0.09375 , iter= 5135
current loss is: 4.007827 , acc is: 0.09375 , iter= 5136
current loss is: 4.06909 , acc is: 0.046875 , iter= 5137
current loss is: 3.970282 , acc is: 0.0625 , iter= 5138
current loss is: 4.1120977 , acc is: 0.046875 , iter= 5139
current loss is: 3.9255474 , acc is: 0.0625 , iter= 5140
current loss is: 4.2724986 , acc is: 0.015625 , iter= 5141
current loss is: 4.094077 , acc is: 0.03125 , iter= 5142
current loss is: 4.111086 , acc is: 0.015625 , iter= 5143
current loss is: 4.057202 , acc is: 0.078125 , iter= 5144
current loss is: 4.1659856 , acc is: 0.015625 , iter= 5145
current loss is: 4.119409 , acc is: 0.0625 , iter= 5146
current loss is: 4.0498013 , acc is: 0.046875 , iter= 5147
current loss is: 3.9827347 , acc is: 0.0625 , iter= 5148
current loss is: 4.007763 , acc is: 0.046875 , iter= 5149
current loss is: 4.0592093 , acc is: 0.078125 , iter= 5150
current loss is: 4.1866894 , acc is: 0.0 , iter= 5151
current loss is: 4.0202823 , acc is: 0.078125 , iter= 5152
current loss is: 4.1783657 , acc is: 0.015625 , iter= 5153
current loss is: 4.098939 , acc is: 0.03125 , iter= 5154
current loss is: 4.0403996 , acc is: 0.046875 , iter= 5155
current loss is: 4.087366 , acc is: 0.0625 , iter= 5156
current loss is: 4.0846033 , acc is: 0.046875 , iter= 5157
current loss is: 4.1698246 , acc is: 0.015625 , iter= 5158
current loss is: 4.1605115 , acc is: 0.0 , iter= 5159
current loss is: 4.1521487 , acc is: 0.015625 , iter= 5160
current loss is: 4.142624 , acc is: 0.03125 , iter= 5161
current loss is: 4.028455 , acc is: 0.046875 , iter= 5162
current loss is: 4.060624 , acc is: 0.03125 , iter= 5163
current loss is: 4.161383 , acc is: 0.046875 , iter= 5164
current loss is: 3.925991 , acc is: 0.0625 , iter= 5165
current loss is: 3.9436285 , acc is: 0.078125 , iter= 5166
current loss is: 4.127824 , acc is: 0.03125 , iter= 5167
current loss is: 4.1131077 , acc is: 0.046875 , iter= 5168
current loss is: 3.8304787 , acc is: 0.09375 , iter= 5169
current loss is: 4.125737 , acc is: 0.0 , iter= 5170
current loss is: 4.1009226 , acc is: 0.03125 , iter= 5171
current loss is: 4.0263395 , acc is: 0.0625 , iter= 5172
current loss is: 4.1436605 , acc is: 0.0 , iter= 5173
current loss is: 4.060989 , acc is: 0.0625 , iter= 5174
current loss is: 4.0194263 , acc is: 0.0625 , iter= 5175
current loss is: 4.082829 , acc is: 0.015625 , iter= 5176
current loss is: 4.017558 , acc is: 0.0625 , iter= 5177
current loss is: 3.9885964 , acc is: 0.078125 , iter= 5178
current loss is: 4.095743 , acc is: 0.0625 , iter= 5179
current loss is: 3.9691112 , acc is: 0.0625 , iter= 5180
current loss is: 4.0816793 , acc is: 0.015625 , iter= 5181
current loss is: 4.0709395 , acc is: 0.046875 , iter= 5182
current loss is: 4.149764 , acc is: 0.015625 , iter= 5183
current loss is: 4.0978994 , acc is: 0.015625 , iter= 5184
current loss is: 3.993661 , acc is: 0.046875 , iter= 5185
current loss is: 4.1217365 , acc is: 0.03125 , iter= 5186
current loss is: 3.775056 , acc is: 0.140625 , iter= 5187
current loss is: 4.1113434 , acc is: 0.03125 , iter= 5188
current loss is: 4.1270275 , acc is: 0.015625 , iter= 5189
current loss is: 4.0993366 , acc is: 0.0625 , iter= 5190
current loss is: 4.047408 , acc is: 0.03125 , iter= 5191
current loss is: 4.0852942 , acc is: 0.0625 , iter= 5192
current loss is: 4.1891837 , acc is: 0.015625 , iter= 5193
current loss is: 3.9046638 , acc is: 0.078125 , iter= 5194
current loss is: 3.972642 , acc is: 0.0625 , iter= 5195
current loss is: 4.1672096 , acc is: 0.015625 , iter= 5196
current loss is: 4.046652 , acc is: 0.046875 , iter= 5197
current loss is: 4.1533003 , acc is: 0.046875 , iter= 5198
current loss is: 4.0860205 , acc is: 0.015625 , iter= 5199
current loss is: 3.948944 , acc is: 0.0625 , iter= 5200
current loss is: 3.9737048 , acc is: 0.03125 , iter= 5201
current loss is: 4.0035276 , acc is: 0.03125 , iter= 5202
current loss is: 4.0927057 , acc is: 0.015625 , iter= 5203
current loss is: 3.9727068 , acc is: 0.0625 , iter= 5204
current loss is: 4.0303307 , acc is: 0.0625 , iter= 5205
current loss is: 4.094453 , acc is: 0.015625 , iter= 5206
current loss is: 4.064569 , acc is: 0.078125 , iter= 5207
current loss is: 4.204999 , acc is: 0.0 , iter= 5208
current loss is: 4.0865383 , acc is: 0.046875 , iter= 5209
current loss is: 4.0894837 , acc is: 0.046875 , iter= 5210
current loss is: 3.9142416 , acc is: 0.0625 , iter= 5211
current loss is: 4.186563 , acc is: 0.078125 , iter= 5212
current loss is: 4.0697885 , acc is: 0.015625 , iter= 5213
current loss is: 4.1694922 , acc is: 0.0 , iter= 5214
current loss is: 4.0440645 , acc is: 0.046875 , iter= 5215
current loss is: 3.972723 , acc is: 0.046875 , iter= 5216
current loss is: 4.090963 , acc is: 0.078125 , iter= 5217
current loss is: 3.9815116 , acc is: 0.109375 , iter= 5218
current loss is: 3.919883 , acc is: 0.046875 , iter= 5219
current loss is: 4.2469397 , acc is: 0.0625 , iter= 5220
current loss is: 4.0276003 , acc is: 0.0625 , iter= 5221
current loss is: 4.09481 , acc is: 0.03125 , iter= 5222
current loss is: 4.0923786 , acc is: 0.015625 , iter= 5223
current loss is: 4.0240936 , acc is: 0.078125 , iter= 5224
current loss is: 4.202916 , acc is: 0.03125 , iter= 5225
current loss is: 4.0788593 , acc is: 0.03125 , iter= 5226
current loss is: 3.9781787 , acc is: 0.046875 , iter= 5227
current loss is: 4.147018 , acc is: 0.046875 , iter= 5228
current loss is: 4.1439047 , acc is: 0.015625 , iter= 5229
current loss is: 4.1290975 , acc is: 0.0 , iter= 5230
current loss is: 4.111805 , acc is: 0.03125 , iter= 5231
current loss is: 4.1798925 , acc is: 0.0 , iter= 5232
current loss is: 3.9076338 , acc is: 0.046875 , iter= 5233
current loss is: 4.110989 , acc is: 0.015625 , iter= 5234
current loss is: 4.184433 , acc is: 0.0 , iter= 5235
current loss is: 4.08317 , acc is: 0.03125 , iter= 5236
current loss is: 4.164208 , acc is: 0.03125 , iter= 5237
current loss is: 4.1585407 , acc is: 0.0 , iter= 5238
current loss is: 4.1148868 , acc is: 0.046875 , iter= 5239
current loss is: 4.166473 , acc is: 0.03125 , iter= 5240
current loss is: 4.031949 , acc is: 0.046875 , iter= 5241
current loss is: 3.9678476 , acc is: 0.09375 , iter= 5242
current loss is: 4.1599555 , acc is: 0.015625 , iter= 5243
current loss is: 3.9776511 , acc is: 0.078125 , iter= 5244
current loss is: 4.1404552 , acc is: 0.046875 , iter= 5245
current loss is: 4.0904856 , acc is: 0.046875 , iter= 5246
current loss is: 4.0285277 , acc is: 0.046875 , iter= 5247
current loss is: 3.9869318 , acc is: 0.03125 , iter= 5248
current loss is: 4.068243 , acc is: 0.03125 , iter= 5249
current loss is: 4.082671 , acc is: 0.078125 , iter= 5250
current loss is: 4.181593 , acc is: 0.015625 , iter= 5251
current loss is: 4.106311 , acc is: 0.046875 , iter= 5252
current loss is: 4.12156 , acc is: 0.046875 , iter= 5253
current loss is: 4.0342245 , acc is: 0.046875 , iter= 5254
current loss is: 3.9004877 , acc is: 0.078125 , iter= 5255
current loss is: 4.156186 , acc is: 0.03125 , iter= 5256
current loss is: 4.0582194 , acc is: 0.046875 , iter= 5257
current loss is: 4.179593 , acc is: 0.015625 , iter= 5258
current loss is: 4.1025057 , acc is: 0.03125 , iter= 5259
current loss is: 4.1077566 , acc is: 0.03125 , iter= 5260
current loss is: 4.072719 , acc is: 0.015625 , iter= 5261
current loss is: 4.0404925 , acc is: 0.03125 , iter= 5262
current loss is: 4.01747 , acc is: 0.078125 , iter= 5263
current loss is: 4.0481453 , acc is: 0.0625 , iter= 5264
current loss is: 4.127793 , acc is: 0.03125 , iter= 5265
current loss is: 4.1063786 , acc is: 0.046875 , iter= 5266
current loss is: 4.0894012 , acc is: 0.03125 , iter= 5267
current loss is: 4.0236053 , acc is: 0.015625 , iter= 5268
current loss is: 4.038724 , acc is: 0.03125 , iter= 5269
current loss is: 4.0767345 , acc is: 0.046875 , iter= 5270
current loss is: 3.9321804 , acc is: 0.0625 , iter= 5271
current loss is: 4.0750775 , acc is: 0.03125 , iter= 5272
current loss is: 4.1248374 , acc is: 0.03125 , iter= 5273
current loss is: 3.962652 , acc is: 0.0625 , iter= 5274
current loss is: 4.040428 , acc is: 0.078125 , iter= 5275
current loss is: 3.9880133 , acc is: 0.0625 , iter= 5276
current loss is: 4.1859255 , acc is: 0.046875 , iter= 5277
current loss is: 4.179772 , acc is: 0.03125 , iter= 5278
current loss is: 4.0978875 , acc is: 0.015625 , iter= 5279
current loss is: 4.070076 , acc is: 0.015625 , iter= 5280
current loss is: 4.0430093 , acc is: 0.03125 , iter= 5281
current loss is: 4.1530066 , acc is: 0.03125 , iter= 5282
current loss is: 4.142901 , acc is: 0.0 , iter= 5283
current loss is: 3.9102716 , acc is: 0.046875 , iter= 5284
current loss is: 4.031663 , acc is: 0.046875 , iter= 5285
current loss is: 4.01836 , acc is: 0.0625 , iter= 5286
current loss is: 4.1721435 , acc is: 0.03125 , iter= 5287
current loss is: 4.052984 , acc is: 0.046875 , iter= 5288
current loss is: 4.0812106 , acc is: 0.0625 , iter= 5289
current loss is: 4.1056604 , acc is: 0.03125 , iter= 5290
current loss is: 3.9545023 , acc is: 0.0625 , iter= 5291
current loss is: 3.8896277 , acc is: 0.0625 , iter= 5292
current loss is: 4.2276263 , acc is: 0.015625 , iter= 5293
current loss is: 4.0098457 , acc is: 0.046875 , iter= 5294
current loss is: 4.0327587 , acc is: 0.03125 , iter= 5295
current loss is: 4.545129 , acc is: 0.015625 , iter= 5296
current loss is: 4.0755296 , acc is: 0.015625 , iter= 5297
current loss is: 4.2055144 , acc is: 0.0 , iter= 5298
current loss is: 4.16117 , acc is: 0.015625 , iter= 5299
current loss is: 4.121877 , acc is: 0.03125 , iter= 5300
current loss is: 3.9071207 , acc is: 0.09375 , iter= 5301
current loss is: 4.4082174 , acc is: 0.015625 , iter= 5302
current loss is: 3.9789627 , acc is: 0.046875 , iter= 5303
current loss is: 3.9484463 , acc is: 0.0625 , iter= 5304
current loss is: 4.158893 , acc is: 0.015625 , iter= 5305
current loss is: 5.172452 , acc is: 0.03125 , iter= 5306
current loss is: 4.112666 , acc is: 0.015625 , iter= 5307
current loss is: 3.9301245 , acc is: 0.109375 , iter= 5308
current loss is: 4.146917 , acc is: 0.015625 , iter= 5309
current loss is: 4.0669136 , acc is: 0.078125 , iter= 5310
current loss is: 4.4196825 , acc is: 0.015625 , iter= 5311
current loss is: 4.1072507 , acc is: 0.015625 , iter= 5312
current loss is: 4.0698323 , acc is: 0.03125 , iter= 5313
current loss is: 4.1005964 , acc is: 0.0625 , iter= 5314
current loss is: 3.98973 , acc is: 0.078125 , iter= 5315
current loss is: 3.9539256 , acc is: 0.046875 , iter= 5316
current loss is: 4.068159 , acc is: 0.03125 , iter= 5317
current loss is: 4.0063467 , acc is: 0.0625 , iter= 5318
current loss is: 4.115694 , acc is: 0.015625 , iter= 5319
current loss is: 4.0235734 , acc is: 0.078125 , iter= 5320
current loss is: 4.067177 , acc is: 0.046875 , iter= 5321
current loss is: 4.1307564 , acc is: 0.0 , iter= 5322
current loss is: 4.1402183 , acc is: 0.015625 , iter= 5323
current loss is: 4.044681 , acc is: 0.03125 , iter= 5324
current loss is: 4.104824 , acc is: 0.03125 , iter= 5325
current loss is: 4.1587067 , acc is: 0.015625 , iter= 5326
current loss is: 4.1262484 , acc is: 0.0 , iter= 5327
current loss is: 4.0902796 , acc is: 0.03125 , iter= 5328
current loss is: 4.133666 , acc is: 0.0 , iter= 5329
current loss is: 4.1169972 , acc is: 0.046875 , iter= 5330
current loss is: 4.0622506 , acc is: 0.046875 , iter= 5331
current loss is: 3.9816966 , acc is: 0.0625 , iter= 5332
current loss is: 4.068011 , acc is: 0.0625 , iter= 5333
current loss is: 4.118915 , acc is: 0.046875 , iter= 5334
current loss is: 4.055123 , acc is: 0.046875 , iter= 5335
current loss is: 3.9296024 , acc is: 0.046875 , iter= 5336
current loss is: 4.150535 , acc is: 0.015625 , iter= 5337
current loss is: 4.130906 , acc is: 0.046875 , iter= 5338
current loss is: 4.0531654 , acc is: 0.078125 , iter= 5339
current loss is: 3.9797494 , acc is: 0.0625 , iter= 5340
current loss is: 10.260206 , acc is: 0.03125 , iter= 5341
current loss is: 4.1111517 , acc is: 0.03125 , iter= 5342
current loss is: 4.0882998 , acc is: 0.03125 , iter= 5343
current loss is: 4.1826696 , acc is: 0.015625 , iter= 5344
current loss is: 4.147555 , acc is: 0.0 , iter= 5345
current loss is: 3.976511 , acc is: 0.0625 , iter= 5346
current loss is: 4.111375 , acc is: 0.03125 , iter= 5347
current loss is: 4.0047064 , acc is: 0.03125 , iter= 5348
current loss is: 4.1283636 , acc is: 0.015625 , iter= 5349
current loss is: 4.0176463 , acc is: 0.046875 , iter= 5350
current loss is: 3.844036 , acc is: 0.125 , iter= 5351
current loss is: 3.9614577 , acc is: 0.046875 , iter= 5352
current loss is: 4.0469465 , acc is: 0.046875 , iter= 5353
current loss is: 4.0143824 , acc is: 0.03125 , iter= 5354
current loss is: 4.0071726 , acc is: 0.0625 , iter= 5355
current loss is: 4.1168933 , acc is: 0.015625 , iter= 5356
current loss is: 4.010194 , acc is: 0.046875 , iter= 5357
current loss is: 4.0845966 , acc is: 0.046875 , iter= 5358
current loss is: 4.0391912 , acc is: 0.03125 , iter= 5359
current loss is: 4.126979 , acc is: 0.03125 , iter= 5360
current loss is: 4.08298 , acc is: 0.078125 , iter= 5361
current loss is: 4.049235 , acc is: 0.03125 , iter= 5362
current loss is: 4.0069685 , acc is: 0.046875 , iter= 5363
current loss is: 4.130866 , acc is: 0.015625 , iter= 5364
current loss is: 4.1717024 , acc is: 0.046875 , iter= 5365
current loss is: 4.1648483 , acc is: 0.0 , iter= 5366
current loss is: 4.1769443 , acc is: 0.0 , iter= 5367
current loss is: 4.051968 , acc is: 0.03125 , iter= 5368
current loss is: 4.039386 , acc is: 0.015625 , iter= 5369
current loss is: 4.033072 , acc is: 0.046875 , iter= 5370
current loss is: 4.0542207 , acc is: 0.015625 , iter= 5371
current loss is: 4.140901 , acc is: 0.015625 , iter= 5372
current loss is: 4.1237917 , acc is: 0.015625 , iter= 5373
current loss is: 4.033637 , acc is: 0.046875 , iter= 5374
current loss is: 4.0119762 , acc is: 0.0625 , iter= 5375
current loss is: 4.080415 , acc is: 0.015625 , iter= 5376
current loss is: 4.1059403 , acc is: 0.03125 , iter= 5377
current loss is: 3.9113746 , acc is: 0.078125 , iter= 5378
current loss is: 4.1586027 , acc is: 0.015625 , iter= 5379
current loss is: 4.143756 , acc is: 0.015625 , iter= 5380
current loss is: 4.0892982 , acc is: 0.015625 , iter= 5381
current loss is: 4.1374397 , acc is: 0.03125 , iter= 5382
current loss is: 4.133884 , acc is: 0.03125 , iter= 5383
current loss is: 4.025217 , acc is: 0.046875 , iter= 5384
current loss is: 4.1623116 , acc is: 0.015625 , iter= 5385
current loss is: 3.9993842 , acc is: 0.03125 , iter= 5386
current loss is: 4.08769 , acc is: 0.03125 , iter= 5387
current loss is: 4.1109643 , acc is: 0.03125 , iter= 5388
current loss is: 4.135625 , acc is: 0.03125 , iter= 5389
current loss is: 4.133293 , acc is: 0.0 , iter= 5390
current loss is: 4.1198378 , acc is: 0.03125 , iter= 5391
current loss is: 4.038786 , acc is: 0.0625 , iter= 5392
current loss is: 4.0934696 , acc is: 0.015625 , iter= 5393
current loss is: 4.176659 , acc is: 0.0 , iter= 5394
current loss is: 4.020984 , acc is: 0.09375 , iter= 5395
current loss is: 3.959313 , acc is: 0.046875 , iter= 5396
current loss is: 4.132432 , acc is: 0.03125 , iter= 5397
current loss is: 4.1887646 , acc is: 0.03125 , iter= 5398
current loss is: 3.98636 , acc is: 0.0625 , iter= 5399
current loss is: 3.9849157 , acc is: 0.078125 , iter= 5400
current loss is: 3.9534283 , acc is: 0.078125 , iter= 5401
current loss is: 4.1557446 , acc is: 0.015625 , iter= 5402
current loss is: 4.133223 , acc is: 0.046875 , iter= 5403
current loss is: 4.062874 , acc is: 0.03125 , iter= 5404
current loss is: 4.12207 , acc is: 0.015625 , iter= 5405
current loss is: 4.0197716 , acc is: 0.03125 , iter= 5406
current loss is: 4.14915 , acc is: 0.015625 , iter= 5407
current loss is: 4.0317483 , acc is: 0.03125 , iter= 5408
current loss is: 4.044424 , acc is: 0.0625 , iter= 5409
current loss is: 3.9726737 , acc is: 0.03125 , iter= 5410
current loss is: 4.155278 , acc is: 0.03125 , iter= 5411
current loss is: 4.031038 , acc is: 0.03125 , iter= 5412
current loss is: 4.133006 , acc is: 0.015625 , iter= 5413
current loss is: 4.1692667 , acc is: 0.015625 , iter= 5414
current loss is: 4.097044 , acc is: 0.015625 , iter= 5415
current loss is: 4.126385 , acc is: 0.015625 , iter= 5416
current loss is: 4.0528984 , acc is: 0.0625 , iter= 5417
current loss is: 4.0203605 , acc is: 0.078125 , iter= 5418
current loss is: 4.087352 , acc is: 0.0625 , iter= 5419
current loss is: 4.1180773 , acc is: 0.03125 , iter= 5420
current loss is: 4.008255 , acc is: 0.078125 , iter= 5421
current loss is: 4.062299 , acc is: 0.046875 , iter= 5422
current loss is: 4.1542335 , acc is: 0.015625 , iter= 5423
current loss is: 4.055472 , acc is: 0.03125 , iter= 5424
current loss is: 4.088208 , acc is: 0.0 , iter= 5425
current loss is: 4.0785704 , acc is: 0.03125 , iter= 5426
current loss is: 4.1131473 , acc is: 0.015625 , iter= 5427
current loss is: 4.0759687 , acc is: 0.015625 , iter= 5428
current loss is: 3.9695277 , acc is: 0.0625 , iter= 5429
current loss is: 3.9784887 , acc is: 0.0625 , iter= 5430
current loss is: 4.0765343 , acc is: 0.046875 , iter= 5431
current loss is: 4.075842 , acc is: 0.0625 , iter= 5432
current loss is: 4.0597777 , acc is: 0.03125 , iter= 5433
current loss is: 4.0742693 , acc is: 0.015625 , iter= 5434
current loss is: 4.0553827 , acc is: 0.03125 , iter= 5435
current loss is: 3.897677 , acc is: 0.09375 , iter= 5436
current loss is: 4.11792 , acc is: 0.03125 , iter= 5437
current loss is: 4.1743145 , acc is: 0.015625 , iter= 5438
current loss is: 4.1364965 , acc is: 0.015625 , iter= 5439
current loss is: 3.8943167 , acc is: 0.078125 , iter= 5440
current loss is: 4.0942354 , acc is: 0.015625 , iter= 5441
current loss is: 4.1447883 , acc is: 0.015625 , iter= 5442
current loss is: 4.110799 , acc is: 0.03125 , iter= 5443
current loss is: 3.9449348 , acc is: 0.078125 , iter= 5444
current loss is: 4.004651 , acc is: 0.078125 , iter= 5445
current loss is: 4.0753365 , acc is: 0.03125 , iter= 5446
current loss is: 4.0832014 , acc is: 0.046875 , iter= 5447
current loss is: 4.1240096 , acc is: 0.015625 , iter= 5448
current loss is: 4.1707306 , acc is: 0.0 , iter= 5449
current loss is: 4.106689 , acc is: 0.03125 , iter= 5450
current loss is: 4.0059485 , acc is: 0.0625 , iter= 5451
current loss is: 4.006967 , acc is: 0.046875 , iter= 5452
current loss is: 3.9769936 , acc is: 0.046875 , iter= 5453
current loss is: 4.1251717 , acc is: 0.0 , iter= 5454
current loss is: 3.8880477 , acc is: 0.078125 , iter= 5455
current loss is: 4.0541964 , acc is: 0.015625 , iter= 5456
current loss is: 4.1361 , acc is: 0.03125 , iter= 5457
current loss is: 3.9835894 , acc is: 0.0625 , iter= 5458
current loss is: 4.089205 , acc is: 0.03125 , iter= 5459
current loss is: 4.117793 , acc is: 0.015625 , iter= 5460
current loss is: 4.022799 , acc is: 0.03125 , iter= 5461
current loss is: 4.0026174 , acc is: 0.0625 , iter= 5462
current loss is: 4.135634 , acc is: 0.03125 , iter= 5463
current loss is: 4.1168528 , acc is: 0.015625 , iter= 5464
current loss is: 4.0525074 , acc is: 0.0625 , iter= 5465
current loss is: 4.127162 , acc is: 0.015625 , iter= 5466
current loss is: 4.195365 , acc is: 0.015625 , iter= 5467
current loss is: 4.1737 , acc is: 0.03125 , iter= 5468
current loss is: 4.1455326 , acc is: 0.015625 , iter= 5469
current loss is: 3.937329 , acc is: 0.078125 , iter= 5470
current loss is: 4.1596417 , acc is: 0.046875 , iter= 5471
current loss is: 4.149898 , acc is: 0.03125 , iter= 5472
current loss is: 4.096099 , acc is: 0.09375 , iter= 5473
current loss is: 4.077988 , acc is: 0.03125 , iter= 5474
current loss is: 4.003707 , acc is: 0.046875 , iter= 5475
current loss is: 4.115176 , acc is: 0.03125 , iter= 5476
current loss is: 3.9580631 , acc is: 0.09375 , iter= 5477
current loss is: 4.0605063 , acc is: 0.015625 , iter= 5478
current loss is: 4.050387 , acc is: 0.03125 , iter= 5479
current loss is: 4.090148 , acc is: 0.03125 , iter= 5480
current loss is: 4.0462646 , acc is: 0.015625 , iter= 5481
current loss is: 4.130971 , acc is: 0.015625 , iter= 5482
current loss is: 4.096513 , acc is: 0.03125 , iter= 5483
current loss is: 4.017151 , acc is: 0.0625 , iter= 5484
current loss is: 3.9812672 , acc is: 0.078125 , iter= 5485
current loss is: 5.8562803 , acc is: 0.046875 , iter= 5486
current loss is: 7.0035014 , acc is: 0.03125 , iter= 5487
current loss is: 3.9750376 , acc is: 0.046875 , iter= 5488
current loss is: 5.3922877 , acc is: 0.0625 , iter= 5489
current loss is: 3.989188 , acc is: 0.03125 , iter= 5490
current loss is: 4.139471 , acc is: 0.0 , iter= 5491
current loss is: 4.081066 , acc is: 0.03125 , iter= 5492
current loss is: 4.091321 , acc is: 0.046875 , iter= 5493
current loss is: 3.9796355 , acc is: 0.03125 , iter= 5494
current loss is: 4.182514 , acc is: 0.0 , iter= 5495
current loss is: 4.0059104 , acc is: 0.0625 , iter= 5496
current loss is: 4.16731 , acc is: 0.03125 , iter= 5497
current loss is: 4.178005 , acc is: 0.0 , iter= 5498
current loss is: 4.0859547 , acc is: 0.015625 , iter= 5499
current loss is: 4.1032352 , acc is: 0.03125 , iter= 5500
current loss is: 4.1621637 , acc is: 0.03125 , iter= 5501
current loss is: 4.0393915 , acc is: 0.078125 , iter= 5502
current loss is: 4.068395 , acc is: 0.046875 , iter= 5503
current loss is: 4.1355276 , acc is: 0.03125 , iter= 5504
current loss is: 4.313242 , acc is: 0.03125 , iter= 5505
current loss is: 4.112006 , acc is: 0.03125 , iter= 5506
current loss is: 3.9061508 , acc is: 0.078125 , iter= 5507
current loss is: 4.1889253 , acc is: 0.015625 , iter= 5508
current loss is: 3.7985907 , acc is: 0.125 , iter= 5509
current loss is: 4.07481 , acc is: 0.0625 , iter= 5510
current loss is: 4.042923 , acc is: 0.0625 , iter= 5511
current loss is: 4.549735 , acc is: 0.078125 , iter= 5512
current loss is: 3.9637055 , acc is: 0.078125 , iter= 5513
current loss is: 15.44444 , acc is: 0.015625 , iter= 5514
current loss is: 4.0417256 , acc is: 0.0625 , iter= 5515
current loss is: 4.118703 , acc is: 0.046875 , iter= 5516
current loss is: 4.048333 , acc is: 0.03125 , iter= 5517
current loss is: 4.003004 , acc is: 0.046875 , iter= 5518
current loss is: 4.1117244 , acc is: 0.03125 , iter= 5519
current loss is: 4.074318 , acc is: 0.03125 , iter= 5520
current loss is: 4.0410953 , acc is: 0.015625 , iter= 5521
current loss is: 4.12086 , acc is: 0.015625 , iter= 5522
current loss is: 5.3680964 , acc is: 0.078125 , iter= 5523
current loss is: 4.578145 , acc is: 0.046875 , iter= 5524
current loss is: 4.0804477 , acc is: 0.03125 , iter= 5525
current loss is: 4.0771084 , acc is: 0.03125 , iter= 5526
current loss is: 4.829725 , acc is: 0.015625 , iter= 5527
current loss is: 4.0694685 , acc is: 0.03125 , iter= 5528
current loss is: 4.111231 , acc is: 0.03125 , iter= 5529
current loss is: 4.060931 , acc is: 0.046875 , iter= 5530
current loss is: 4.1291485 , acc is: 0.0 , iter= 5531
current loss is: 3.9708521 , acc is: 0.046875 , iter= 5532
current loss is: 4.0416665 , acc is: 0.03125 , iter= 5533
current loss is: 4.137768 , acc is: 0.03125 , iter= 5534
current loss is: 4.0533123 , acc is: 0.046875 , iter= 5535
current loss is: 4.145034 , acc is: 0.0 , iter= 5536
current loss is: 4.1770315 , acc is: 0.015625 , iter= 5537
current loss is: 3.9065428 , acc is: 0.125 , iter= 5538
current loss is: 3.9686508 , acc is: 0.0625 , iter= 5539
current loss is: 12.02369 , acc is: 0.0625 , iter= 5540
current loss is: 4.161077 , acc is: 0.03125 , iter= 5541
current loss is: 4.064232 , acc is: 0.078125 , iter= 5542
current loss is: 4.1904993 , acc is: 0.0 , iter= 5543
current loss is: 3.8878136 , acc is: 0.078125 , iter= 5544
current loss is: 4.047385 , acc is: 0.015625 , iter= 5545
current loss is: 4.046621 , acc is: 0.09375 , iter= 5546
current loss is: 4.0154333 , acc is: 0.046875 , iter= 5547
current loss is: 4.0980635 , acc is: 0.015625 , iter= 5548
current loss is: 4.2222004 , acc is: 0.0 , iter= 5549
current loss is: 4.0028286 , acc is: 0.03125 , iter= 5550
current loss is: 4.070655 , acc is: 0.015625 , iter= 5551
current loss is: 4.1108437 , acc is: 0.03125 , iter= 5552
current loss is: 4.116317 , acc is: 0.0 , iter= 5553
current loss is: 4.147747 , acc is: 0.015625 , iter= 5554
current loss is: 4.022478 , acc is: 0.078125 , iter= 5555
current loss is: 4.142194 , acc is: 0.0 , iter= 5556
current loss is: 4.040787 , acc is: 0.0625 , iter= 5557
current loss is: 3.9751613 , acc is: 0.0625 , iter= 5558
current loss is: 4.1990337 , acc is: 0.015625 , iter= 5559
current loss is: 4.1607533 , acc is: 0.03125 , iter= 5560
current loss is: 3.9950142 , acc is: 0.0625 , iter= 5561
current loss is: 4.0054474 , acc is: 0.046875 , iter= 5562
current loss is: 4.179404 , acc is: 0.078125 , iter= 5563
current loss is: 4.0217957 , acc is: 0.0625 , iter= 5564
current loss is: 5.8477564 , acc is: 0.046875 , iter= 5565
current loss is: 4.5743647 , acc is: 0.03125 , iter= 5566
current loss is: 4.212167 , acc is: 0.015625 , iter= 5567
current loss is: 4.02054 , acc is: 0.078125 , iter= 5568
current loss is: 4.2476587 , acc is: 0.0625 , iter= 5569
current loss is: 4.0323114 , acc is: 0.0625 , iter= 5570
current loss is: 4.5499153 , acc is: 0.046875 , iter= 5571
current loss is: 4.16253 , acc is: 0.0 , iter= 5572
current loss is: 4.181755 , acc is: 0.015625 , iter= 5573
current loss is: 4.175846 , acc is: 0.03125 , iter= 5574
current loss is: 3.9515305 , acc is: 0.046875 , iter= 5575
current loss is: 4.094983 , acc is: 0.03125 , iter= 5576
current loss is: 4.0016727 , acc is: 0.078125 , iter= 5577
current loss is: 4.124129 , acc is: 0.0625 , iter= 5578
current loss is: 4.199154 , acc is: 0.03125 , iter= 5579
current loss is: 4.1749573 , acc is: 0.03125 , iter= 5580
current loss is: 4.1192694 , acc is: 0.03125 , iter= 5581
current loss is: 3.8986094 , acc is: 0.078125 , iter= 5582
current loss is: 4.0847697 , acc is: 0.03125 , iter= 5583
current loss is: 3.9439993 , acc is: 0.046875 , iter= 5584
current loss is: 4.180602 , acc is: 0.03125 , iter= 5585
current loss is: 4.0040145 , acc is: 0.03125 , iter= 5586
current loss is: 4.034629 , acc is: 0.046875 , iter= 5587
current loss is: 4.247898 , acc is: 0.015625 , iter= 5588
current loss is: 4.1813383 , acc is: 0.03125 , iter= 5589
current loss is: 4.077999 , acc is: 0.046875 , iter= 5590
current loss is: 4.049018 , acc is: 0.046875 , iter= 5591
current loss is: 4.1951523 , acc is: 0.015625 , iter= 5592
current loss is: 4.1109333 , acc is: 0.046875 , iter= 5593
current loss is: 4.0478354 , acc is: 0.046875 , iter= 5594
current loss is: 4.0910215 , acc is: 0.015625 , iter= 5595
current loss is: 4.0537806 , acc is: 0.03125 , iter= 5596
current loss is: 4.1057143 , acc is: 0.015625 , iter= 5597
current loss is: 4.0666776 , acc is: 0.015625 , iter= 5598
current loss is: 4.084918 , acc is: 0.03125 , iter= 5599
current loss is: 4.061559 , acc is: 0.03125 , iter= 5600
current loss is: 4.153372 , acc is: 0.0 , iter= 5601
current loss is: 4.1774106 , acc is: 0.0 , iter= 5602
current loss is: 4.1783752 , acc is: 0.0 , iter= 5603
current loss is: 4.0450516 , acc is: 0.046875 , iter= 5604
current loss is: 4.1589346 , acc is: 0.015625 , iter= 5605
current loss is: 4.032926 , acc is: 0.015625 , iter= 5606
current loss is: 4.081687 , acc is: 0.03125 , iter= 5607
current loss is: 4.2090664 , acc is: 0.03125 , iter= 5608
current loss is: 4.1512213 , acc is: 0.015625 , iter= 5609
current loss is: 4.0268526 , acc is: 0.03125 , iter= 5610
current loss is: 4.1109743 , acc is: 0.03125 , iter= 5611
current loss is: 3.9983168 , acc is: 0.046875 , iter= 5612
current loss is: 8.008241 , acc is: 0.015625 , iter= 5613
current loss is: 4.023553 , acc is: 0.046875 , iter= 5614
current loss is: 4.135204 , acc is: 0.015625 , iter= 5615
current loss is: 4.0788794 , acc is: 0.03125 , iter= 5616
current loss is: 3.96545 , acc is: 0.0625 , iter= 5617
current loss is: 4.1223 , acc is: 0.015625 , iter= 5618
current loss is: 5.121955 , acc is: 0.015625 , iter= 5619
current loss is: 4.0912967 , acc is: 0.03125 , iter= 5620
current loss is: 4.1262712 , acc is: 0.0 , iter= 5621
current loss is: 4.126049 , acc is: 0.015625 , iter= 5622
current loss is: 3.8790941 , acc is: 0.109375 , iter= 5623
current loss is: 4.0088215 , acc is: 0.046875 , iter= 5624
current loss is: 4.6480083 , acc is: 0.046875 , iter= 5625
current loss is: 4.242532 , acc is: 0.046875 , iter= 5626
current loss is: 4.089538 , acc is: 0.03125 , iter= 5627
current loss is: 4.103094 , acc is: 0.03125 , iter= 5628
current loss is: 3.9219646 , acc is: 0.078125 , iter= 5629
current loss is: 4.1863165 , acc is: 0.0 , iter= 5630
current loss is: 5.0233994 , acc is: 0.03125 , iter= 5631
current loss is: 4.0430713 , acc is: 0.046875 , iter= 5632
current loss is: 4.0625005 , acc is: 0.03125 , iter= 5633
current loss is: 4.0854745 , acc is: 0.03125 , iter= 5634
current loss is: 4.359126 , acc is: 0.03125 , iter= 5635
current loss is: 4.1469197 , acc is: 0.03125 , iter= 5636
current loss is: 4.180423 , acc is: 0.015625 , iter= 5637
current loss is: 4.102703 , acc is: 0.0625 , iter= 5638
current loss is: 4.2192655 , acc is: 0.03125 , iter= 5639
current loss is: 4.1773825 , acc is: 0.0 , iter= 5640
current loss is: 4.0754066 , acc is: 0.03125 , iter= 5641
current loss is: 4.203667 , acc is: 0.03125 , iter= 5642
current loss is: 3.9230866 , acc is: 0.0625 , iter= 5643
current loss is: 4.1669207 , acc is: 0.015625 , iter= 5644
current loss is: 4.1519794 , acc is: 0.03125 , iter= 5645
current loss is: 4.1627016 , acc is: 0.0625 , iter= 5646
current loss is: 4.0959616 , acc is: 0.015625 , iter= 5647
current loss is: 4.0765743 , acc is: 0.03125 , iter= 5648
current loss is: 4.1482935 , acc is: 0.03125 , iter= 5649
current loss is: 4.1655207 , acc is: 0.03125 , iter= 5650
current loss is: 3.9876037 , acc is: 0.078125 , iter= 5651
current loss is: 4.122825 , acc is: 0.046875 , iter= 5652
current loss is: 4.076744 , acc is: 0.015625 , iter= 5653
current loss is: 4.06916 , acc is: 0.0625 , iter= 5654
current loss is: 4.180391 , acc is: 0.015625 , iter= 5655
current loss is: 4.119435 , acc is: 0.015625 , iter= 5656
current loss is: 4.4614296 , acc is: 0.015625 , iter= 5657
current loss is: 4.146913 , acc is: 0.015625 , iter= 5658
current loss is: 6.9124393 , acc is: 0.015625 , iter= 5659
current loss is: 3.9679918 , acc is: 0.078125 , iter= 5660
current loss is: 4.0664845 , acc is: 0.0625 , iter= 5661
current loss is: 4.06904 , acc is: 0.046875 , iter= 5662
current loss is: 4.0882535 , acc is: 0.015625 , iter= 5663
current loss is: 4.169507 , acc is: 0.015625 , iter= 5664
current loss is: 4.6802073 , acc is: 0.03125 , iter= 5665
current loss is: 11.931744 , acc is: 0.03125 , iter= 5666
current loss is: 4.0734577 , acc is: 0.046875 , iter= 5667
current loss is: 4.1077847 , acc is: 0.015625 , iter= 5668
current loss is: 4.00809 , acc is: 0.078125 , iter= 5669
current loss is: 4.100509 , acc is: 0.03125 , iter= 5670
current loss is: 4.0531936 , acc is: 0.046875 , iter= 5671
current loss is: 4.0919614 , acc is: 0.015625 , iter= 5672
current loss is: 4.1528444 , acc is: 0.0 , iter= 5673
current loss is: 4.1371117 , acc is: 0.046875 , iter= 5674
current loss is: 4.096073 , acc is: 0.03125 , iter= 5675
current loss is: 4.064717 , acc is: 0.046875 , iter= 5676
current loss is: 4.068638 , acc is: 0.03125 , iter= 5677
current loss is: 4.1113825 , acc is: 0.0625 , iter= 5678
current loss is: 4.095375 , acc is: 0.078125 , iter= 5679
current loss is: 4.1876326 , acc is: 0.03125 , iter= 5680
current loss is: 4.1706343 , acc is: 0.015625 , iter= 5681
current loss is: 4.1733327 , acc is: 0.015625 , iter= 5682
current loss is: 4.074376 , acc is: 0.03125 , iter= 5683
current loss is: 4.0089736 , acc is: 0.03125 , iter= 5684
current loss is: 4.173751 , acc is: 0.0 , iter= 5685
current loss is: 4.044101 , acc is: 0.03125 , iter= 5686
current loss is: 4.1285048 , acc is: 0.03125 , iter= 5687
current loss is: 7.981165 , acc is: 0.03125 , iter= 5688
current loss is: 4.070885 , acc is: 0.046875 , iter= 5689
current loss is: 4.082014 , acc is: 0.046875 , iter= 5690
current loss is: 3.9887717 , acc is: 0.03125 , iter= 5691
current loss is: 4.0940247 , acc is: 0.03125 , iter= 5692
current loss is: 4.1494384 , acc is: 0.046875 , iter= 5693
current loss is: 9.971894 , acc is: 0.015625 , iter= 5694
current loss is: 4.091055 , acc is: 0.015625 , iter= 5695
current loss is: 4.058268 , acc is: 0.046875 , iter= 5696
current loss is: 4.1308975 , acc is: 0.015625 , iter= 5697
current loss is: 4.0330915 , acc is: 0.0625 , iter= 5698
current loss is: 4.1235895 , acc is: 0.03125 , iter= 5699
current loss is: 4.013394 , acc is: 0.0625 , iter= 5700
current loss is: 4.045066 , acc is: 0.015625 , iter= 5701
current loss is: 4.2313104 , acc is: 0.015625 , iter= 5702
current loss is: 4.1370068 , acc is: 0.046875 , iter= 5703
current loss is: 4.828123 , acc is: 0.015625 , iter= 5704
current loss is: 4.0509205 , acc is: 0.015625 , iter= 5705
current loss is: 4.121791 , acc is: 0.03125 , iter= 5706
current loss is: 9.472285 , acc is: 0.046875 , iter= 5707
current loss is: 3.9627244 , acc is: 0.046875 , iter= 5708
current loss is: 3.966527 , acc is: 0.046875 , iter= 5709
current loss is: 3.8846188 , acc is: 0.09375 , iter= 5710
current loss is: 4.031171 , acc is: 0.03125 , iter= 5711
current loss is: 4.137057 , acc is: 0.03125 , iter= 5712
current loss is: 4.139498 , acc is: 0.0 , iter= 5713
current loss is: 4.0997286 , acc is: 0.046875 , iter= 5714
current loss is: 3.9419103 , acc is: 0.0625 , iter= 5715
current loss is: 4.109109 , acc is: 0.046875 , iter= 5716
current loss is: 3.9603963 , acc is: 0.0625 , iter= 5717
current loss is: 4.1199045 , acc is: 0.046875 , iter= 5718
current loss is: 4.114308 , acc is: 0.0 , iter= 5719
current loss is: 4.1918955 , acc is: 0.046875 , iter= 5720
current loss is: 4.095265 , acc is: 0.046875 , iter= 5721
current loss is: 4.154925 , acc is: 0.015625 , iter= 5722
current loss is: 4.1772666 , acc is: 0.0 , iter= 5723
current loss is: 4.1019535 , acc is: 0.015625 , iter= 5724
current loss is: 4.1317277 , acc is: 0.015625 , iter= 5725
current loss is: 4.18294 , acc is: 0.015625 , iter= 5726
current loss is: 4.1186457 , acc is: 0.03125 , iter= 5727
current loss is: 4.0677023 , acc is: 0.0625 , iter= 5728
current loss is: 4.1139297 , acc is: 0.03125 , iter= 5729
current loss is: 4.068316 , acc is: 0.0625 , iter= 5730
current loss is: 3.9421825 , acc is: 0.078125 , iter= 5731
current loss is: 4.0996118 , acc is: 0.03125 , iter= 5732
current loss is: 4.156731 , acc is: 0.0 , iter= 5733
current loss is: 3.988799 , acc is: 0.0625 , iter= 5734
current loss is: 4.104418 , acc is: 0.03125 , iter= 5735
current loss is: 4.1585703 , acc is: 0.03125 , iter= 5736
current loss is: 4.1531925 , acc is: 0.03125 , iter= 5737
current loss is: 4.1482797 , acc is: 0.03125 , iter= 5738
current loss is: 4.1668935 , acc is: 0.0 , iter= 5739
current loss is: 4.15107 , acc is: 0.015625 , iter= 5740
current loss is: 4.1573763 , acc is: 0.015625 , iter= 5741
current loss is: 4.1064744 , acc is: 0.015625 , iter= 5742
current loss is: 3.9162629 , acc is: 0.078125 , iter= 5743
current loss is: 3.983242 , acc is: 0.09375 , iter= 5744
current loss is: 4.0588074 , acc is: 0.03125 , iter= 5745
current loss is: 4.1804457 , acc is: 0.0 , iter= 5746
current loss is: 4.1869817 , acc is: 0.015625 , iter= 5747
current loss is: 4.0816545 , acc is: 0.03125 , iter= 5748
current loss is: 4.040969 , acc is: 0.046875 , iter= 5749
current loss is: 4.141904 , acc is: 0.0 , iter= 5750
current loss is: 4.0491667 , acc is: 0.0625 , iter= 5751
current loss is: 4.147771 , acc is: 0.015625 , iter= 5752
current loss is: 4.10216 , acc is: 0.015625 , iter= 5753
current loss is: 4.1342516 , acc is: 0.03125 , iter= 5754
current loss is: 4.7691956 , acc is: 0.0 , iter= 5755
current loss is: 3.9004583 , acc is: 0.078125 , iter= 5756
current loss is: 4.089756 , acc is: 0.046875 , iter= 5757
current loss is: 4.0635242 , acc is: 0.03125 , iter= 5758
current loss is: 4.082342 , acc is: 0.015625 , iter= 5759
current loss is: 4.111994 , acc is: 0.0 , iter= 5760
current loss is: 4.0567837 , acc is: 0.03125 , iter= 5761
current loss is: 4.0716925 , acc is: 0.03125 , iter= 5762
current loss is: 4.0815926 , acc is: 0.046875 , iter= 5763
current loss is: 4.0657396 , acc is: 0.0625 , iter= 5764
current loss is: 4.092406 , acc is: 0.015625 , iter= 5765
current loss is: 4.0856647 , acc is: 0.03125 , iter= 5766
current loss is: 3.919244 , acc is: 0.078125 , iter= 5767
current loss is: 4.1629415 , acc is: 0.03125 , iter= 5768
current loss is: 4.0116506 , acc is: 0.0625 , iter= 5769
current loss is: 4.075095 , acc is: 0.046875 , iter= 5770
current loss is: 4.009103 , acc is: 0.046875 , iter= 5771
current loss is: 4.091531 , acc is: 0.09375 , iter= 5772
current loss is: 4.173517 , acc is: 0.0 , iter= 5773
current loss is: 4.0395255 , acc is: 0.046875 , iter= 5774
current loss is: 3.895216 , acc is: 0.09375 , iter= 5775
current loss is: 4.1030946 , acc is: 0.03125 , iter= 5776
current loss is: 4.0297422 , acc is: 0.0625 , iter= 5777
current loss is: 4.0821548 , acc is: 0.015625 , iter= 5778
current loss is: 4.128035 , acc is: 0.03125 , iter= 5779
current loss is: 4.1551685 , acc is: 0.015625 , iter= 5780
current loss is: 4.158884 , acc is: 0.03125 , iter= 5781
current loss is: 7.228425 , acc is: 0.0625 , iter= 5782
current loss is: 4.051218 , acc is: 0.03125 , iter= 5783
current loss is: 4.214737 , acc is: 0.03125 , iter= 5784
current loss is: 4.1042886 , acc is: 0.03125 , iter= 5785
current loss is: 22.499886 , acc is: 0.03125 , iter= 5786
current loss is: 4.0089245 , acc is: 0.046875 , iter= 5787
current loss is: 4.035761 , acc is: 0.03125 , iter= 5788
current loss is: 4.117303 , acc is: 0.046875 , iter= 5789
current loss is: 4.1622086 , acc is: 0.0 , iter= 5790
current loss is: 4.1075573 , acc is: 0.03125 , iter= 5791
current loss is: 4.183055 , acc is: 0.0 , iter= 5792
current loss is: 4.139085 , acc is: 0.0 , iter= 5793
current loss is: 4.1228895 , acc is: 0.0625 , iter= 5794
current loss is: 4.100647 , acc is: 0.046875 , iter= 5795
current loss is: 4.0323095 , acc is: 0.015625 , iter= 5796
current loss is: 4.100267 , acc is: 0.015625 , iter= 5797
current loss is: 4.0899405 , acc is: 0.03125 , iter= 5798
current loss is: 4.089834 , acc is: 0.03125 , iter= 5799
current loss is: 4.1236134 , acc is: 0.03125 , iter= 5800
current loss is: 4.138341 , acc is: 0.03125 , iter= 5801
current loss is: 4.1596937 , acc is: 0.015625 , iter= 5802
current loss is: 4.104457 , acc is: 0.03125 , iter= 5803
current loss is: 4.052492 , acc is: 0.046875 , iter= 5804
current loss is: 3.9288235 , acc is: 0.0625 , iter= 5805
current loss is: 4.153592 , acc is: 0.046875 , iter= 5806
current loss is: 3.9783795 , acc is: 0.0625 , iter= 5807
current loss is: 4.1793814 , acc is: 0.015625 , iter= 5808
current loss is: 4.0840483 , acc is: 0.03125 , iter= 5809
current loss is: 4.112112 , acc is: 0.046875 , iter= 5810
current loss is: 4.0108843 , acc is: 0.0625 , iter= 5811
current loss is: 4.1116433 , acc is: 0.03125 , iter= 5812
current loss is: 3.8866196 , acc is: 0.078125 , iter= 5813
current loss is: 4.0690002 , acc is: 0.046875 , iter= 5814
current loss is: 4.039583 , acc is: 0.046875 , iter= 5815
current loss is: 4.1173763 , acc is: 0.03125 , iter= 5816
current loss is: 4.182132 , acc is: 0.0 , iter= 5817
current loss is: 4.695257 , acc is: 0.0 , iter= 5818
current loss is: 4.1378393 , acc is: 0.03125 , iter= 5819
current loss is: 4.106449 , acc is: 0.03125 , iter= 5820
current loss is: 3.9150827 , acc is: 0.078125 , iter= 5821
current loss is: 4.0525093 , acc is: 0.046875 , iter= 5822
current loss is: 4.0622606 , acc is: 0.03125 , iter= 5823
current loss is: 4.0357056 , acc is: 0.0625 , iter= 5824
current loss is: 4.136832 , acc is: 0.046875 , iter= 5825
current loss is: 4.0993924 , acc is: 0.015625 , iter= 5826
current loss is: 4.1419296 , acc is: 0.03125 , iter= 5827
current loss is: 4.120125 , acc is: 0.0625 , iter= 5828
current loss is: 4.022274 , acc is: 0.046875 , iter= 5829
current loss is: 4.059145 , acc is: 0.046875 , iter= 5830
current loss is: 4.0391006 , acc is: 0.046875 , iter= 5831
current loss is: 4.1516476 , acc is: 0.015625 , iter= 5832
current loss is: 4.088846 , acc is: 0.03125 , iter= 5833
current loss is: 4.1397967 , acc is: 0.0 , iter= 5834
current loss is: 4.0648074 , acc is: 0.03125 , iter= 5835
current loss is: 4.1200705 , acc is: 0.015625 , iter= 5836
current loss is: 4.1440344 , acc is: 0.03125 , iter= 5837
current loss is: 4.1295238 , acc is: 0.03125 , iter= 5838
current loss is: 4.130872 , acc is: 0.0 , iter= 5839
current loss is: 4.1458616 , acc is: 0.03125 , iter= 5840
current loss is: 4.1005836 , acc is: 0.03125 , iter= 5841
current loss is: 3.8740692 , acc is: 0.125 , iter= 5842
current loss is: 4.058754 , acc is: 0.0625 , iter= 5843
current loss is: 4.076989 , acc is: 0.03125 , iter= 5844
current loss is: 4.1080236 , acc is: 0.015625 , iter= 5845
current loss is: 4.0592146 , acc is: 0.015625 , iter= 5846
current loss is: 4.09861 , acc is: 0.046875 , iter= 5847
current loss is: 4.138442 , acc is: 0.015625 , iter= 5848
current loss is: 4.140297 , acc is: 0.046875 , iter= 5849
current loss is: 4.0607715 , acc is: 0.03125 , iter= 5850
current loss is: 4.1644616 , acc is: 0.015625 , iter= 5851
current loss is: 4.008581 , acc is: 0.0625 , iter= 5852
current loss is: 4.0664535 , acc is: 0.03125 , iter= 5853
current loss is: 3.976447 , acc is: 0.09375 , iter= 5854
current loss is: 3.9553246 , acc is: 0.046875 , iter= 5855
current loss is: 3.8992214 , acc is: 0.09375 , iter= 5856
current loss is: 4.1220336 , acc is: 0.0 , iter= 5857
current loss is: 4.113515 , acc is: 0.078125 , iter= 5858
current loss is: 4.157732 , acc is: 0.015625 , iter= 5859
current loss is: 4.0360355 , acc is: 0.0625 , iter= 5860
current loss is: 4.089972 , acc is: 0.046875 , iter= 5861
current loss is: 4.1573963 , acc is: 0.03125 , iter= 5862
current loss is: 4.1656804 , acc is: 0.0 , iter= 5863
current loss is: 4.1552334 , acc is: 0.0 , iter= 5864
current loss is: 4.1364737 , acc is: 0.015625 , iter= 5865
current loss is: 4.0267286 , acc is: 0.03125 , iter= 5866
current loss is: 4.0836315 , acc is: 0.0625 , iter= 5867
current loss is: 4.082569 , acc is: 0.046875 , iter= 5868
current loss is: 4.0623684 , acc is: 0.0625 , iter= 5869
current loss is: 3.938155 , acc is: 0.0625 , iter= 5870
current loss is: 4.0746126 , acc is: 0.015625 , iter= 5871
current loss is: 4.1355877 , acc is: 0.046875 , iter= 5872
current loss is: 4.114656 , acc is: 0.03125 , iter= 5873
current loss is: 4.157447 , acc is: 0.03125 , iter= 5874
current loss is: 4.0859528 , acc is: 0.046875 , iter= 5875
current loss is: 4.0552583 , acc is: 0.03125 , iter= 5876
current loss is: 4.1439743 , acc is: 0.0 , iter= 5877
current loss is: 4.175832 , acc is: 0.0 , iter= 5878
current loss is: 3.9611483 , acc is: 0.046875 , iter= 5879
current loss is: 4.1638107 , acc is: 0.03125 , iter= 5880
current loss is: 4.00723 , acc is: 0.078125 , iter= 5881
current loss is: 4.1546106 , acc is: 0.015625 , iter= 5882
current loss is: 4.0978646 , acc is: 0.015625 , iter= 5883
current loss is: 3.9356074 , acc is: 0.046875 , iter= 5884
current loss is: 4.0835075 , acc is: 0.03125 , iter= 5885
current loss is: 4.0450277 , acc is: 0.109375 , iter= 5886
current loss is: 4.195622 , acc is: 0.015625 , iter= 5887
current loss is: 4.074455 , acc is: 0.046875 , iter= 5888
current loss is: 3.9646077 , acc is: 0.03125 , iter= 5889
current loss is: 4.1843004 , acc is: 0.03125 , iter= 5890
current loss is: 4.1782236 , acc is: 0.03125 , iter= 5891
current loss is: 4.062216 , acc is: 0.015625 , iter= 5892
current loss is: 4.1124926 , acc is: 0.046875 , iter= 5893
current loss is: 4.0360284 , acc is: 0.03125 , iter= 5894
current loss is: 4.120178 , acc is: 0.015625 , iter= 5895
current loss is: 4.131706 , acc is: 0.015625 , iter= 5896
current loss is: 4.126711 , acc is: 0.046875 , iter= 5897
current loss is: 4.043187 , acc is: 0.03125 , iter= 5898
current loss is: 4.070078 , acc is: 0.046875 , iter= 5899
current loss is: 4.1455307 , acc is: 0.015625 , iter= 5900
current loss is: 4.068615 , acc is: 0.015625 , iter= 5901
current loss is: 4.160823 , acc is: 0.015625 , iter= 5902
current loss is: 4.1933274 , acc is: 0.015625 , iter= 5903
current loss is: 4.170512 , acc is: 0.0 , iter= 5904
current loss is: 4.0236845 , acc is: 0.03125 , iter= 5905
current loss is: 4.0021434 , acc is: 0.046875 , iter= 5906
current loss is: 3.9542668 , acc is: 0.078125 , iter= 5907
current loss is: 4.082116 , acc is: 0.03125 , iter= 5908
current loss is: 4.009977 , acc is: 0.046875 , iter= 5909
current loss is: 4.114082 , acc is: 0.015625 , iter= 5910
current loss is: 4.1254997 , acc is: 0.046875 , iter= 5911
current loss is: 3.969653 , acc is: 0.0625 , iter= 5912
current loss is: 4.8831596 , acc is: 0.0625 , iter= 5913
current loss is: 4.195634 , acc is: 0.015625 , iter= 5914
current loss is: 4.1421795 , acc is: 0.015625 , iter= 5915
current loss is: 4.127632 , acc is: 0.015625 , iter= 5916
current loss is: 4.0931997 , acc is: 0.015625 , iter= 5917
current loss is: 4.2159905 , acc is: 0.0 , iter= 5918
current loss is: 4.1346684 , acc is: 0.03125 , iter= 5919
current loss is: 4.12716 , acc is: 0.03125 , iter= 5920
current loss is: 3.9981742 , acc is: 0.03125 , iter= 5921
current loss is: 4.0022516 , acc is: 0.03125 , iter= 5922
current loss is: 4.060022 , acc is: 0.03125 , iter= 5923
current loss is: 4.0905786 , acc is: 0.015625 , iter= 5924
current loss is: 4.0883327 , acc is: 0.015625 , iter= 5925
current loss is: 4.143459 , acc is: 0.015625 , iter= 5926
current loss is: 4.101066 , acc is: 0.03125 , iter= 5927
current loss is: 4.168845 , acc is: 0.0 , iter= 5928
current loss is: 4.137204 , acc is: 0.046875 , iter= 5929
current loss is: 4.152383 , acc is: 0.03125 , iter= 5930
current loss is: 3.9916973 , acc is: 0.03125 , iter= 5931
current loss is: 4.034236 , acc is: 0.0625 , iter= 5932
current loss is: 4.216733 , acc is: 0.015625 , iter= 5933
current loss is: 3.9940996 , acc is: 0.046875 , iter= 5934
current loss is: 4.0982747 , acc is: 0.0625 , iter= 5935
current loss is: 4.112163 , acc is: 0.03125 , iter= 5936
current loss is: 4.024045 , acc is: 0.03125 , iter= 5937
current loss is: 4.1325836 , acc is: 0.015625 , iter= 5938
current loss is: 4.131613 , acc is: 0.0 , iter= 5939
current loss is: 4.06839 , acc is: 0.03125 , iter= 5940
current loss is: 6.722274 , acc is: 0.0625 , iter= 5941
current loss is: 4.1710033 , acc is: 0.03125 , iter= 5942
current loss is: 3.7577262 , acc is: 0.140625 , iter= 5943
current loss is: 4.1509256 , acc is: 0.03125 , iter= 5944
current loss is: 4.09873 , acc is: 0.03125 , iter= 5945
current loss is: 4.1707354 , acc is: 0.03125 , iter= 5946
current loss is: 3.9259772 , acc is: 0.046875 , iter= 5947
current loss is: 4.1389284 , acc is: 0.046875 , iter= 5948
current loss is: 4.095934 , acc is: 0.03125 , iter= 5949
current loss is: 4.0850987 , acc is: 0.046875 , iter= 5950
current loss is: 4.1646166 , acc is: 0.015625 , iter= 5951
current loss is: 4.1458697 , acc is: 0.015625 , iter= 5952
current loss is: 4.18318 , acc is: 0.03125 , iter= 5953
current loss is: 3.9051309 , acc is: 0.09375 , iter= 5954
current loss is: 4.073175 , acc is: 0.09375 , iter= 5955
current loss is: 4.1387973 , acc is: 0.03125 , iter= 5956
current loss is: 4.121222 , acc is: 0.078125 , iter= 5957
current loss is: 4.050151 , acc is: 0.0625 , iter= 5958
current loss is: 4.094085 , acc is: 0.046875 , iter= 5959
current loss is: 4.0902314 , acc is: 0.03125 , iter= 5960
current loss is: 4.0307283 , acc is: 0.03125 , iter= 5961
current loss is: 4.0675926 , acc is: 0.03125 , iter= 5962
current loss is: 4.0557427 , acc is: 0.046875 , iter= 5963
current loss is: 4.150897 , acc is: 0.015625 , iter= 5964
current loss is: 4.0809402 , acc is: 0.03125 , iter= 5965
current loss is: 4.052237 , acc is: 0.03125 , iter= 5966
current loss is: 4.143965 , acc is: 0.0 , iter= 5967
current loss is: 4.1447425 , acc is: 0.03125 , iter= 5968
current loss is: 4.1710577 , acc is: 0.0 , iter= 5969
current loss is: 4.072891 , acc is: 0.015625 , iter= 5970
current loss is: 4.1472845 , acc is: 0.0 , iter= 5971
current loss is: 4.066819 , acc is: 0.015625 , iter= 5972
current loss is: 4.144836 , acc is: 0.015625 , iter= 5973
current loss is: 4.0305657 , acc is: 0.046875 , iter= 5974
current loss is: 4.1496553 , acc is: 0.03125 , iter= 5975
current loss is: 4.05323 , acc is: 0.015625 , iter= 5976
current loss is: 4.0756807 , acc is: 0.03125 , iter= 5977
current loss is: 4.0538287 , acc is: 0.0625 , iter= 5978
current loss is: 4.054275 , acc is: 0.015625 , iter= 5979
current loss is: 4.1471176 , acc is: 0.046875 , iter= 5980
current loss is: 4.070522 , acc is: 0.015625 , iter= 5981
current loss is: 4.003193 , acc is: 0.046875 , iter= 5982
current loss is: 4.1147585 , acc is: 0.03125 , iter= 5983
current loss is: 4.0649567 , acc is: 0.046875 , iter= 5984
current loss is: 5.459626 , acc is: 0.0625 , iter= 5985
current loss is: 4.0297737 , acc is: 0.03125 , iter= 5986
current loss is: 4.021364 , acc is: 0.03125 , iter= 5987
current loss is: 4.172366 , acc is: 0.03125 , iter= 5988
current loss is: 3.9757001 , acc is: 0.046875 , iter= 5989
current loss is: 4.1257305 , acc is: 0.046875 , iter= 5990
current loss is: 3.9920733 , acc is: 0.046875 , iter= 5991
current loss is: 4.2117815 , acc is: 0.0 , iter= 5992
current loss is: 3.9761653 , acc is: 0.0625 , iter= 5993
current loss is: 4.081139 , acc is: 0.046875 , iter= 5994
current loss is: 4.0378604 , acc is: 0.03125 , iter= 5995
current loss is: 4.148692 , acc is: 0.015625 , iter= 5996
current loss is: 4.1072807 , acc is: 0.0 , iter= 5997
current loss is: 4.1151104 , acc is: 0.03125 , iter= 5998
current loss is: 4.1483793 , acc is: 0.015625 , iter= 5999
current loss is: 4.096384 , acc is: 0.015625 , iter= 6000
tot_acc= 19.0 tot_input= 768
current accuracy is: 0.024739583333333332
current loss is: 4.058332 , acc is: 0.046875 , iter= 6001
current loss is: 4.191333 , acc is: 0.015625 , iter= 6002
current loss is: 4.1494837 , acc is: 0.03125 , iter= 6003
current loss is: 4.0531416 , acc is: 0.046875 , iter= 6004
current loss is: 4.1911755 , acc is: 0.03125 , iter= 6005
current loss is: 4.0988493 , acc is: 0.015625 , iter= 6006
current loss is: 4.105689 , acc is: 0.015625 , iter= 6007
current loss is: 3.9618666 , acc is: 0.078125 , iter= 6008
current loss is: 4.1490097 , acc is: 0.015625 , iter= 6009
current loss is: 4.1541286 , acc is: 0.03125 , iter= 6010
current loss is: 4.103505 , acc is: 0.046875 , iter= 6011
current loss is: 4.110758 , acc is: 0.03125 , iter= 6012
current loss is: 4.1646385 , acc is: 0.03125 , iter= 6013
current loss is: 4.0515356 , acc is: 0.046875 , iter= 6014
current loss is: 4.1440034 , acc is: 0.015625 , iter= 6015
current loss is: 4.05052 , acc is: 0.03125 , iter= 6016
current loss is: 3.9861166 , acc is: 0.046875 , iter= 6017
current loss is: 4.101076 , acc is: 0.046875 , iter= 6018
current loss is: 4.100054 , acc is: 0.0625 , iter= 6019
current loss is: 4.0892844 , acc is: 0.015625 , iter= 6020
current loss is: 4.0801 , acc is: 0.046875 , iter= 6021
current loss is: 4.096076 , acc is: 0.046875 , iter= 6022
current loss is: 4.138155 , acc is: 0.03125 , iter= 6023
current loss is: 3.95788 , acc is: 0.046875 , iter= 6024
current loss is: 4.151757 , acc is: 0.03125 , iter= 6025
current loss is: 4.0240593 , acc is: 0.046875 , iter= 6026
current loss is: 4.0902815 , acc is: 0.03125 , iter= 6027
current loss is: 4.156373 , acc is: 0.015625 , iter= 6028
current loss is: 4.1167784 , acc is: 0.046875 , iter= 6029
current loss is: 4.052148 , acc is: 0.03125 , iter= 6030
current loss is: 4.0489235 , acc is: 0.046875 , iter= 6031
current loss is: 4.09145 , acc is: 0.03125 , iter= 6032
current loss is: 4.019145 , acc is: 0.0625 , iter= 6033
current loss is: 4.061446 , acc is: 0.03125 , iter= 6034
current loss is: 4.1377325 , acc is: 0.046875 , iter= 6035
current loss is: 4.0055876 , acc is: 0.03125 , iter= 6036
current loss is: 4.141878 , acc is: 0.03125 , iter= 6037
current loss is: 4.0711136 , acc is: 0.046875 , iter= 6038
current loss is: 4.0856633 , acc is: 0.046875 , iter= 6039
current loss is: 4.1105313 , acc is: 0.015625 , iter= 6040
current loss is: 4.014138 , acc is: 0.015625 , iter= 6041
current loss is: 4.09653 , acc is: 0.046875 , iter= 6042
current loss is: 4.141527 , acc is: 0.046875 , iter= 6043
current loss is: 3.9056785 , acc is: 0.0625 , iter= 6044
current loss is: 4.1699166 , acc is: 0.03125 , iter= 6045
current loss is: 4.062457 , acc is: 0.046875 , iter= 6046
current loss is: 4.071559 , acc is: 0.03125 , iter= 6047
current loss is: 4.116548 , acc is: 0.03125 , iter= 6048
current loss is: 4.4146523 , acc is: 0.03125 , iter= 6049
current loss is: 4.046053 , acc is: 0.015625 , iter= 6050
current loss is: 4.004009 , acc is: 0.078125 , iter= 6051
current loss is: 4.030868 , acc is: 0.046875 , iter= 6052
current loss is: 4.123078 , acc is: 0.0 , iter= 6053
current loss is: 4.080758 , acc is: 0.015625 , iter= 6054
current loss is: 4.1343307 , acc is: 0.0 , iter= 6055
current loss is: 4.177805 , acc is: 0.046875 , iter= 6056
current loss is: 4.1125736 , acc is: 0.0 , iter= 6057
current loss is: 4.146253 , acc is: 0.0 , iter= 6058
current loss is: 4.128716 , acc is: 0.015625 , iter= 6059
current loss is: 4.1094885 , acc is: 0.09375 , iter= 6060
current loss is: 4.014473 , acc is: 0.078125 , iter= 6061
current loss is: 4.1170373 , acc is: 0.015625 , iter= 6062
current loss is: 4.0095243 , acc is: 0.046875 , iter= 6063
current loss is: 4.070283 , acc is: 0.015625 , iter= 6064
current loss is: 4.091658 , acc is: 0.046875 , iter= 6065
current loss is: 4.15257 , acc is: 0.046875 , iter= 6066
current loss is: 4.0205045 , acc is: 0.0625 , iter= 6067
current loss is: 4.1544247 , acc is: 0.03125 , iter= 6068
current loss is: 4.083701 , acc is: 0.03125 , iter= 6069
current loss is: 4.021499 , acc is: 0.03125 , iter= 6070
current loss is: 4.1216984 , acc is: 0.015625 , iter= 6071
current loss is: 4.109606 , acc is: 0.046875 , iter= 6072
current loss is: 4.003397 , acc is: 0.046875 , iter= 6073
current loss is: 4.0873756 , acc is: 0.046875 , iter= 6074
current loss is: 4.1550617 , acc is: 0.015625 , iter= 6075
current loss is: 4.0775466 , acc is: 0.03125 , iter= 6076
current loss is: 4.1192236 , acc is: 0.0 , iter= 6077
current loss is: 4.1803102 , acc is: 0.0 , iter= 6078
current loss is: 4.1233954 , acc is: 0.0625 , iter= 6079
current loss is: 4.1098757 , acc is: 0.015625 , iter= 6080
current loss is: 4.1524744 , acc is: 0.03125 , iter= 6081
current loss is: 4.0527105 , acc is: 0.046875 , iter= 6082
current loss is: 4.1884346 , acc is: 0.015625 , iter= 6083
current loss is: 4.045121 , acc is: 0.046875 , iter= 6084
current loss is: 4.147382 , acc is: 0.015625 , iter= 6085
current loss is: 4.1112967 , acc is: 0.046875 , iter= 6086
current loss is: 3.9198349 , acc is: 0.078125 , iter= 6087
current loss is: 4.1140842 , acc is: 0.046875 , iter= 6088
current loss is: 4.0973296 , acc is: 0.0625 , iter= 6089
current loss is: 4.170525 , acc is: 0.015625 , iter= 6090
current loss is: 4.132309 , acc is: 0.015625 , iter= 6091
current loss is: 3.9711237 , acc is: 0.03125 , iter= 6092
current loss is: 4.0693874 , acc is: 0.015625 , iter= 6093
current loss is: 4.13943 , acc is: 0.0 , iter= 6094
current loss is: 3.9398007 , acc is: 0.0625 , iter= 6095
current loss is: 4.0114193 , acc is: 0.0625 , iter= 6096
current loss is: 4.0086565 , acc is: 0.09375 , iter= 6097
current loss is: 4.13017 , acc is: 0.0 , iter= 6098
current loss is: 4.153472 , acc is: 0.015625 , iter= 6099
current loss is: 4.1552567 , acc is: 0.015625 , iter= 6100
current loss is: 4.043196 , acc is: 0.03125 , iter= 6101
current loss is: 4.123827 , acc is: 0.046875 , iter= 6102
current loss is: 4.152709 , acc is: 0.0 , iter= 6103
current loss is: 4.017164 , acc is: 0.03125 , iter= 6104
current loss is: 4.1488347 , acc is: 0.0 , iter= 6105
current loss is: 4.1709623 , acc is: 0.015625 , iter= 6106
current loss is: 4.0623198 , acc is: 0.046875 , iter= 6107
current loss is: 4.0787945 , acc is: 0.046875 , iter= 6108
current loss is: 5.798312 , acc is: 0.0 , iter= 6109
current loss is: 4.1378174 , acc is: 0.015625 , iter= 6110
current loss is: 4.1822457 , acc is: 0.0 , iter= 6111
current loss is: 4.1257257 , acc is: 0.0 , iter= 6112
current loss is: 3.9652843 , acc is: 0.0625 , iter= 6113
current loss is: 4.0342436 , acc is: 0.03125 , iter= 6114
current loss is: 4.0192275 , acc is: 0.046875 , iter= 6115
current loss is: 4.16502 , acc is: 0.0 , iter= 6116
current loss is: 4.062191 , acc is: 0.046875 , iter= 6117
current loss is: 4.050436 , acc is: 0.0625 , iter= 6118
current loss is: 4.1218157 , acc is: 0.0 , iter= 6119
current loss is: 3.9837203 , acc is: 0.03125 , iter= 6120
current loss is: 4.0729704 , acc is: 0.046875 , iter= 6121
current loss is: 4.0511036 , acc is: 0.0625 , iter= 6122
current loss is: 4.0330935 , acc is: 0.046875 , iter= 6123
current loss is: 4.111231 , acc is: 0.015625 , iter= 6124
current loss is: 4.108317 , acc is: 0.03125 , iter= 6125
current loss is: 4.1383705 , acc is: 0.015625 , iter= 6126
current loss is: 4.096746 , acc is: 0.015625 , iter= 6127
current loss is: 4.1599607 , acc is: 0.015625 , iter= 6128
current loss is: 4.015765 , acc is: 0.046875 , iter= 6129
current loss is: 4.1028175 , acc is: 0.015625 , iter= 6130
current loss is: 4.0329204 , acc is: 0.0625 , iter= 6131
current loss is: 4.1107807 , acc is: 0.015625 , iter= 6132
current loss is: 4.082486 , acc is: 0.015625 , iter= 6133
current loss is: 4.0619583 , acc is: 0.03125 , iter= 6134
current loss is: 4.08626 , acc is: 0.046875 , iter= 6135
current loss is: 4.105485 , acc is: 0.015625 , iter= 6136
current loss is: 4.1622705 , acc is: 0.03125 , iter= 6137
current loss is: 4.062413 , acc is: 0.03125 , iter= 6138
current loss is: 4.0282946 , acc is: 0.03125 , iter= 6139
current loss is: 4.012282 , acc is: 0.046875 , iter= 6140
current loss is: 4.107372 , acc is: 0.03125 , iter= 6141
current loss is: 4.032329 , acc is: 0.046875 , iter= 6142
current loss is: 4.0697255 , acc is: 0.0625 , iter= 6143
current loss is: 4.6319504 , acc is: 0.0 , iter= 6144
current loss is: 4.070085 , acc is: 0.03125 , iter= 6145
current loss is: 4.0869207 , acc is: 0.0625 , iter= 6146
current loss is: 4.087332 , acc is: 0.015625 , iter= 6147
current loss is: 4.0958433 , acc is: 0.046875 , iter= 6148
current loss is: 4.114416 , acc is: 0.0625 , iter= 6149
current loss is: 4.1862245 , acc is: 0.015625 , iter= 6150
current loss is: 4.1427975 , acc is: 0.03125 , iter= 6151
current loss is: 4.09256 , acc is: 0.03125 , iter= 6152
current loss is: 4.123068 , acc is: 0.015625 , iter= 6153
current loss is: 4.1483364 , acc is: 0.03125 , iter= 6154
current loss is: 4.119507 , acc is: 0.0625 , iter= 6155
current loss is: 4.1317787 , acc is: 0.0 , iter= 6156
current loss is: 4.153252 , acc is: 0.03125 , iter= 6157
current loss is: 4.1751723 , acc is: 0.0 , iter= 6158
current loss is: 4.07551 , acc is: 0.046875 , iter= 6159
current loss is: 4.029255 , acc is: 0.046875 , iter= 6160
current loss is: 4.1841145 , acc is: 0.0 , iter= 6161
current loss is: 4.163841 , acc is: 0.0 , iter= 6162
current loss is: 4.1298227 , acc is: 0.0625 , iter= 6163
current loss is: 4.0725193 , acc is: 0.03125 , iter= 6164
current loss is: 4.118046 , acc is: 0.03125 , iter= 6165
current loss is: 4.098092 , acc is: 0.046875 , iter= 6166
current loss is: 4.1264257 , acc is: 0.03125 , iter= 6167
current loss is: 4.025163 , acc is: 0.03125 , iter= 6168
current loss is: 4.144099 , acc is: 0.03125 , iter= 6169
current loss is: 4.1587806 , acc is: 0.015625 , iter= 6170
current loss is: 4.0809436 , acc is: 0.046875 , iter= 6171
current loss is: 4.0844793 , acc is: 0.015625 , iter= 6172
current loss is: 4.1387987 , acc is: 0.03125 , iter= 6173
current loss is: 4.1255026 , acc is: 0.015625 , iter= 6174
current loss is: 4.0714645 , acc is: 0.03125 , iter= 6175
current loss is: 4.028404 , acc is: 0.015625 , iter= 6176
current loss is: 4.1792717 , acc is: 0.015625 , iter= 6177
current loss is: 4.0080624 , acc is: 0.0625 , iter= 6178
current loss is: 3.928131 , acc is: 0.078125 , iter= 6179
current loss is: 4.085708 , acc is: 0.046875 , iter= 6180
current loss is: 4.1517515 , acc is: 0.015625 , iter= 6181
current loss is: 4.0159793 , acc is: 0.046875 , iter= 6182
current loss is: 3.9950547 , acc is: 0.078125 , iter= 6183
current loss is: 4.0477476 , acc is: 0.0625 , iter= 6184
current loss is: 4.0633254 , acc is: 0.03125 , iter= 6185
current loss is: 4.1115804 , acc is: 0.015625 , iter= 6186
current loss is: 4.0983515 , acc is: 0.015625 , iter= 6187
current loss is: 4.0858316 , acc is: 0.0625 , iter= 6188
current loss is: 4.1741 , acc is: 0.015625 , iter= 6189
current loss is: 4.1331143 , acc is: 0.0 , iter= 6190
current loss is: 4.0111895 , acc is: 0.046875 , iter= 6191
current loss is: 4.104048 , acc is: 0.015625 , iter= 6192
current loss is: 3.95652 , acc is: 0.0625 , iter= 6193
current loss is: 4.053653 , acc is: 0.0625 , iter= 6194
current loss is: 4.0968037 , acc is: 0.015625 , iter= 6195
current loss is: 4.0119944 , acc is: 0.046875 , iter= 6196
current loss is: 3.9223478 , acc is: 0.0625 , iter= 6197
current loss is: 4.031955 , acc is: 0.078125 , iter= 6198
current loss is: 4.179052 , acc is: 0.0 , iter= 6199
current loss is: 4.0366497 , acc is: 0.03125 , iter= 6200
current loss is: 4.073325 , acc is: 0.046875 , iter= 6201
current loss is: 4.0696297 , acc is: 0.015625 , iter= 6202
current loss is: 4.175663 , acc is: 0.015625 , iter= 6203
current loss is: 4.208504 , acc is: 0.015625 , iter= 6204
current loss is: 4.0987115 , acc is: 0.015625 , iter= 6205
current loss is: 3.9216194 , acc is: 0.0625 , iter= 6206
current loss is: 4.160215 , acc is: 0.0 , iter= 6207
current loss is: 4.138912 , acc is: 0.03125 , iter= 6208
current loss is: 3.982283 , acc is: 0.046875 , iter= 6209
current loss is: 3.9927754 , acc is: 0.046875 , iter= 6210
current loss is: 4.0949564 , acc is: 0.046875 , iter= 6211
current loss is: 4.110787 , acc is: 0.015625 , iter= 6212
current loss is: 4.0944357 , acc is: 0.046875 , iter= 6213
current loss is: 4.1438246 , acc is: 0.03125 , iter= 6214
current loss is: 4.105792 , acc is: 0.03125 , iter= 6215
current loss is: 4.059654 , acc is: 0.046875 , iter= 6216
current loss is: 4.207439 , acc is: 0.0 , iter= 6217
current loss is: 4.0757694 , acc is: 0.015625 , iter= 6218
current loss is: 3.9338026 , acc is: 0.0625 , iter= 6219
current loss is: 4.140393 , acc is: 0.015625 , iter= 6220
current loss is: 4.121485 , acc is: 0.015625 , iter= 6221
current loss is: 4.0544677 , acc is: 0.046875 , iter= 6222
current loss is: 4.058615 , acc is: 0.0625 , iter= 6223
current loss is: 4.099634 , acc is: 0.03125 , iter= 6224
current loss is: 4.1501904 , acc is: 0.0 , iter= 6225
current loss is: 3.9598184 , acc is: 0.078125 , iter= 6226
current loss is: 4.010157 , acc is: 0.0625 , iter= 6227
current loss is: 4.025693 , acc is: 0.046875 , iter= 6228
current loss is: 4.064041 , acc is: 0.0625 , iter= 6229
current loss is: 4.083787 , acc is: 0.0 , iter= 6230
current loss is: 4.1119905 , acc is: 0.015625 , iter= 6231
current loss is: 4.132373 , acc is: 0.0 , iter= 6232
current loss is: 4.0292897 , acc is: 0.03125 , iter= 6233
current loss is: 4.0922804 , acc is: 0.03125 , iter= 6234
current loss is: 3.9796169 , acc is: 0.046875 , iter= 6235
current loss is: 4.0804467 , acc is: 0.03125 , iter= 6236
current loss is: 4.153324 , acc is: 0.015625 , iter= 6237
current loss is: 4.0059776 , acc is: 0.0625 , iter= 6238
current loss is: 4.095744 , acc is: 0.046875 , iter= 6239
current loss is: 4.1426477 , acc is: 0.03125 , iter= 6240
current loss is: 4.059491 , acc is: 0.0625 , iter= 6241
current loss is: 4.124471 , acc is: 0.015625 , iter= 6242
current loss is: 4.082762 , acc is: 0.046875 , iter= 6243
current loss is: 4.088378 , acc is: 0.03125 , iter= 6244
current loss is: 4.1088686 , acc is: 0.0 , iter= 6245
current loss is: 4.1564245 , acc is: 0.0 , iter= 6246
current loss is: 4.0470324 , acc is: 0.046875 , iter= 6247
current loss is: 4.1955614 , acc is: 0.046875 , iter= 6248
current loss is: 4.073456 , acc is: 0.015625 , iter= 6249
current loss is: 4.0270414 , acc is: 0.046875 , iter= 6250
current loss is: 4.0701933 , acc is: 0.0625 , iter= 6251
current loss is: 4.113519 , acc is: 0.0 , iter= 6252
current loss is: 4.1018586 , acc is: 0.0 , iter= 6253
current loss is: 4.1490364 , acc is: 0.015625 , iter= 6254
current loss is: 4.0786715 , acc is: 0.046875 , iter= 6255
current loss is: 4.135001 , acc is: 0.03125 , iter= 6256
current loss is: 4.0531073 , acc is: 0.0625 , iter= 6257
current loss is: 3.9920673 , acc is: 0.078125 , iter= 6258
current loss is: 4.0838995 , acc is: 0.078125 , iter= 6259
current loss is: 4.1360226 , acc is: 0.0 , iter= 6260
current loss is: 4.0845323 , acc is: 0.015625 , iter= 6261
current loss is: 4.140625 , acc is: 0.015625 , iter= 6262
current loss is: 4.1407447 , acc is: 0.0 , iter= 6263
current loss is: 4.066827 , acc is: 0.03125 , iter= 6264
current loss is: 4.1522627 , acc is: 0.015625 , iter= 6265
current loss is: 3.922761 , acc is: 0.09375 , iter= 6266
current loss is: 4.028299 , acc is: 0.046875 , iter= 6267
current loss is: 4.00352 , acc is: 0.09375 , iter= 6268
current loss is: 4.1501045 , acc is: 0.015625 , iter= 6269
current loss is: 4.2056303 , acc is: 0.0 , iter= 6270
current loss is: 4.0935397 , acc is: 0.03125 , iter= 6271
current loss is: 4.1201506 , acc is: 0.015625 , iter= 6272
current loss is: 4.0776906 , acc is: 0.03125 , iter= 6273
current loss is: 4.1898403 , acc is: 0.015625 , iter= 6274
current loss is: 4.108572 , acc is: 0.046875 , iter= 6275
current loss is: 3.945372 , acc is: 0.078125 , iter= 6276
current loss is: 4.0255976 , acc is: 0.0625 , iter= 6277
current loss is: 4.0336766 , acc is: 0.0625 , iter= 6278
current loss is: 4.097465 , acc is: 0.03125 , iter= 6279
current loss is: 3.9692192 , acc is: 0.0625 , iter= 6280
current loss is: 4.176675 , acc is: 0.0 , iter= 6281
current loss is: 4.088026 , acc is: 0.03125 , iter= 6282
current loss is: 3.9185953 , acc is: 0.0625 , iter= 6283
current loss is: 4.169943 , acc is: 0.015625 , iter= 6284
current loss is: 4.135174 , acc is: 0.015625 , iter= 6285
current loss is: 4.0740952 , acc is: 0.03125 , iter= 6286
current loss is: 4.082455 , acc is: 0.046875 , iter= 6287
current loss is: 4.099395 , acc is: 0.046875 , iter= 6288
current loss is: 4.153352 , acc is: 0.03125 , iter= 6289
current loss is: 4.1337433 , acc is: 0.046875 , iter= 6290
current loss is: 4.126619 , acc is: 0.015625 , iter= 6291
current loss is: 4.0543423 , acc is: 0.03125 , iter= 6292
current loss is: 4.1323605 , acc is: 0.015625 , iter= 6293
current loss is: 3.9441385 , acc is: 0.078125 , iter= 6294
current loss is: 4.076844 , acc is: 0.046875 , iter= 6295
current loss is: 4.017099 , acc is: 0.078125 , iter= 6296
current loss is: 4.185893 , acc is: 0.03125 , iter= 6297
current loss is: 4.1199355 , acc is: 0.015625 , iter= 6298
current loss is: 4.0926576 , acc is: 0.046875 , iter= 6299
current loss is: 4.041383 , acc is: 0.03125 , iter= 6300
current loss is: 4.1539755 , acc is: 0.015625 , iter= 6301
current loss is: 4.120597 , acc is: 0.015625 , iter= 6302
current loss is: 4.051009 , acc is: 0.046875 , iter= 6303
current loss is: 4.0437326 , acc is: 0.03125 , iter= 6304
current loss is: 4.0579734 , acc is: 0.0625 , iter= 6305
current loss is: 4.1064796 , acc is: 0.03125 , iter= 6306
current loss is: 4.045249 , acc is: 0.0625 , iter= 6307
current loss is: 4.087655 , acc is: 0.0625 , iter= 6308
current loss is: 4.05145 , acc is: 0.03125 , iter= 6309
current loss is: 4.0901003 , acc is: 0.03125 , iter= 6310
current loss is: 4.0220737 , acc is: 0.03125 , iter= 6311
current loss is: 4.1469917 , acc is: 0.03125 , iter= 6312
current loss is: 4.154558 , acc is: 0.046875 , iter= 6313
current loss is: 4.00375 , acc is: 0.09375 , iter= 6314
current loss is: 4.210969 , acc is: 0.0 , iter= 6315
current loss is: 4.0356627 , acc is: 0.046875 , iter= 6316
current loss is: 4.072072 , acc is: 0.046875 , iter= 6317
current loss is: 4.085824 , acc is: 0.046875 , iter= 6318
current loss is: 4.078141 , acc is: 0.03125 , iter= 6319
current loss is: 4.1103077 , acc is: 0.03125 , iter= 6320
current loss is: 4.067349 , acc is: 0.0625 , iter= 6321
current loss is: 4.0306206 , acc is: 0.046875 , iter= 6322
current loss is: 3.9906077 , acc is: 0.046875 , iter= 6323
current loss is: 4.080112 , acc is: 0.015625 , iter= 6324
current loss is: 3.9952402 , acc is: 0.078125 , iter= 6325
current loss is: 4.1412134 , acc is: 0.0 , iter= 6326
current loss is: 4.0643544 , acc is: 0.015625 , iter= 6327
current loss is: 4.10647 , acc is: 0.015625 , iter= 6328
current loss is: 4.1188984 , acc is: 0.015625 , iter= 6329
current loss is: 4.127355 , acc is: 0.0 , iter= 6330
current loss is: 4.136676 , acc is: 0.0 , iter= 6331
current loss is: 4.023223 , acc is: 0.0625 , iter= 6332
current loss is: 4.0898495 , acc is: 0.03125 , iter= 6333
current loss is: 4.118784 , acc is: 0.046875 , iter= 6334
current loss is: 4.0528436 , acc is: 0.0625 , iter= 6335
current loss is: 4.079677 , acc is: 0.015625 , iter= 6336
current loss is: 4.1325674 , acc is: 0.015625 , iter= 6337
current loss is: 4.068324 , acc is: 0.03125 , iter= 6338
current loss is: 4.1356726 , acc is: 0.03125 , iter= 6339
current loss is: 4.171529 , acc is: 0.015625 , iter= 6340
current loss is: 4.0254316 , acc is: 0.0625 , iter= 6341
current loss is: 4.0867386 , acc is: 0.015625 , iter= 6342
current loss is: 4.0425844 , acc is: 0.046875 , iter= 6343
current loss is: 4.122019 , acc is: 0.03125 , iter= 6344
current loss is: 4.081129 , acc is: 0.03125 , iter= 6345
current loss is: 4.0432434 , acc is: 0.0625 , iter= 6346
current loss is: 4.1319556 , acc is: 0.015625 , iter= 6347
current loss is: 4.143438 , acc is: 0.0 , iter= 6348
current loss is: 4.019367 , acc is: 0.046875 , iter= 6349
current loss is: 3.9970124 , acc is: 0.078125 , iter= 6350
current loss is: 4.014242 , acc is: 0.03125 , iter= 6351
current loss is: 4.12086 , acc is: 0.015625 , iter= 6352
current loss is: 4.070635 , acc is: 0.03125 , iter= 6353
current loss is: 4.0650945 , acc is: 0.015625 , iter= 6354
current loss is: 4.0497327 , acc is: 0.0625 , iter= 6355
current loss is: 4.096902 , acc is: 0.046875 , iter= 6356
current loss is: 4.1995583 , acc is: 0.03125 , iter= 6357
current loss is: 4.189488 , acc is: 0.0 , iter= 6358
current loss is: 4.113929 , acc is: 0.046875 , iter= 6359
current loss is: 4.1388516 , acc is: 0.015625 , iter= 6360
current loss is: 4.152912 , acc is: 0.015625 , iter= 6361
current loss is: 4.0334396 , acc is: 0.03125 , iter= 6362
current loss is: 4.087351 , acc is: 0.015625 , iter= 6363
current loss is: 4.128764 , acc is: 0.03125 , iter= 6364
current loss is: 4.100648 , acc is: 0.015625 , iter= 6365
current loss is: 3.9915752 , acc is: 0.03125 , iter= 6366
current loss is: 4.124228 , acc is: 0.03125 , iter= 6367
current loss is: 4.077091 , acc is: 0.0625 , iter= 6368
current loss is: 3.9728909 , acc is: 0.046875 , iter= 6369
current loss is: 4.0878224 , acc is: 0.015625 , iter= 6370
current loss is: 4.0332246 , acc is: 0.0625 , iter= 6371
current loss is: 4.1252184 , acc is: 0.015625 , iter= 6372
current loss is: 3.9985497 , acc is: 0.0625 , iter= 6373
current loss is: 4.079837 , acc is: 0.046875 , iter= 6374
current loss is: 4.076768 , acc is: 0.03125 , iter= 6375
current loss is: 4.012076 , acc is: 0.046875 , iter= 6376
current loss is: 3.9565632 , acc is: 0.09375 , iter= 6377
current loss is: 4.0200353 , acc is: 0.078125 , iter= 6378
current loss is: 4.015256 , acc is: 0.0625 , iter= 6379
current loss is: 4.1433344 , acc is: 0.015625 , iter= 6380
current loss is: 4.0763845 , acc is: 0.078125 , iter= 6381
current loss is: 4.150761 , acc is: 0.0 , iter= 6382
current loss is: 3.9940357 , acc is: 0.046875 , iter= 6383
current loss is: 4.196854 , acc is: 0.015625 , iter= 6384
current loss is: 4.1380873 , acc is: 0.015625 , iter= 6385
current loss is: 4.118169 , acc is: 0.046875 , iter= 6386
current loss is: 4.132271 , acc is: 0.03125 , iter= 6387
current loss is: 4.074466 , acc is: 0.046875 , iter= 6388
current loss is: 4.104188 , acc is: 0.015625 , iter= 6389
current loss is: 4.1821795 , acc is: 0.046875 , iter= 6390
current loss is: 4.156881 , acc is: 0.015625 , iter= 6391
current loss is: 4.001289 , acc is: 0.046875 , iter= 6392
current loss is: 4.16082 , acc is: 0.03125 , iter= 6393
current loss is: 4.1059504 , acc is: 0.03125 , iter= 6394
current loss is: 4.1483364 , acc is: 0.0 , iter= 6395
current loss is: 3.9572883 , acc is: 0.0625 , iter= 6396
current loss is: 3.986397 , acc is: 0.03125 , iter= 6397
current loss is: 4.1668286 , acc is: 0.015625 , iter= 6398
current loss is: 4.0864115 , acc is: 0.015625 , iter= 6399
current loss is: 4.0856094 , acc is: 0.046875 , iter= 6400
current loss is: 4.062331 , acc is: 0.03125 , iter= 6401
current loss is: 3.9326773 , acc is: 0.078125 , iter= 6402
current loss is: 3.9939392 , acc is: 0.0625 , iter= 6403
current loss is: 4.131855 , acc is: 0.0 , iter= 6404
current loss is: 4.191945 , acc is: 0.015625 , iter= 6405
current loss is: 4.1142917 , acc is: 0.03125 , iter= 6406
current loss is: 4.095319 , acc is: 0.0 , iter= 6407
current loss is: 4.114345 , acc is: 0.015625 , iter= 6408
current loss is: 4.0902014 , acc is: 0.0 , iter= 6409
current loss is: 3.9912493 , acc is: 0.03125 , iter= 6410
current loss is: 4.0755467 , acc is: 0.03125 , iter= 6411
current loss is: 4.0975075 , acc is: 0.03125 , iter= 6412
current loss is: 3.9496102 , acc is: 0.109375 , iter= 6413
current loss is: 4.12994 , acc is: 0.0 , iter= 6414
current loss is: 4.0069885 , acc is: 0.046875 , iter= 6415
current loss is: 4.061887 , acc is: 0.046875 , iter= 6416
current loss is: 3.9280658 , acc is: 0.09375 , iter= 6417
current loss is: 4.085489 , acc is: 0.03125 , iter= 6418
current loss is: 4.0746393 , acc is: 0.03125 , iter= 6419
current loss is: 4.087585 , acc is: 0.015625 , iter= 6420
current loss is: 4.12345 , acc is: 0.046875 , iter= 6421
current loss is: 4.1146364 , acc is: 0.03125 , iter= 6422
current loss is: 4.0081787 , acc is: 0.0625 , iter= 6423
current loss is: 3.966073 , acc is: 0.09375 , iter= 6424
current loss is: 4.1394777 , acc is: 0.046875 , iter= 6425
current loss is: 4.0637617 , acc is: 0.03125 , iter= 6426
current loss is: 4.0762663 , acc is: 0.03125 , iter= 6427
current loss is: 4.1606436 , acc is: 0.03125 , iter= 6428
current loss is: 4.0466137 , acc is: 0.046875 , iter= 6429
current loss is: 4.1233964 , acc is: 0.03125 , iter= 6430
current loss is: 4.1267843 , acc is: 0.015625 , iter= 6431
current loss is: 4.113221 , acc is: 0.015625 , iter= 6432
current loss is: 4.1530786 , acc is: 0.03125 , iter= 6433
current loss is: 4.178204 , acc is: 0.015625 , iter= 6434
current loss is: 4.0953016 , acc is: 0.015625 , iter= 6435
current loss is: 4.171772 , acc is: 0.015625 , iter= 6436
current loss is: 4.058611 , acc is: 0.03125 , iter= 6437
current loss is: 4.0888715 , acc is: 0.03125 , iter= 6438
current loss is: 4.0715857 , acc is: 0.03125 , iter= 6439
current loss is: 4.1563816 , acc is: 0.03125 , iter= 6440
current loss is: 4.1434994 , acc is: 0.0625 , iter= 6441
current loss is: 4.096533 , acc is: 0.03125 , iter= 6442
current loss is: 4.0101523 , acc is: 0.046875 , iter= 6443
current loss is: 4.0165286 , acc is: 0.0625 , iter= 6444
current loss is: 4.0214314 , acc is: 0.03125 , iter= 6445
current loss is: 4.1820965 , acc is: 0.03125 , iter= 6446
current loss is: 4.09911 , acc is: 0.046875 , iter= 6447
current loss is: 4.120883 , acc is: 0.03125 , iter= 6448
current loss is: 4.105133 , acc is: 0.03125 , iter= 6449
current loss is: 4.041523 , acc is: 0.03125 , iter= 6450
current loss is: 4.190694 , acc is: 0.015625 , iter= 6451
current loss is: 4.1331615 , acc is: 0.015625 , iter= 6452
current loss is: 3.9853082 , acc is: 0.046875 , iter= 6453
current loss is: 3.8482935 , acc is: 0.109375 , iter= 6454
current loss is: 4.1293693 , acc is: 0.015625 , iter= 6455
current loss is: 4.109645 , acc is: 0.046875 , iter= 6456
current loss is: 4.155519 , acc is: 0.0 , iter= 6457
current loss is: 4.0932665 , acc is: 0.046875 , iter= 6458
current loss is: 4.115176 , acc is: 0.0625 , iter= 6459
current loss is: 4.035062 , acc is: 0.0625 , iter= 6460
current loss is: 4.076951 , acc is: 0.015625 , iter= 6461
current loss is: 4.076552 , acc is: 0.03125 , iter= 6462
current loss is: 3.939315 , acc is: 0.078125 , iter= 6463
current loss is: 4.135124 , acc is: 0.046875 , iter= 6464
current loss is: 4.192442 , acc is: 0.03125 , iter= 6465
current loss is: 3.98067 , acc is: 0.0625 , iter= 6466
current loss is: 4.128442 , acc is: 0.015625 , iter= 6467
current loss is: 3.98816 , acc is: 0.046875 , iter= 6468
current loss is: 4.1566277 , acc is: 0.015625 , iter= 6469
current loss is: 3.8547692 , acc is: 0.078125 , iter= 6470
current loss is: 4.038764 , acc is: 0.03125 , iter= 6471
current loss is: 4.1286597 , acc is: 0.015625 , iter= 6472
current loss is: 4.1669703 , acc is: 0.0 , iter= 6473
current loss is: 4.1600485 , acc is: 0.03125 , iter= 6474
current loss is: 4.0238633 , acc is: 0.0625 , iter= 6475
current loss is: 3.9890184 , acc is: 0.046875 , iter= 6476
current loss is: 4.1174555 , acc is: 0.0625 , iter= 6477
current loss is: 4.02034 , acc is: 0.015625 , iter= 6478
current loss is: 3.961211 , acc is: 0.046875 , iter= 6479
current loss is: 4.0741587 , acc is: 0.015625 , iter= 6480
current loss is: 4.1394587 , acc is: 0.03125 , iter= 6481
current loss is: 4.050328 , acc is: 0.046875 , iter= 6482
current loss is: 4.117973 , acc is: 0.015625 , iter= 6483
current loss is: 4.1347313 , acc is: 0.015625 , iter= 6484
current loss is: 4.137295 , acc is: 0.046875 , iter= 6485
current loss is: 4.1481895 , acc is: 0.015625 , iter= 6486
current loss is: 4.0095606 , acc is: 0.046875 , iter= 6487
current loss is: 4.0336294 , acc is: 0.03125 , iter= 6488
current loss is: 4.1244926 , acc is: 0.015625 , iter= 6489
current loss is: 4.1684613 , acc is: 0.0625 , iter= 6490
current loss is: 4.147071 , acc is: 0.015625 , iter= 6491
current loss is: 4.090316 , acc is: 0.046875 , iter= 6492
current loss is: 4.171447 , acc is: 0.0 , iter= 6493
current loss is: 4.0907683 , acc is: 0.015625 , iter= 6494
current loss is: 4.1607447 , acc is: 0.03125 , iter= 6495
current loss is: 3.9399805 , acc is: 0.078125 , iter= 6496
current loss is: 4.164362 , acc is: 0.015625 , iter= 6497
current loss is: 4.145563 , acc is: 0.015625 , iter= 6498
current loss is: 4.10951 , acc is: 0.046875 , iter= 6499
current loss is: 4.1075897 , acc is: 0.03125 , iter= 6500
current loss is: 4.123296 , acc is: 0.03125 , iter= 6501
current loss is: 4.0087385 , acc is: 0.03125 , iter= 6502
current loss is: 4.1644006 , acc is: 0.015625 , iter= 6503
current loss is: 4.0323725 , acc is: 0.03125 , iter= 6504
current loss is: 4.1246433 , acc is: 0.015625 , iter= 6505
current loss is: 3.9175014 , acc is: 0.078125 , iter= 6506
current loss is: 4.131175 , acc is: 0.0 , iter= 6507
current loss is: 4.079212 , acc is: 0.03125 , iter= 6508
current loss is: 3.9705758 , acc is: 0.078125 , iter= 6509
current loss is: 4.0756326 , acc is: 0.0625 , iter= 6510
current loss is: 4.0385613 , acc is: 0.046875 , iter= 6511
current loss is: 4.1814117 , acc is: 0.0 , iter= 6512
current loss is: 4.1157045 , acc is: 0.046875 , iter= 6513
current loss is: 4.1982694 , acc is: 0.015625 , iter= 6514
current loss is: 4.1306124 , acc is: 0.015625 , iter= 6515
current loss is: 4.143858 , acc is: 0.0 , iter= 6516
current loss is: 4.099513 , acc is: 0.046875 , iter= 6517
current loss is: 3.960442 , acc is: 0.046875 , iter= 6518
current loss is: 4.1456575 , acc is: 0.03125 , iter= 6519
current loss is: 4.0926476 , acc is: 0.03125 , iter= 6520
current loss is: 4.1446667 , acc is: 0.046875 , iter= 6521
current loss is: 4.089726 , acc is: 0.046875 , iter= 6522
current loss is: 4.2231383 , acc is: 0.0 , iter= 6523
current loss is: 4.144946 , acc is: 0.015625 , iter= 6524
current loss is: 4.056128 , acc is: 0.03125 , iter= 6525
current loss is: 4.0910907 , acc is: 0.03125 , iter= 6526
current loss is: 4.037183 , acc is: 0.078125 , iter= 6527
current loss is: 4.0456867 , acc is: 0.03125 , iter= 6528
current loss is: 4.0213423 , acc is: 0.03125 , iter= 6529
current loss is: 4.089257 , acc is: 0.015625 , iter= 6530
current loss is: 3.9951289 , acc is: 0.03125 , iter= 6531
current loss is: 3.9736502 , acc is: 0.09375 , iter= 6532
current loss is: 4.137836 , acc is: 0.03125 , iter= 6533
current loss is: 4.173687 , acc is: 0.015625 , iter= 6534
current loss is: 4.073751 , acc is: 0.03125 , iter= 6535
current loss is: 3.9737878 , acc is: 0.03125 , iter= 6536
current loss is: 3.9519327 , acc is: 0.0625 , iter= 6537
current loss is: 4.186509 , acc is: 0.0 , iter= 6538
current loss is: 4.068776 , acc is: 0.046875 , iter= 6539
current loss is: 4.175234 , acc is: 0.0 , iter= 6540
current loss is: 3.9910774 , acc is: 0.046875 , iter= 6541
current loss is: 3.9491134 , acc is: 0.09375 , iter= 6542
current loss is: 4.1032524 , acc is: 0.03125 , iter= 6543
current loss is: 4.0669227 , acc is: 0.046875 , iter= 6544
current loss is: 4.110855 , acc is: 0.015625 , iter= 6545
current loss is: 4.160121 , acc is: 0.0 , iter= 6546
current loss is: 4.138131 , acc is: 0.015625 , iter= 6547
current loss is: 4.1507344 , acc is: 0.015625 , iter= 6548
current loss is: 4.0469494 , acc is: 0.03125 , iter= 6549
current loss is: 4.1267614 , acc is: 0.0 , iter= 6550
current loss is: 4.080551 , acc is: 0.03125 , iter= 6551
current loss is: 4.1420527 , acc is: 0.015625 , iter= 6552
current loss is: 4.0908117 , acc is: 0.0625 , iter= 6553
current loss is: 3.9693692 , acc is: 0.0625 , iter= 6554
current loss is: 4.0626135 , acc is: 0.015625 , iter= 6555
current loss is: 3.977501 , acc is: 0.0625 , iter= 6556
current loss is: 4.1343794 , acc is: 0.0 , iter= 6557
current loss is: 3.9760344 , acc is: 0.0625 , iter= 6558
current loss is: 4.0053406 , acc is: 0.078125 , iter= 6559
current loss is: 4.1012077 , acc is: 0.015625 , iter= 6560
current loss is: 4.1131334 , acc is: 0.03125 , iter= 6561
current loss is: 4.147295 , acc is: 0.03125 , iter= 6562
current loss is: 4.1591444 , acc is: 0.046875 , iter= 6563
current loss is: 4.1530404 , acc is: 0.0 , iter= 6564
current loss is: 4.0982294 , acc is: 0.03125 , iter= 6565
current loss is: 4.019548 , acc is: 0.0625 , iter= 6566
current loss is: 4.1853805 , acc is: 0.015625 , iter= 6567
current loss is: 4.165821 , acc is: 0.03125 , iter= 6568
current loss is: 4.0929623 , acc is: 0.015625 , iter= 6569
current loss is: 4.1842585 , acc is: 0.015625 , iter= 6570
current loss is: 4.174116 , acc is: 0.0 , iter= 6571
current loss is: 3.9554737 , acc is: 0.0625 , iter= 6572
current loss is: 4.0661874 , acc is: 0.046875 , iter= 6573
current loss is: 4.1187954 , acc is: 0.03125 , iter= 6574
current loss is: 4.0057855 , acc is: 0.046875 , iter= 6575
current loss is: 4.1901712 , acc is: 0.03125 , iter= 6576
current loss is: 4.019675 , acc is: 0.046875 , iter= 6577
current loss is: 4.0402575 , acc is: 0.015625 , iter= 6578
current loss is: 4.1600003 , acc is: 0.078125 , iter= 6579
current loss is: 4.035923 , acc is: 0.03125 , iter= 6580
current loss is: 3.858222 , acc is: 0.0625 , iter= 6581
current loss is: 4.030384 , acc is: 0.03125 , iter= 6582
current loss is: 4.1456957 , acc is: 0.046875 , iter= 6583
current loss is: 3.995453 , acc is: 0.0625 , iter= 6584
current loss is: 4.131419 , acc is: 0.015625 , iter= 6585
current loss is: 4.0588593 , acc is: 0.046875 , iter= 6586
current loss is: 4.098759 , acc is: 0.03125 , iter= 6587
current loss is: 4.0443535 , acc is: 0.078125 , iter= 6588
current loss is: 4.1419168 , acc is: 0.03125 , iter= 6589
current loss is: 4.143512 , acc is: 0.03125 , iter= 6590
current loss is: 4.1494265 , acc is: 0.015625 , iter= 6591
current loss is: 4.081709 , acc is: 0.03125 , iter= 6592
current loss is: 4.1592026 , acc is: 0.0 , iter= 6593
current loss is: 4.0870647 , acc is: 0.03125 , iter= 6594
current loss is: 4.0591364 , acc is: 0.046875 , iter= 6595
current loss is: 3.9616718 , acc is: 0.046875 , iter= 6596
current loss is: 4.1139393 , acc is: 0.015625 , iter= 6597
current loss is: 4.2077093 , acc is: 0.0 , iter= 6598
current loss is: 3.9955666 , acc is: 0.078125 , iter= 6599
current loss is: 4.056775 , acc is: 0.03125 , iter= 6600
current loss is: 4.0345993 , acc is: 0.046875 , iter= 6601
current loss is: 4.0724754 , acc is: 0.03125 , iter= 6602
current loss is: 4.067664 , acc is: 0.03125 , iter= 6603
current loss is: 4.147861 , acc is: 0.015625 , iter= 6604
current loss is: 4.1181784 , acc is: 0.046875 , iter= 6605
current loss is: 4.047755 , acc is: 0.03125 , iter= 6606
current loss is: 4.078252 , acc is: 0.046875 , iter= 6607
current loss is: 4.084262 , acc is: 0.046875 , iter= 6608
current loss is: 4.078289 , acc is: 0.03125 , iter= 6609
current loss is: 4.042209 , acc is: 0.046875 , iter= 6610
current loss is: 4.13414 , acc is: 0.015625 , iter= 6611
current loss is: 4.1448965 , acc is: 0.03125 , iter= 6612
current loss is: 4.19614 , acc is: 0.0 , iter= 6613
current loss is: 4.0668325 , acc is: 0.046875 , iter= 6614
current loss is: 4.0034933 , acc is: 0.09375 , iter= 6615
current loss is: 4.0732594 , acc is: 0.03125 , iter= 6616
current loss is: 4.0304985 , acc is: 0.03125 , iter= 6617
current loss is: 4.141888 , acc is: 0.03125 , iter= 6618
current loss is: 4.183962 , acc is: 0.015625 , iter= 6619
current loss is: 4.046785 , acc is: 0.046875 , iter= 6620
current loss is: 4.1006756 , acc is: 0.015625 , iter= 6621
current loss is: 4.154645 , acc is: 0.03125 , iter= 6622
current loss is: 4.1494513 , acc is: 0.03125 , iter= 6623
current loss is: 4.0129237 , acc is: 0.03125 , iter= 6624
current loss is: 4.074874 , acc is: 0.03125 , iter= 6625
current loss is: 4.0518446 , acc is: 0.0625 , iter= 6626
current loss is: 4.052264 , acc is: 0.0625 , iter= 6627
current loss is: 4.0800138 , acc is: 0.015625 , iter= 6628
current loss is: 4.040728 , acc is: 0.046875 , iter= 6629
current loss is: 4.0621777 , acc is: 0.015625 , iter= 6630
current loss is: 3.9595973 , acc is: 0.046875 , iter= 6631
current loss is: 4.054613 , acc is: 0.03125 , iter= 6632
current loss is: 4.1054344 , acc is: 0.03125 , iter= 6633
current loss is: 4.1272383 , acc is: 0.03125 , iter= 6634
current loss is: 4.129819 , acc is: 0.015625 , iter= 6635
current loss is: 4.0430274 , acc is: 0.046875 , iter= 6636
current loss is: 4.100592 , acc is: 0.015625 , iter= 6637
current loss is: 4.1151094 , acc is: 0.0 , iter= 6638
current loss is: 4.0671043 , acc is: 0.03125 , iter= 6639
current loss is: 4.068522 , acc is: 0.015625 , iter= 6640
current loss is: 4.129078 , acc is: 0.03125 , iter= 6641
current loss is: 4.111149 , acc is: 0.03125 , iter= 6642
current loss is: 4.0500965 , acc is: 0.03125 , iter= 6643
current loss is: 4.0453463 , acc is: 0.03125 , iter= 6644
current loss is: 4.059148 , acc is: 0.03125 , iter= 6645
current loss is: 4.0920663 , acc is: 0.015625 , iter= 6646
current loss is: 4.1850824 , acc is: 0.015625 , iter= 6647
current loss is: 4.122873 , acc is: 0.03125 , iter= 6648
current loss is: 4.065063 , acc is: 0.03125 , iter= 6649
current loss is: 4.140256 , acc is: 0.0625 , iter= 6650
current loss is: 4.062482 , acc is: 0.0625 , iter= 6651
current loss is: 4.154172 , acc is: 0.0 , iter= 6652
current loss is: 4.117276 , acc is: 0.015625 , iter= 6653
current loss is: 4.0837417 , acc is: 0.046875 , iter= 6654
current loss is: 4.0412264 , acc is: 0.03125 , iter= 6655
current loss is: 4.0808954 , acc is: 0.03125 , iter= 6656
current loss is: 3.9344234 , acc is: 0.0625 , iter= 6657
current loss is: 4.045742 , acc is: 0.046875 , iter= 6658
current loss is: 3.9278123 , acc is: 0.046875 , iter= 6659
current loss is: 4.097131 , acc is: 0.0625 , iter= 6660
current loss is: 4.098484 , acc is: 0.03125 , iter= 6661
current loss is: 4.0122375 , acc is: 0.0625 , iter= 6662
current loss is: 4.038776 , acc is: 0.046875 , iter= 6663
current loss is: 4.0677805 , acc is: 0.015625 , iter= 6664
current loss is: 3.927691 , acc is: 0.0625 , iter= 6665
current loss is: 4.160678 , acc is: 0.0 , iter= 6666
current loss is: 4.109949 , acc is: 0.03125 , iter= 6667
current loss is: 4.092021 , acc is: 0.0625 , iter= 6668
current loss is: 4.080865 , acc is: 0.078125 , iter= 6669
current loss is: 4.1495647 , acc is: 0.03125 , iter= 6670
current loss is: 4.1805644 , acc is: 0.0 , iter= 6671
current loss is: 4.0574865 , acc is: 0.0625 , iter= 6672
current loss is: 4.130426 , acc is: 0.03125 , iter= 6673
current loss is: 4.1566267 , acc is: 0.0 , iter= 6674
current loss is: 4.1196737 , acc is: 0.0625 , iter= 6675
current loss is: 4.1545563 , acc is: 0.015625 , iter= 6676
current loss is: 4.069271 , acc is: 0.015625 , iter= 6677
current loss is: 4.171116 , acc is: 0.015625 , iter= 6678
current loss is: 4.1523285 , acc is: 0.0 , iter= 6679
current loss is: 4.033703 , acc is: 0.0625 , iter= 6680
current loss is: 4.0788345 , acc is: 0.015625 , iter= 6681
current loss is: 4.137661 , acc is: 0.015625 , iter= 6682
current loss is: 4.189644 , acc is: 0.015625 , iter= 6683
current loss is: 3.9893875 , acc is: 0.046875 , iter= 6684
current loss is: 4.1307287 , acc is: 0.03125 , iter= 6685
current loss is: 3.920076 , acc is: 0.0625 , iter= 6686
current loss is: 4.123726 , acc is: 0.015625 , iter= 6687
current loss is: 3.9713788 , acc is: 0.046875 , iter= 6688
current loss is: 4.1408105 , acc is: 0.015625 , iter= 6689
current loss is: 4.1753817 , acc is: 0.015625 , iter= 6690
current loss is: 4.119813 , acc is: 0.046875 , iter= 6691
current loss is: 3.982595 , acc is: 0.0625 , iter= 6692
current loss is: 4.1557636 , acc is: 0.0 , iter= 6693
current loss is: 3.9857562 , acc is: 0.0625 , iter= 6694
current loss is: 4.0184345 , acc is: 0.0625 , iter= 6695
current loss is: 4.168068 , acc is: 0.015625 , iter= 6696
current loss is: 4.0787916 , acc is: 0.03125 , iter= 6697
current loss is: 4.1098466 , acc is: 0.03125 , iter= 6698
current loss is: 4.074139 , acc is: 0.03125 , iter= 6699
current loss is: 4.1633506 , acc is: 0.03125 , iter= 6700
current loss is: 4.0687857 , acc is: 0.046875 , iter= 6701
current loss is: 4.0485625 , acc is: 0.03125 , iter= 6702
current loss is: 4.0808434 , acc is: 0.03125 , iter= 6703
current loss is: 4.065099 , acc is: 0.03125 , iter= 6704
current loss is: 4.114148 , acc is: 0.03125 , iter= 6705
current loss is: 4.0847683 , acc is: 0.03125 , iter= 6706
current loss is: 4.0492687 , acc is: 0.109375 , iter= 6707
current loss is: 4.108594 , acc is: 0.0 , iter= 6708
current loss is: 4.028093 , acc is: 0.03125 , iter= 6709
current loss is: 4.182255 , acc is: 0.0 , iter= 6710
current loss is: 4.178213 , acc is: 0.0 , iter= 6711
current loss is: 4.11831 , acc is: 0.015625 , iter= 6712
current loss is: 4.0731964 , acc is: 0.015625 , iter= 6713
current loss is: 3.998076 , acc is: 0.046875 , iter= 6714
current loss is: 4.062641 , acc is: 0.046875 , iter= 6715
current loss is: 4.1666503 , acc is: 0.015625 , iter= 6716
current loss is: 4.222142 , acc is: 0.0 , iter= 6717
current loss is: 4.127368 , acc is: 0.03125 , iter= 6718
current loss is: 4.1720777 , acc is: 0.03125 , iter= 6719
current loss is: 4.07886 , acc is: 0.046875 , iter= 6720
current loss is: 4.1390114 , acc is: 0.015625 , iter= 6721
current loss is: 4.125699 , acc is: 0.03125 , iter= 6722
current loss is: 3.9957986 , acc is: 0.046875 , iter= 6723
current loss is: 4.0595727 , acc is: 0.015625 , iter= 6724
current loss is: 4.0811815 , acc is: 0.09375 , iter= 6725
current loss is: 3.930441 , acc is: 0.0625 , iter= 6726
current loss is: 4.089444 , acc is: 0.0625 , iter= 6727
current loss is: 4.1123886 , acc is: 0.0 , iter= 6728
current loss is: 4.044593 , acc is: 0.03125 , iter= 6729
current loss is: 4.1153126 , acc is: 0.03125 , iter= 6730
current loss is: 4.14589 , acc is: 0.03125 , iter= 6731
current loss is: 4.0627813 , acc is: 0.046875 , iter= 6732
current loss is: 3.998447 , acc is: 0.0625 , iter= 6733
current loss is: 4.072733 , acc is: 0.015625 , iter= 6734
current loss is: 4.101655 , acc is: 0.03125 , iter= 6735
current loss is: 3.999988 , acc is: 0.046875 , iter= 6736
current loss is: 4.071638 , acc is: 0.03125 , iter= 6737
current loss is: 4.1358232 , acc is: 0.0 , iter= 6738
current loss is: 4.0626407 , acc is: 0.0625 , iter= 6739
current loss is: 4.1324296 , acc is: 0.015625 , iter= 6740
current loss is: 4.1690335 , acc is: 0.0 , iter= 6741
current loss is: 4.1315784 , acc is: 0.03125 , iter= 6742
current loss is: 4.0817137 , acc is: 0.03125 , iter= 6743
current loss is: 4.168227 , acc is: 0.0 , iter= 6744
current loss is: 4.088463 , acc is: 0.015625 , iter= 6745
current loss is: 3.8532295 , acc is: 0.0625 , iter= 6746
current loss is: 3.936905 , acc is: 0.09375 , iter= 6747
current loss is: 3.9659107 , acc is: 0.0625 , iter= 6748
current loss is: 4.1868525 , acc is: 0.0 , iter= 6749
current loss is: 4.120782 , acc is: 0.015625 , iter= 6750
current loss is: 4.0385256 , acc is: 0.03125 , iter= 6751
current loss is: 4.1269665 , acc is: 0.015625 , iter= 6752
current loss is: 4.0305004 , acc is: 0.046875 , iter= 6753
current loss is: 4.0563164 , acc is: 0.046875 , iter= 6754
current loss is: 4.114546 , acc is: 0.046875 , iter= 6755
current loss is: 4.0343175 , acc is: 0.03125 , iter= 6756
current loss is: 4.171936 , acc is: 0.0 , iter= 6757
current loss is: 4.1722155 , acc is: 0.0 , iter= 6758
current loss is: 4.0498796 , acc is: 0.03125 , iter= 6759
current loss is: 3.9244366 , acc is: 0.046875 , iter= 6760
current loss is: 4.151531 , acc is: 0.015625 , iter= 6761
current loss is: 4.108783 , acc is: 0.0625 , iter= 6762
current loss is: 4.051741 , acc is: 0.046875 , iter= 6763
current loss is: 4.155459 , acc is: 0.015625 , iter= 6764
current loss is: 3.913776 , acc is: 0.0625 , iter= 6765
current loss is: 4.205742 , acc is: 0.0 , iter= 6766
current loss is: 4.1158667 , acc is: 0.03125 , iter= 6767
current loss is: 3.9923291 , acc is: 0.078125 , iter= 6768
current loss is: 4.126706 , acc is: 0.015625 , iter= 6769
current loss is: 4.134053 , acc is: 0.046875 , iter= 6770
current loss is: 4.0842466 , acc is: 0.015625 , iter= 6771
current loss is: 3.9213982 , acc is: 0.0625 , iter= 6772
current loss is: 4.1208696 , acc is: 0.015625 , iter= 6773
current loss is: 4.086529 , acc is: 0.015625 , iter= 6774
current loss is: 4.115833 , acc is: 0.03125 , iter= 6775
current loss is: 3.9915974 , acc is: 0.078125 , iter= 6776
current loss is: 4.0849075 , acc is: 0.046875 , iter= 6777
current loss is: 4.030839 , acc is: 0.015625 , iter= 6778
current loss is: 4.0722504 , acc is: 0.09375 , iter= 6779
current loss is: 4.1090474 , acc is: 0.015625 , iter= 6780
current loss is: 4.06874 , acc is: 0.046875 , iter= 6781
current loss is: 4.098251 , acc is: 0.03125 , iter= 6782
current loss is: 3.9468455 , acc is: 0.0625 , iter= 6783
current loss is: 4.151636 , acc is: 0.015625 , iter= 6784
current loss is: 4.0649877 , acc is: 0.046875 , iter= 6785
current loss is: 4.121948 , acc is: 0.0625 , iter= 6786
current loss is: 4.107885 , acc is: 0.046875 , iter= 6787
current loss is: 4.1824846 , acc is: 0.015625 , iter= 6788
current loss is: 3.9925623 , acc is: 0.03125 , iter= 6789
current loss is: 4.1630883 , acc is: 0.0 , iter= 6790
current loss is: 4.1153307 , acc is: 0.03125 , iter= 6791
current loss is: 4.0061073 , acc is: 0.046875 , iter= 6792
current loss is: 4.0973973 , acc is: 0.046875 , iter= 6793
current loss is: 4.169566 , acc is: 0.0 , iter= 6794
current loss is: 4.1509295 , acc is: 0.0 , iter= 6795
current loss is: 4.057684 , acc is: 0.015625 , iter= 6796
current loss is: 4.0954657 , acc is: 0.015625 , iter= 6797
current loss is: 4.0421615 , acc is: 0.03125 , iter= 6798
current loss is: 4.1117277 , acc is: 0.046875 , iter= 6799
current loss is: 4.167539 , acc is: 0.0 , iter= 6800
current loss is: 4.151555 , acc is: 0.0 , iter= 6801
current loss is: 4.1021805 , acc is: 0.046875 , iter= 6802
current loss is: 4.1420975 , acc is: 0.0 , iter= 6803
current loss is: 4.0224886 , acc is: 0.03125 , iter= 6804
current loss is: 4.0827255 , acc is: 0.046875 , iter= 6805
current loss is: 4.064397 , acc is: 0.046875 , iter= 6806
current loss is: 4.0984955 , acc is: 0.046875 , iter= 6807
current loss is: 4.1156683 , acc is: 0.046875 , iter= 6808
current loss is: 4.0536814 , acc is: 0.015625 , iter= 6809
current loss is: 4.0355916 , acc is: 0.0625 , iter= 6810
current loss is: 4.095093 , acc is: 0.03125 , iter= 6811
current loss is: 4.1407704 , acc is: 0.015625 , iter= 6812
current loss is: 4.150673 , acc is: 0.0 , iter= 6813
current loss is: 4.175952 , acc is: 0.03125 , iter= 6814
current loss is: 4.1165705 , acc is: 0.03125 , iter= 6815
current loss is: 4.0529566 , acc is: 0.0625 , iter= 6816
current loss is: 3.9745996 , acc is: 0.046875 , iter= 6817
current loss is: 4.157071 , acc is: 0.03125 , iter= 6818
current loss is: 4.1045456 , acc is: 0.015625 , iter= 6819
current loss is: 4.1194534 , acc is: 0.015625 , iter= 6820
current loss is: 3.9302936 , acc is: 0.0625 , iter= 6821
current loss is: 4.133391 , acc is: 0.03125 , iter= 6822
current loss is: 4.061597 , acc is: 0.046875 , iter= 6823
current loss is: 4.032592 , acc is: 0.03125 , iter= 6824
current loss is: 4.224226 , acc is: 0.0 , iter= 6825
current loss is: 4.103548 , acc is: 0.046875 , iter= 6826
current loss is: 4.1164207 , acc is: 0.015625 , iter= 6827
current loss is: 4.078675 , acc is: 0.046875 , iter= 6828
current loss is: 4.0389047 , acc is: 0.03125 , iter= 6829
current loss is: 4.132483 , acc is: 0.015625 , iter= 6830
current loss is: 4.0161633 , acc is: 0.046875 , iter= 6831
current loss is: 4.070182 , acc is: 0.046875 , iter= 6832
current loss is: 4.1069345 , acc is: 0.046875 , iter= 6833
current loss is: 4.073615 , acc is: 0.046875 , iter= 6834
current loss is: 4.1203995 , acc is: 0.03125 , iter= 6835
current loss is: 4.22452 , acc is: 0.0 , iter= 6836
current loss is: 4.059289 , acc is: 0.078125 , iter= 6837
current loss is: 4.0105486 , acc is: 0.046875 , iter= 6838
current loss is: 4.1318827 , acc is: 0.015625 , iter= 6839
current loss is: 4.031325 , acc is: 0.03125 , iter= 6840
current loss is: 4.07073 , acc is: 0.046875 , iter= 6841
current loss is: 4.0199623 , acc is: 0.046875 , iter= 6842
current loss is: 4.113676 , acc is: 0.015625 , iter= 6843
current loss is: 3.9889033 , acc is: 0.078125 , iter= 6844
current loss is: 4.0858145 , acc is: 0.015625 , iter= 6845
current loss is: 4.1917133 , acc is: 0.015625 , iter= 6846
current loss is: 4.093167 , acc is: 0.03125 , iter= 6847
current loss is: 3.8671641 , acc is: 0.078125 , iter= 6848
current loss is: 4.045003 , acc is: 0.03125 , iter= 6849
current loss is: 4.1600714 , acc is: 0.015625 , iter= 6850
current loss is: 4.019375 , acc is: 0.0625 , iter= 6851
current loss is: 4.007476 , acc is: 0.046875 , iter= 6852
current loss is: 3.9700234 , acc is: 0.09375 , iter= 6853
current loss is: 3.956364 , acc is: 0.078125 , iter= 6854
current loss is: 4.0496182 , acc is: 0.0625 , iter= 6855
current loss is: 4.0812206 , acc is: 0.03125 , iter= 6856
current loss is: 4.000641 , acc is: 0.03125 , iter= 6857
current loss is: 4.1771545 , acc is: 0.03125 , iter= 6858
current loss is: 4.157132 , acc is: 0.015625 , iter= 6859
current loss is: 4.0846024 , acc is: 0.03125 , iter= 6860
current loss is: 4.16614 , acc is: 0.0 , iter= 6861
current loss is: 3.9494386 , acc is: 0.0625 , iter= 6862
current loss is: 4.076848 , acc is: 0.03125 , iter= 6863
current loss is: 4.1027737 , acc is: 0.03125 , iter= 6864
current loss is: 4.182703 , acc is: 0.015625 , iter= 6865
current loss is: 4.118722 , acc is: 0.046875 , iter= 6866
current loss is: 4.1496162 , acc is: 0.03125 , iter= 6867
current loss is: 4.1387973 , acc is: 0.046875 , iter= 6868
current loss is: 4.1064005 , acc is: 0.015625 , iter= 6869
current loss is: 4.147149 , acc is: 0.03125 , iter= 6870
current loss is: 4.0883446 , acc is: 0.03125 , iter= 6871
current loss is: 4.0415964 , acc is: 0.046875 , iter= 6872
current loss is: 4.082815 , acc is: 0.09375 , iter= 6873
current loss is: 4.028739 , acc is: 0.109375 , iter= 6874
current loss is: 4.069482 , acc is: 0.046875 , iter= 6875
current loss is: 4.080374 , acc is: 0.0625 , iter= 6876
current loss is: 4.0161805 , acc is: 0.03125 , iter= 6877
current loss is: 4.1492386 , acc is: 0.015625 , iter= 6878
current loss is: 4.10805 , acc is: 0.03125 , iter= 6879
current loss is: 4.0833445 , acc is: 0.046875 , iter= 6880
current loss is: 4.0962954 , acc is: 0.03125 , iter= 6881
current loss is: 4.0744486 , acc is: 0.03125 , iter= 6882
current loss is: 4.0166497 , acc is: 0.046875 , iter= 6883
current loss is: 4.0699983 , acc is: 0.03125 , iter= 6884
current loss is: 4.147004 , acc is: 0.046875 , iter= 6885
current loss is: 4.035286 , acc is: 0.0625 , iter= 6886
current loss is: 4.136119 , acc is: 0.0 , iter= 6887
current loss is: 4.172452 , acc is: 0.0 , iter= 6888
current loss is: 4.13585 , acc is: 0.03125 , iter= 6889
current loss is: 4.1255527 , acc is: 0.0 , iter= 6890
current loss is: 4.068632 , acc is: 0.015625 , iter= 6891
current loss is: 4.153759 , acc is: 0.015625 , iter= 6892
current loss is: 4.132388 , acc is: 0.03125 , iter= 6893
current loss is: 4.1071157 , acc is: 0.0 , iter= 6894
current loss is: 4.076967 , acc is: 0.03125 , iter= 6895
current loss is: 4.0754404 , acc is: 0.015625 , iter= 6896
current loss is: 4.107537 , acc is: 0.03125 , iter= 6897
current loss is: 3.9257698 , acc is: 0.046875 , iter= 6898
current loss is: 4.133684 , acc is: 0.015625 , iter= 6899
current loss is: 3.948757 , acc is: 0.0625 , iter= 6900
current loss is: 4.129784 , acc is: 0.03125 , iter= 6901
current loss is: 3.9378371 , acc is: 0.046875 , iter= 6902
current loss is: 4.14744 , acc is: 0.0 , iter= 6903
current loss is: 3.9564586 , acc is: 0.046875 , iter= 6904
current loss is: 4.157852 , acc is: 0.0 , iter= 6905
current loss is: 3.997159 , acc is: 0.0625 , iter= 6906
current loss is: 4.1062193 , acc is: 0.046875 , iter= 6907
current loss is: 4.180631 , acc is: 0.0 , iter= 6908
current loss is: 4.1464815 , acc is: 0.03125 , iter= 6909
current loss is: 4.0838904 , acc is: 0.03125 , iter= 6910
current loss is: 4.1174593 , acc is: 0.03125 , iter= 6911
current loss is: 3.9340215 , acc is: 0.09375 , iter= 6912
current loss is: 4.1498537 , acc is: 0.0 , iter= 6913
current loss is: 4.1194396 , acc is: 0.015625 , iter= 6914
current loss is: 4.161549 , acc is: 0.015625 , iter= 6915
current loss is: 4.1282167 , acc is: 0.03125 , iter= 6916
current loss is: 4.0039363 , acc is: 0.03125 , iter= 6917
current loss is: 4.090526 , acc is: 0.046875 , iter= 6918
current loss is: 4.1122103 , acc is: 0.015625 , iter= 6919
current loss is: 4.1348386 , acc is: 0.078125 , iter= 6920
current loss is: 4.1184893 , acc is: 0.015625 , iter= 6921
current loss is: 4.118558 , acc is: 0.03125 , iter= 6922
current loss is: 4.0814667 , acc is: 0.0625 , iter= 6923
current loss is: 4.0173497 , acc is: 0.0625 , iter= 6924
current loss is: 3.9762974 , acc is: 0.0625 , iter= 6925
current loss is: 4.0002513 , acc is: 0.046875 , iter= 6926
current loss is: 3.992169 , acc is: 0.03125 , iter= 6927
current loss is: 4.0987015 , acc is: 0.015625 , iter= 6928
current loss is: 4.1503816 , acc is: 0.03125 , iter= 6929
current loss is: 4.180453 , acc is: 0.03125 , iter= 6930
current loss is: 4.1445208 , acc is: 0.015625 , iter= 6931
current loss is: 4.1694555 , acc is: 0.03125 , iter= 6932
current loss is: 4.0132265 , acc is: 0.046875 , iter= 6933
current loss is: 4.1825314 , acc is: 0.046875 , iter= 6934
current loss is: 3.9324968 , acc is: 0.109375 , iter= 6935
current loss is: 4.1613255 , acc is: 0.0 , iter= 6936
current loss is: 4.108776 , acc is: 0.046875 , iter= 6937
current loss is: 4.121301 , acc is: 0.03125 , iter= 6938
current loss is: 4.1535587 , acc is: 0.0 , iter= 6939
current loss is: 4.105006 , acc is: 0.03125 , iter= 6940
current loss is: 4.067834 , acc is: 0.03125 , iter= 6941
current loss is: 4.020463 , acc is: 0.0625 , iter= 6942
current loss is: 4.1338243 , acc is: 0.03125 , iter= 6943
current loss is: 4.128442 , acc is: 0.03125 , iter= 6944
current loss is: 4.0419774 , acc is: 0.046875 , iter= 6945
current loss is: 4.139375 , acc is: 0.0 , iter= 6946
current loss is: 4.2077956 , acc is: 0.015625 , iter= 6947
current loss is: 4.1081243 , acc is: 0.015625 , iter= 6948
current loss is: 4.0194435 , acc is: 0.03125 , iter= 6949
current loss is: 3.8966968 , acc is: 0.078125 , iter= 6950
current loss is: 4.107736 , acc is: 0.109375 , iter= 6951
current loss is: 4.141899 , acc is: 0.015625 , iter= 6952
current loss is: 3.9633498 , acc is: 0.078125 , iter= 6953
current loss is: 3.9869661 , acc is: 0.0625 , iter= 6954
current loss is: 4.088217 , acc is: 0.0625 , iter= 6955
current loss is: 4.146551 , acc is: 0.046875 , iter= 6956
current loss is: 4.0790863 , acc is: 0.03125 , iter= 6957
current loss is: 4.002019 , acc is: 0.046875 , iter= 6958
current loss is: 4.0679026 , acc is: 0.03125 , iter= 6959
current loss is: 4.1745615 , acc is: 0.03125 , iter= 6960
current loss is: 4.193625 , acc is: 0.015625 , iter= 6961
current loss is: 4.133833 , acc is: 0.03125 , iter= 6962
current loss is: 4.0818176 , acc is: 0.03125 , iter= 6963
current loss is: 4.067872 , acc is: 0.0625 , iter= 6964
current loss is: 3.9802577 , acc is: 0.078125 , iter= 6965
current loss is: 4.0798903 , acc is: 0.0 , iter= 6966
current loss is: 4.011244 , acc is: 0.046875 , iter= 6967
current loss is: 4.1317034 , acc is: 0.015625 , iter= 6968
current loss is: 4.0894527 , acc is: 0.03125 , iter= 6969
current loss is: 4.154517 , acc is: 0.03125 , iter= 6970
current loss is: 4.070692 , acc is: 0.0625 , iter= 6971
current loss is: 4.1782513 , acc is: 0.0 , iter= 6972
current loss is: 3.991403 , acc is: 0.0625 , iter= 6973
current loss is: 4.089403 , acc is: 0.03125 , iter= 6974
current loss is: 4.0917397 , acc is: 0.0 , iter= 6975
current loss is: 4.0520377 , acc is: 0.015625 , iter= 6976
current loss is: 4.068774 , acc is: 0.015625 , iter= 6977
current loss is: 4.1460304 , acc is: 0.015625 , iter= 6978
current loss is: 4.058859 , acc is: 0.046875 , iter= 6979
current loss is: 4.1541777 , acc is: 0.015625 , iter= 6980
current loss is: 4.1746697 , acc is: 0.0 , iter= 6981
current loss is: 4.0696692 , acc is: 0.046875 , iter= 6982
current loss is: 4.119892 , acc is: 0.015625 , iter= 6983
current loss is: 4.064193 , acc is: 0.03125 , iter= 6984
current loss is: 4.016621 , acc is: 0.046875 , iter= 6985
current loss is: 4.0561185 , acc is: 0.078125 , iter= 6986
current loss is: 4.0637045 , acc is: 0.046875 , iter= 6987
current loss is: 4.187659 , acc is: 0.0 , iter= 6988
current loss is: 4.109924 , acc is: 0.03125 , iter= 6989
current loss is: 4.042548 , acc is: 0.015625 , iter= 6990
current loss is: 4.084257 , acc is: 0.03125 , iter= 6991
current loss is: 4.1411085 , acc is: 0.03125 , iter= 6992
current loss is: 4.174512 , acc is: 0.046875 , iter= 6993
current loss is: 4.0932417 , acc is: 0.015625 , iter= 6994
current loss is: 4.1718497 , acc is: 0.015625 , iter= 6995
current loss is: 4.1530147 , acc is: 0.03125 , iter= 6996
current loss is: 3.954523 , acc is: 0.078125 , iter= 6997
current loss is: 4.1542544 , acc is: 0.0 , iter= 6998
current loss is: 4.02897 , acc is: 0.0625 , iter= 6999
current loss is: 4.0158763 , acc is: 0.0625 , iter= 7000
tot_acc= 19.0 tot_input= 768
current accuracy is: 0.024739583333333332
current loss is: 4.02827 , acc is: 0.03125 , iter= 7001
current loss is: 3.971985 , acc is: 0.046875 , iter= 7002
current loss is: 4.0146675 , acc is: 0.03125 , iter= 7003
current loss is: 4.1383877 , acc is: 0.015625 , iter= 7004
current loss is: 4.140717 , acc is: 0.03125 , iter= 7005
current loss is: 4.107644 , acc is: 0.046875 , iter= 7006
current loss is: 4.1530876 , acc is: 0.015625 , iter= 7007
current loss is: 4.022501 , acc is: 0.03125 , iter= 7008
current loss is: 4.1275864 , acc is: 0.015625 , iter= 7009
current loss is: 3.9518418 , acc is: 0.046875 , iter= 7010
current loss is: 4.138485 , acc is: 0.015625 , iter= 7011
current loss is: 4.0910387 , acc is: 0.015625 , iter= 7012
current loss is: 4.068446 , acc is: 0.03125 , iter= 7013
current loss is: 4.0763245 , acc is: 0.03125 , iter= 7014
current loss is: 4.096879 , acc is: 0.0 , iter= 7015
current loss is: 4.076456 , acc is: 0.046875 , iter= 7016
current loss is: 4.201175 , acc is: 0.015625 , iter= 7017
current loss is: 4.1879478 , acc is: 0.015625 , iter= 7018
current loss is: 4.1371307 , acc is: 0.03125 , iter= 7019
current loss is: 4.0460215 , acc is: 0.078125 , iter= 7020
current loss is: 4.111894 , acc is: 0.03125 , iter= 7021
current loss is: 4.2120614 , acc is: 0.0625 , iter= 7022
current loss is: 4.1504064 , acc is: 0.015625 , iter= 7023
current loss is: 4.070432 , acc is: 0.046875 , iter= 7024
current loss is: 4.1330395 , acc is: 0.03125 , iter= 7025
current loss is: 4.08531 , acc is: 0.015625 , iter= 7026
current loss is: 4.194807 , acc is: 0.03125 , iter= 7027
current loss is: 4.070633 , acc is: 0.03125 , iter= 7028
current loss is: 4.0650616 , acc is: 0.09375 , iter= 7029
current loss is: 4.131987 , acc is: 0.0 , iter= 7030
current loss is: 4.080119 , acc is: 0.046875 , iter= 7031
current loss is: 4.1137686 , acc is: 0.015625 , iter= 7032
current loss is: 4.014162 , acc is: 0.046875 , iter= 7033
current loss is: 4.101742 , acc is: 0.015625 , iter= 7034
current loss is: 4.141475 , acc is: 0.015625 , iter= 7035
current loss is: 4.0580254 , acc is: 0.046875 , iter= 7036
current loss is: 4.1192703 , acc is: 0.0 , iter= 7037
current loss is: 4.0333776 , acc is: 0.046875 , iter= 7038
current loss is: 4.0844564 , acc is: 0.03125 , iter= 7039
current loss is: 4.077002 , acc is: 0.015625 , iter= 7040
current loss is: 4.174226 , acc is: 0.046875 , iter= 7041
current loss is: 3.983708 , acc is: 0.046875 , iter= 7042
current loss is: 4.142084 , acc is: 0.046875 , iter= 7043
current loss is: 4.018512 , acc is: 0.046875 , iter= 7044
current loss is: 3.9312313 , acc is: 0.09375 , iter= 7045
current loss is: 4.1048856 , acc is: 0.03125 , iter= 7046
current loss is: 4.081964 , acc is: 0.015625 , iter= 7047
current loss is: 3.9753747 , acc is: 0.046875 , iter= 7048
current loss is: 4.032769 , acc is: 0.03125 , iter= 7049
current loss is: 4.047025 , acc is: 0.03125 , iter= 7050
current loss is: 3.989348 , acc is: 0.046875 , iter= 7051
current loss is: 4.0734596 , acc is: 0.0625 , iter= 7052
current loss is: 4.092806 , acc is: 0.046875 , iter= 7053
current loss is: 4.139764 , acc is: 0.0 , iter= 7054
current loss is: 3.9223843 , acc is: 0.0625 , iter= 7055
current loss is: 4.1253233 , acc is: 0.03125 , iter= 7056
current loss is: 4.0863676 , acc is: 0.015625 , iter= 7057
current loss is: 4.0303607 , acc is: 0.0625 , iter= 7058
current loss is: 4.0534906 , acc is: 0.03125 , iter= 7059
current loss is: 4.1248217 , acc is: 0.046875 , iter= 7060
current loss is: 4.1265783 , acc is: 0.0 , iter= 7061
current loss is: 4.135907 , acc is: 0.0 , iter= 7062
current loss is: 4.0711 , acc is: 0.015625 , iter= 7063
current loss is: 4.100853 , acc is: 0.046875 , iter= 7064
current loss is: 4.129069 , acc is: 0.015625 , iter= 7065
current loss is: 4.0979548 , acc is: 0.015625 , iter= 7066
current loss is: 4.1986513 , acc is: 0.0 , iter= 7067
current loss is: 4.147302 , acc is: 0.046875 , iter= 7068
current loss is: 4.0320244 , acc is: 0.078125 , iter= 7069
current loss is: 4.0985928 , acc is: 0.046875 , iter= 7070
current loss is: 4.1516986 , acc is: 0.015625 , iter= 7071
current loss is: 3.998764 , acc is: 0.078125 , iter= 7072
current loss is: 4.1170173 , acc is: 0.015625 , iter= 7073
current loss is: 4.0780287 , acc is: 0.03125 , iter= 7074
current loss is: 4.1610503 , acc is: 0.0 , iter= 7075
current loss is: 4.0096846 , acc is: 0.046875 , iter= 7076
current loss is: 3.9128428 , acc is: 0.109375 , iter= 7077
current loss is: 4.0128 , acc is: 0.0625 , iter= 7078
current loss is: 4.0628743 , acc is: 0.0625 , iter= 7079
current loss is: 4.133218 , acc is: 0.0625 , iter= 7080
current loss is: 4.172208 , acc is: 0.046875 , iter= 7081
current loss is: 4.2242804 , acc is: 0.0 , iter= 7082
current loss is: 4.053238 , acc is: 0.0625 , iter= 7083
current loss is: 4.1041427 , acc is: 0.03125 , iter= 7084
current loss is: 4.087537 , acc is: 0.015625 , iter= 7085
current loss is: 4.1291194 , acc is: 0.015625 , iter= 7086
current loss is: 4.050956 , acc is: 0.046875 , iter= 7087
current loss is: 3.986596 , acc is: 0.03125 , iter= 7088
current loss is: 4.1106443 , acc is: 0.0 , iter= 7089
current loss is: 4.0979066 , acc is: 0.03125 , iter= 7090
current loss is: 4.09142 , acc is: 0.03125 , iter= 7091
current loss is: 4.0301027 , acc is: 0.109375 , iter= 7092
current loss is: 4.159176 , acc is: 0.03125 , iter= 7093
current loss is: 4.0678854 , acc is: 0.03125 , iter= 7094
current loss is: 4.135583 , acc is: 0.03125 , iter= 7095
current loss is: 4.047943 , acc is: 0.046875 , iter= 7096
current loss is: 4.042775 , acc is: 0.03125 , iter= 7097
current loss is: 4.0795107 , acc is: 0.03125 , iter= 7098
current loss is: 4.1608458 , acc is: 0.015625 , iter= 7099
current loss is: 4.0137124 , acc is: 0.03125 , iter= 7100
current loss is: 4.1151237 , acc is: 0.0625 , iter= 7101
current loss is: 3.999344 , acc is: 0.046875 , iter= 7102
current loss is: 4.106749 , acc is: 0.0625 , iter= 7103
current loss is: 4.043001 , acc is: 0.03125 , iter= 7104
current loss is: 4.1367846 , acc is: 0.03125 , iter= 7105
current loss is: 3.9152248 , acc is: 0.0625 , iter= 7106
current loss is: 4.0295496 , acc is: 0.046875 , iter= 7107
current loss is: 4.086208 , acc is: 0.046875 , iter= 7108
current loss is: 3.9906821 , acc is: 0.0625 , iter= 7109
current loss is: 4.1358914 , acc is: 0.078125 , iter= 7110
current loss is: 4.0364814 , acc is: 0.03125 , iter= 7111
current loss is: 4.1159544 , acc is: 0.03125 , iter= 7112
current loss is: 4.1398764 , acc is: 0.03125 , iter= 7113
current loss is: 4.1008005 , acc is: 0.0625 , iter= 7114
current loss is: 4.135489 , acc is: 0.0625 , iter= 7115
current loss is: 4.0820813 , acc is: 0.046875 , iter= 7116
current loss is: 4.1743336 , acc is: 0.015625 , iter= 7117
current loss is: 4.0907717 , acc is: 0.03125 , iter= 7118
current loss is: 4.139759 , acc is: 0.015625 , iter= 7119
current loss is: 4.1820383 , acc is: 0.015625 , iter= 7120
current loss is: 4.081893 , acc is: 0.015625 , iter= 7121
current loss is: 4.1215286 , acc is: 0.03125 , iter= 7122
current loss is: 4.0785103 , acc is: 0.03125 , iter= 7123
current loss is: 4.0459905 , acc is: 0.03125 , iter= 7124
current loss is: 4.126317 , acc is: 0.015625 , iter= 7125
current loss is: 4.017439 , acc is: 0.03125 , iter= 7126
current loss is: 4.165697 , acc is: 0.015625 , iter= 7127
current loss is: 4.08197 , acc is: 0.046875 , iter= 7128
current loss is: 4.166404 , acc is: 0.03125 , iter= 7129
current loss is: 4.1042204 , acc is: 0.0 , iter= 7130
current loss is: 4.000971 , acc is: 0.0625 , iter= 7131
current loss is: 4.0981607 , acc is: 0.0625 , iter= 7132
current loss is: 4.1257496 , acc is: 0.0 , iter= 7133
current loss is: 4.1441784 , acc is: 0.015625 , iter= 7134
current loss is: 4.1203146 , acc is: 0.046875 , iter= 7135
current loss is: 4.1656027 , acc is: 0.0 , iter= 7136
current loss is: 4.0302496 , acc is: 0.046875 , iter= 7137
current loss is: 4.0740805 , acc is: 0.0625 , iter= 7138
current loss is: 3.9767904 , acc is: 0.046875 , iter= 7139
current loss is: 4.0030355 , acc is: 0.03125 , iter= 7140
current loss is: 4.1596327 , acc is: 0.015625 , iter= 7141
current loss is: 4.153769 , acc is: 0.015625 , iter= 7142
current loss is: 4.1033125 , acc is: 0.03125 , iter= 7143
current loss is: 4.081173 , acc is: 0.046875 , iter= 7144
current loss is: 4.1408653 , acc is: 0.015625 , iter= 7145
current loss is: 3.9855855 , acc is: 0.078125 , iter= 7146
current loss is: 4.197606 , acc is: 0.0 , iter= 7147
current loss is: 4.106731 , acc is: 0.03125 , iter= 7148
current loss is: 4.067272 , acc is: 0.0625 , iter= 7149
current loss is: 4.076602 , acc is: 0.046875 , iter= 7150
current loss is: 4.1188064 , acc is: 0.03125 , iter= 7151
current loss is: 4.105698 , acc is: 0.015625 , iter= 7152
current loss is: 4.1571474 , acc is: 0.0 , iter= 7153
current loss is: 4.05103 , acc is: 0.03125 , iter= 7154
current loss is: 4.1210394 , acc is: 0.015625 , iter= 7155
current loss is: 4.1046534 , acc is: 0.03125 , iter= 7156
current loss is: 4.030841 , acc is: 0.046875 , iter= 7157
current loss is: 4.1213856 , acc is: 0.015625 , iter= 7158
current loss is: 4.0521965 , acc is: 0.046875 , iter= 7159
current loss is: 4.140653 , acc is: 0.03125 , iter= 7160
current loss is: 4.058972 , acc is: 0.046875 , iter= 7161
current loss is: 4.048529 , acc is: 0.046875 , iter= 7162
current loss is: 4.0868297 , acc is: 0.046875 , iter= 7163
current loss is: 4.0276556 , acc is: 0.078125 , iter= 7164
current loss is: 4.046925 , acc is: 0.046875 , iter= 7165
current loss is: 4.0889473 , acc is: 0.015625 , iter= 7166
current loss is: 4.095334 , acc is: 0.03125 , iter= 7167
current loss is: 4.2027435 , acc is: 0.015625 , iter= 7168
current loss is: 4.044342 , acc is: 0.015625 , iter= 7169
current loss is: 4.154277 , acc is: 0.046875 , iter= 7170
current loss is: 4.1049914 , acc is: 0.03125 , iter= 7171
current loss is: 4.1074324 , acc is: 0.0625 , iter= 7172
current loss is: 4.0861335 , acc is: 0.03125 , iter= 7173
current loss is: 4.051777 , acc is: 0.046875 , iter= 7174
current loss is: 4.1436605 , acc is: 0.0 , iter= 7175
current loss is: 4.1221285 , acc is: 0.015625 , iter= 7176
current loss is: 4.1849613 , acc is: 0.03125 , iter= 7177
current loss is: 4.020067 , acc is: 0.0625 , iter= 7178
current loss is: 4.1084976 , acc is: 0.03125 , iter= 7179
current loss is: 4.1177044 , acc is: 0.03125 , iter= 7180
current loss is: 4.0143538 , acc is: 0.046875 , iter= 7181
current loss is: 4.111498 , acc is: 0.0625 , iter= 7182
current loss is: 4.155631 , acc is: 0.03125 , iter= 7183
current loss is: 4.1303673 , acc is: 0.046875 , iter= 7184
current loss is: 4.147246 , acc is: 0.0 , iter= 7185
current loss is: 4.077872 , acc is: 0.03125 , iter= 7186
current loss is: 4.0734425 , acc is: 0.03125 , iter= 7187
current loss is: 4.083943 , acc is: 0.046875 , iter= 7188
current loss is: 4.054516 , acc is: 0.0625 , iter= 7189
current loss is: 4.040419 , acc is: 0.03125 , iter= 7190
current loss is: 4.113132 , acc is: 0.0 , iter= 7191
current loss is: 4.0619297 , acc is: 0.046875 , iter= 7192
current loss is: 4.1252575 , acc is: 0.03125 , iter= 7193
current loss is: 4.0931053 , acc is: 0.03125 , iter= 7194
current loss is: 3.9495308 , acc is: 0.046875 , iter= 7195
current loss is: 3.9736652 , acc is: 0.046875 , iter= 7196
current loss is: 4.1281176 , acc is: 0.015625 , iter= 7197
current loss is: 4.085332 , acc is: 0.078125 , iter= 7198
current loss is: 4.1730146 , acc is: 0.015625 , iter= 7199
current loss is: 4.0604153 , acc is: 0.046875 , iter= 7200
current loss is: 4.158588 , acc is: 0.015625 , iter= 7201
current loss is: 4.1004043 , acc is: 0.015625 , iter= 7202
current loss is: 4.025772 , acc is: 0.046875 , iter= 7203
current loss is: 4.1081724 , acc is: 0.03125 , iter= 7204
current loss is: 4.1068344 , acc is: 0.015625 , iter= 7205
current loss is: 4.1600733 , acc is: 0.0 , iter= 7206
current loss is: 4.105265 , acc is: 0.015625 , iter= 7207
current loss is: 4.1062584 , acc is: 0.03125 , iter= 7208
current loss is: 4.156012 , acc is: 0.015625 , iter= 7209
current loss is: 4.1719456 , acc is: 0.0 , iter= 7210
current loss is: 4.0682716 , acc is: 0.03125 , iter= 7211
current loss is: 4.0865273 , acc is: 0.015625 , iter= 7212
current loss is: 4.117468 , acc is: 0.015625 , iter= 7213
current loss is: 4.105509 , acc is: 0.015625 , iter= 7214
current loss is: 4.14789 , acc is: 0.046875 , iter= 7215
current loss is: 4.059409 , acc is: 0.015625 , iter= 7216
current loss is: 4.108075 , acc is: 0.046875 , iter= 7217
current loss is: 4.1679773 , acc is: 0.0 , iter= 7218
current loss is: 4.0106773 , acc is: 0.046875 , iter= 7219
current loss is: 3.922319 , acc is: 0.0625 , iter= 7220
current loss is: 4.1142206 , acc is: 0.03125 , iter= 7221
current loss is: 4.056466 , acc is: 0.046875 , iter= 7222
current loss is: 4.0686507 , acc is: 0.015625 , iter= 7223
current loss is: 3.9447293 , acc is: 0.046875 , iter= 7224
current loss is: 4.1273866 , acc is: 0.015625 , iter= 7225
current loss is: 4.050659 , acc is: 0.03125 , iter= 7226
current loss is: 4.066267 , acc is: 0.015625 , iter= 7227
current loss is: 4.057789 , acc is: 0.0625 , iter= 7228
current loss is: 4.0899305 , acc is: 0.046875 , iter= 7229
current loss is: 4.187983 , acc is: 0.015625 , iter= 7230
current loss is: 4.1151505 , acc is: 0.0 , iter= 7231
current loss is: 3.996089 , acc is: 0.078125 , iter= 7232
current loss is: 4.1286087 , acc is: 0.03125 , iter= 7233
current loss is: 3.9121873 , acc is: 0.046875 , iter= 7234
current loss is: 4.0676985 , acc is: 0.078125 , iter= 7235
current loss is: 4.09686 , acc is: 0.015625 , iter= 7236
current loss is: 4.1014104 , acc is: 0.03125 , iter= 7237
current loss is: 4.0792975 , acc is: 0.078125 , iter= 7238
current loss is: 4.1208878 , acc is: 0.03125 , iter= 7239
current loss is: 4.170715 , acc is: 0.0 , iter= 7240
current loss is: 4.0783453 , acc is: 0.03125 , iter= 7241
current loss is: 4.0717545 , acc is: 0.015625 , iter= 7242
current loss is: 4.0952873 , acc is: 0.03125 , iter= 7243
current loss is: 3.9659948 , acc is: 0.046875 , iter= 7244
current loss is: 3.9895873 , acc is: 0.0625 , iter= 7245
current loss is: 4.1799736 , acc is: 0.046875 , iter= 7246
current loss is: 4.040767 , acc is: 0.046875 , iter= 7247
current loss is: 4.1653934 , acc is: 0.0 , iter= 7248
current loss is: 4.192635 , acc is: 0.015625 , iter= 7249
current loss is: 4.0546927 , acc is: 0.03125 , iter= 7250
current loss is: 4.0068398 , acc is: 0.09375 , iter= 7251
current loss is: 4.0726666 , acc is: 0.03125 , iter= 7252
current loss is: 4.0965214 , acc is: 0.03125 , iter= 7253
current loss is: 3.992192 , acc is: 0.078125 , iter= 7254
current loss is: 4.148225 , acc is: 0.03125 , iter= 7255
current loss is: 4.151038 , acc is: 0.03125 , iter= 7256
current loss is: 4.203067 , acc is: 0.015625 , iter= 7257
current loss is: 4.0558133 , acc is: 0.046875 , iter= 7258
current loss is: 4.072646 , acc is: 0.03125 , iter= 7259
current loss is: 4.155396 , acc is: 0.03125 , iter= 7260
current loss is: 4.137849 , acc is: 0.0 , iter= 7261
current loss is: 4.0887527 , acc is: 0.046875 , iter= 7262
current loss is: 4.1129117 , acc is: 0.015625 , iter= 7263
current loss is: 4.0468197 , acc is: 0.046875 , iter= 7264
current loss is: 4.1527696 , acc is: 0.0 , iter= 7265
current loss is: 4.066288 , acc is: 0.015625 , iter= 7266
current loss is: 4.002826 , acc is: 0.03125 , iter= 7267
current loss is: 4.082874 , acc is: 0.0625 , iter= 7268
current loss is: 3.932069 , acc is: 0.0625 , iter= 7269
current loss is: 4.04179 , acc is: 0.015625 , iter= 7270
current loss is: 4.0950785 , acc is: 0.046875 , iter= 7271
current loss is: 3.9781094 , acc is: 0.0625 , iter= 7272
current loss is: 4.044842 , acc is: 0.0625 , iter= 7273
current loss is: 4.0727997 , acc is: 0.046875 , iter= 7274
current loss is: 4.0491014 , acc is: 0.0625 , iter= 7275
current loss is: 4.1791615 , acc is: 0.03125 , iter= 7276
current loss is: 3.9136677 , acc is: 0.0625 , iter= 7277
current loss is: 4.1479883 , acc is: 0.015625 , iter= 7278
current loss is: 3.964195 , acc is: 0.0625 , iter= 7279
current loss is: 4.085848 , acc is: 0.046875 , iter= 7280
current loss is: 4.185873 , acc is: 0.015625 , iter= 7281
current loss is: 4.031082 , acc is: 0.046875 , iter= 7282
current loss is: 4.1739097 , acc is: 0.0 , iter= 7283
current loss is: 4.1155057 , acc is: 0.015625 , iter= 7284
current loss is: 3.9873273 , acc is: 0.046875 , iter= 7285
current loss is: 4.001213 , acc is: 0.03125 , iter= 7286
current loss is: 4.157968 , acc is: 0.03125 , iter= 7287
current loss is: 4.087851 , acc is: 0.015625 , iter= 7288
current loss is: 4.1411104 , acc is: 0.0 , iter= 7289
current loss is: 4.0718107 , acc is: 0.015625 , iter= 7290
current loss is: 4.121208 , acc is: 0.015625 , iter= 7291
current loss is: 4.1685133 , acc is: 0.015625 , iter= 7292
current loss is: 4.1156454 , acc is: 0.046875 , iter= 7293
current loss is: 4.0984917 , acc is: 0.03125 , iter= 7294
current loss is: 4.1061535 , acc is: 0.015625 , iter= 7295
current loss is: 4.105311 , acc is: 0.03125 , iter= 7296
current loss is: 4.130602 , acc is: 0.0 , iter= 7297
current loss is: 4.1015835 , acc is: 0.03125 , iter= 7298
current loss is: 4.2213535 , acc is: 0.0 , iter= 7299
current loss is: 4.12938 , acc is: 0.046875 , iter= 7300
current loss is: 4.171596 , acc is: 0.03125 , iter= 7301
current loss is: 4.1349144 , acc is: 0.015625 , iter= 7302
current loss is: 4.087794 , acc is: 0.046875 , iter= 7303
current loss is: 4.093654 , acc is: 0.03125 , iter= 7304
current loss is: 4.059702 , acc is: 0.046875 , iter= 7305
current loss is: 4.1260643 , acc is: 0.015625 , iter= 7306
current loss is: 4.074626 , acc is: 0.015625 , iter= 7307
current loss is: 4.0748024 , acc is: 0.03125 , iter= 7308
current loss is: 4.089057 , acc is: 0.03125 , iter= 7309
current loss is: 4.1131487 , acc is: 0.015625 , iter= 7310
current loss is: 4.027258 , acc is: 0.03125 , iter= 7311
current loss is: 4.1249256 , acc is: 0.03125 , iter= 7312
current loss is: 4.1301584 , acc is: 0.03125 , iter= 7313
current loss is: 4.1497116 , acc is: 0.03125 , iter= 7314
current loss is: 4.1231003 , acc is: 0.0 , iter= 7315
current loss is: 4.0495553 , acc is: 0.03125 , iter= 7316
current loss is: 4.1843085 , acc is: 0.0 , iter= 7317
current loss is: 4.0784664 , acc is: 0.015625 , iter= 7318
current loss is: 3.9818249 , acc is: 0.0625 , iter= 7319
current loss is: 4.031493 , acc is: 0.0625 , iter= 7320
current loss is: 4.0496407 , acc is: 0.046875 , iter= 7321
current loss is: 4.127925 , acc is: 0.03125 , iter= 7322
current loss is: 4.067119 , acc is: 0.046875 , iter= 7323
current loss is: 4.1490545 , acc is: 0.046875 , iter= 7324
current loss is: 4.1351156 , acc is: 0.015625 , iter= 7325
current loss is: 4.0328417 , acc is: 0.015625 , iter= 7326
current loss is: 4.0095835 , acc is: 0.078125 , iter= 7327
current loss is: 4.014806 , acc is: 0.03125 , iter= 7328
current loss is: 4.1102104 , acc is: 0.03125 , iter= 7329
current loss is: 4.0772405 , acc is: 0.0625 , iter= 7330
current loss is: 4.0441904 , acc is: 0.015625 , iter= 7331
current loss is: 4.127273 , acc is: 0.03125 , iter= 7332
current loss is: 4.0436373 , acc is: 0.03125 , iter= 7333
current loss is: 4.0663595 , acc is: 0.046875 , iter= 7334
current loss is: 4.06042 , acc is: 0.03125 , iter= 7335
current loss is: 4.1593266 , acc is: 0.015625 , iter= 7336
current loss is: 4.163391 , acc is: 0.03125 , iter= 7337
current loss is: 4.185207 , acc is: 0.0 , iter= 7338
current loss is: 4.2040434 , acc is: 0.0 , iter= 7339
current loss is: 4.16675 , acc is: 0.015625 , iter= 7340
current loss is: 4.090126 , acc is: 0.0625 , iter= 7341
current loss is: 3.9326563 , acc is: 0.078125 , iter= 7342
current loss is: 4.0203047 , acc is: 0.0625 , iter= 7343
current loss is: 4.0082664 , acc is: 0.046875 , iter= 7344
current loss is: 4.0181575 , acc is: 0.046875 , iter= 7345
current loss is: 4.064392 , acc is: 0.0625 , iter= 7346
current loss is: 4.0338044 , acc is: 0.0625 , iter= 7347
current loss is: 4.070385 , acc is: 0.046875 , iter= 7348
current loss is: 4.1249313 , acc is: 0.015625 , iter= 7349
current loss is: 4.0800414 , acc is: 0.046875 , iter= 7350
current loss is: 4.1117287 , acc is: 0.03125 , iter= 7351
current loss is: 4.135956 , acc is: 0.015625 , iter= 7352
current loss is: 4.090125 , acc is: 0.03125 , iter= 7353
current loss is: 4.0719695 , acc is: 0.015625 , iter= 7354
current loss is: 4.051775 , acc is: 0.015625 , iter= 7355
current loss is: 3.9540932 , acc is: 0.078125 , iter= 7356
current loss is: 3.961802 , acc is: 0.078125 , iter= 7357
current loss is: 4.0650654 , acc is: 0.015625 , iter= 7358
current loss is: 3.9698043 , acc is: 0.0625 , iter= 7359
current loss is: 4.148571 , acc is: 0.0 , iter= 7360
current loss is: 4.224596 , acc is: 0.0 , iter= 7361
current loss is: 4.0544987 , acc is: 0.09375 , iter= 7362
current loss is: 4.109202 , acc is: 0.046875 , iter= 7363
current loss is: 4.145114 , acc is: 0.0 , iter= 7364
current loss is: 3.9692388 , acc is: 0.046875 , iter= 7365
current loss is: 4.1430407 , acc is: 0.046875 , iter= 7366
current loss is: 4.0759583 , acc is: 0.03125 , iter= 7367
current loss is: 4.101486 , acc is: 0.046875 , iter= 7368
current loss is: 4.0774565 , acc is: 0.03125 , iter= 7369
current loss is: 4.0843563 , acc is: 0.015625 , iter= 7370
current loss is: 4.099794 , acc is: 0.03125 , iter= 7371
current loss is: 4.0662394 , acc is: 0.046875 , iter= 7372
current loss is: 4.0508757 , acc is: 0.0625 , iter= 7373
current loss is: 3.9664493 , acc is: 0.0625 , iter= 7374
current loss is: 4.0474224 , acc is: 0.0625 , iter= 7375
current loss is: 4.1494246 , acc is: 0.015625 , iter= 7376
current loss is: 4.0997877 , acc is: 0.015625 , iter= 7377
current loss is: 4.151037 , acc is: 0.03125 , iter= 7378
current loss is: 4.1260138 , acc is: 0.03125 , iter= 7379
current loss is: 4.0992165 , acc is: 0.046875 , iter= 7380
current loss is: 4.183882 , acc is: 0.0 , iter= 7381
current loss is: 4.079545 , acc is: 0.015625 , iter= 7382
current loss is: 4.1030636 , acc is: 0.046875 , iter= 7383
current loss is: 4.1526365 , acc is: 0.03125 , iter= 7384
current loss is: 4.11761 , acc is: 0.046875 , iter= 7385
current loss is: 4.1154966 , acc is: 0.0625 , iter= 7386
current loss is: 4.0155125 , acc is: 0.03125 , iter= 7387
current loss is: 4.141364 , acc is: 0.0 , iter= 7388
current loss is: 4.1578608 , acc is: 0.046875 , iter= 7389
current loss is: 3.9752557 , acc is: 0.0625 , iter= 7390
current loss is: 4.0942593 , acc is: 0.015625 , iter= 7391
current loss is: 4.1378064 , acc is: 0.046875 , iter= 7392
current loss is: 4.174198 , acc is: 0.03125 , iter= 7393
current loss is: 4.015163 , acc is: 0.046875 , iter= 7394
current loss is: 4.039693 , acc is: 0.015625 , iter= 7395
current loss is: 4.050799 , acc is: 0.078125 , iter= 7396
current loss is: 4.1525097 , acc is: 0.03125 , iter= 7397
current loss is: 4.086116 , acc is: 0.015625 , iter= 7398
current loss is: 3.983105 , acc is: 0.046875 , iter= 7399
current loss is: 3.9836094 , acc is: 0.09375 , iter= 7400
current loss is: 4.0325837 , acc is: 0.0625 , iter= 7401
current loss is: 4.133152 , acc is: 0.015625 , iter= 7402
current loss is: 4.073642 , acc is: 0.078125 , iter= 7403
current loss is: 3.929165 , acc is: 0.0625 , iter= 7404
current loss is: 4.1382556 , acc is: 0.0 , iter= 7405
current loss is: 4.1397057 , acc is: 0.0 , iter= 7406
current loss is: 4.0503526 , acc is: 0.046875 , iter= 7407
current loss is: 4.0765743 , acc is: 0.03125 , iter= 7408
current loss is: 4.126174 , acc is: 0.03125 , iter= 7409
current loss is: 4.126178 , acc is: 0.046875 , iter= 7410
current loss is: 4.09161 , acc is: 0.046875 , iter= 7411
current loss is: 3.9354522 , acc is: 0.0625 , iter= 7412
current loss is: 4.148057 , acc is: 0.015625 , iter= 7413
current loss is: 4.037074 , acc is: 0.078125 , iter= 7414
current loss is: 3.9591427 , acc is: 0.0625 , iter= 7415
current loss is: 3.974925 , acc is: 0.0625 , iter= 7416
current loss is: 4.200937 , acc is: 0.015625 , iter= 7417
current loss is: 4.159011 , acc is: 0.015625 , iter= 7418
current loss is: 4.0929146 , acc is: 0.046875 , iter= 7419
current loss is: 4.0432067 , acc is: 0.03125 , iter= 7420
current loss is: 4.1638207 , acc is: 0.03125 , iter= 7421
current loss is: 4.080819 , acc is: 0.046875 , iter= 7422
current loss is: 4.163389 , acc is: 0.015625 , iter= 7423
current loss is: 4.1328464 , acc is: 0.015625 , iter= 7424
current loss is: 4.114562 , acc is: 0.03125 , iter= 7425
current loss is: 4.169096 , acc is: 0.046875 , iter= 7426
current loss is: 4.185034 , acc is: 0.0 , iter= 7427
current loss is: 4.124175 , acc is: 0.015625 , iter= 7428
current loss is: 4.0864706 , acc is: 0.03125 , iter= 7429
current loss is: 4.042813 , acc is: 0.015625 , iter= 7430
current loss is: 4.1656313 , acc is: 0.015625 , iter= 7431
current loss is: 3.969862 , acc is: 0.0625 , iter= 7432
current loss is: 4.236391 , acc is: 0.0 , iter= 7433
current loss is: 3.994131 , acc is: 0.078125 , iter= 7434
current loss is: 4.1183987 , acc is: 0.015625 , iter= 7435
current loss is: 4.060027 , acc is: 0.015625 , iter= 7436
current loss is: 4.136747 , acc is: 0.03125 , iter= 7437
current loss is: 4.0795774 , acc is: 0.015625 , iter= 7438
current loss is: 3.9677215 , acc is: 0.078125 , iter= 7439
current loss is: 4.1624 , acc is: 0.0 , iter= 7440
current loss is: 4.090413 , acc is: 0.015625 , iter= 7441
current loss is: 4.1559763 , acc is: 0.0 , iter= 7442
current loss is: 4.0945716 , acc is: 0.015625 , iter= 7443
current loss is: 4.0602646 , acc is: 0.015625 , iter= 7444
current loss is: 4.01479 , acc is: 0.03125 , iter= 7445
current loss is: 4.0670977 , acc is: 0.046875 , iter= 7446
current loss is: 4.1219645 , acc is: 0.046875 , iter= 7447
current loss is: 4.168605 , acc is: 0.03125 , iter= 7448
current loss is: 4.036868 , acc is: 0.03125 , iter= 7449
current loss is: 4.0944424 , acc is: 0.015625 , iter= 7450
current loss is: 3.987792 , acc is: 0.046875 , iter= 7451
current loss is: 4.1449223 , acc is: 0.0 , iter= 7452
current loss is: 4.069727 , acc is: 0.046875 , iter= 7453
current loss is: 4.0810156 , acc is: 0.015625 , iter= 7454
current loss is: 4.035386 , acc is: 0.046875 , iter= 7455
current loss is: 4.1302743 , acc is: 0.0 , iter= 7456
current loss is: 4.1421313 , acc is: 0.046875 , iter= 7457
current loss is: 4.091605 , acc is: 0.03125 , iter= 7458
current loss is: 4.008517 , acc is: 0.0625 , iter= 7459
current loss is: 3.926495 , acc is: 0.09375 , iter= 7460
current loss is: 4.15626 , acc is: 0.015625 , iter= 7461
current loss is: 4.009982 , acc is: 0.09375 , iter= 7462
current loss is: 4.0151625 , acc is: 0.0625 , iter= 7463
current loss is: 4.0537157 , acc is: 0.015625 , iter= 7464
current loss is: 3.9879277 , acc is: 0.0625 , iter= 7465
current loss is: 4.0654964 , acc is: 0.046875 , iter= 7466
current loss is: 4.1759653 , acc is: 0.0 , iter= 7467
current loss is: 4.174436 , acc is: 0.046875 , iter= 7468
current loss is: 4.1085844 , acc is: 0.015625 , iter= 7469
current loss is: 4.105858 , acc is: 0.03125 , iter= 7470
current loss is: 4.0777965 , acc is: 0.046875 , iter= 7471
current loss is: 4.0639534 , acc is: 0.0625 , iter= 7472
current loss is: 3.8923478 , acc is: 0.0625 , iter= 7473
current loss is: 4.0026693 , acc is: 0.046875 , iter= 7474
current loss is: 4.0905037 , acc is: 0.015625 , iter= 7475
current loss is: 3.9423609 , acc is: 0.046875 , iter= 7476
current loss is: 4.136101 , acc is: 0.015625 , iter= 7477
current loss is: 4.1234913 , acc is: 0.015625 , iter= 7478
current loss is: 4.0775466 , acc is: 0.03125 , iter= 7479
current loss is: 4.1201973 , acc is: 0.015625 , iter= 7480
current loss is: 4.166814 , acc is: 0.015625 , iter= 7481
current loss is: 4.1672583 , acc is: 0.015625 , iter= 7482
current loss is: 4.1725082 , acc is: 0.015625 , iter= 7483
current loss is: 4.156334 , acc is: 0.03125 , iter= 7484
current loss is: 4.166014 , acc is: 0.015625 , iter= 7485
current loss is: 4.102762 , acc is: 0.015625 , iter= 7486
current loss is: 4.026004 , acc is: 0.0625 , iter= 7487
current loss is: 4.142187 , acc is: 0.015625 , iter= 7488
current loss is: 4.1276903 , acc is: 0.0625 , iter= 7489
current loss is: 4.21229 , acc is: 0.03125 , iter= 7490
current loss is: 4.091921 , acc is: 0.03125 , iter= 7491
current loss is: 4.013532 , acc is: 0.046875 , iter= 7492
current loss is: 4.17763 , acc is: 0.0 , iter= 7493
current loss is: 4.083694 , acc is: 0.046875 , iter= 7494
current loss is: 4.1636686 , acc is: 0.015625 , iter= 7495
current loss is: 3.9603953 , acc is: 0.0625 , iter= 7496
current loss is: 4.1624045 , acc is: 0.03125 , iter= 7497
current loss is: 4.1613665 , acc is: 0.0 , iter= 7498
current loss is: 4.0867863 , acc is: 0.015625 , iter= 7499
current loss is: 4.0833173 , acc is: 0.015625 , iter= 7500
current loss is: 4.084963 , acc is: 0.03125 , iter= 7501
current loss is: 4.1369476 , acc is: 0.015625 , iter= 7502
current loss is: 4.0562553 , acc is: 0.046875 , iter= 7503
current loss is: 4.1268005 , acc is: 0.03125 , iter= 7504
current loss is: 4.133718 , acc is: 0.0 , iter= 7505
current loss is: 4.072014 , acc is: 0.125 , iter= 7506
current loss is: 3.8797252 , acc is: 0.0625 , iter= 7507
current loss is: 4.061779 , acc is: 0.015625 , iter= 7508
current loss is: 3.9247503 , acc is: 0.078125 , iter= 7509
current loss is: 4.0800138 , acc is: 0.03125 , iter= 7510
current loss is: 4.13972 , acc is: 0.0625 , iter= 7511
current loss is: 4.13965 , acc is: 0.015625 , iter= 7512
current loss is: 4.1732025 , acc is: 0.0 , iter= 7513
current loss is: 4.1835637 , acc is: 0.015625 , iter= 7514
current loss is: 4.1626983 , acc is: 0.03125 , iter= 7515
current loss is: 4.1416144 , acc is: 0.015625 , iter= 7516
current loss is: 4.0919724 , acc is: 0.03125 , iter= 7517
current loss is: 4.18657 , acc is: 0.0 , iter= 7518
current loss is: 4.158841 , acc is: 0.015625 , iter= 7519
current loss is: 4.090952 , acc is: 0.03125 , iter= 7520
current loss is: 4.03553 , acc is: 0.046875 , iter= 7521
current loss is: 4.050643 , acc is: 0.046875 , iter= 7522
current loss is: 4.076123 , acc is: 0.03125 , iter= 7523
current loss is: 4.0878663 , acc is: 0.015625 , iter= 7524
current loss is: 4.0625668 , acc is: 0.046875 , iter= 7525
current loss is: 4.0042877 , acc is: 0.0625 , iter= 7526
current loss is: 4.126774 , acc is: 0.015625 , iter= 7527
current loss is: 4.1043863 , acc is: 0.015625 , iter= 7528
current loss is: 4.062566 , acc is: 0.046875 , iter= 7529
current loss is: 4.160219 , acc is: 0.03125 , iter= 7530
current loss is: 4.176831 , acc is: 0.0 , iter= 7531
current loss is: 4.0786633 , acc is: 0.046875 , iter= 7532
current loss is: 4.1301603 , acc is: 0.03125 , iter= 7533
current loss is: 4.161538 , acc is: 0.046875 , iter= 7534
current loss is: 4.099662 , acc is: 0.015625 , iter= 7535
current loss is: 4.1483793 , acc is: 0.03125 , iter= 7536
current loss is: 3.9565244 , acc is: 0.0625 , iter= 7537
current loss is: 4.068166 , acc is: 0.03125 , iter= 7538
current loss is: 4.108509 , acc is: 0.015625 , iter= 7539
current loss is: 4.110441 , acc is: 0.015625 , iter= 7540
current loss is: 4.1104517 , acc is: 0.046875 , iter= 7541
current loss is: 4.065637 , acc is: 0.015625 , iter= 7542
current loss is: 4.1519475 , acc is: 0.03125 , iter= 7543
current loss is: 4.1371303 , acc is: 0.0 , iter= 7544
current loss is: 4.1033964 , acc is: 0.03125 , iter= 7545
current loss is: 3.934299 , acc is: 0.0625 , iter= 7546
current loss is: 4.16448 , acc is: 0.03125 , iter= 7547
current loss is: 4.0129237 , acc is: 0.03125 , iter= 7548
current loss is: 3.952859 , acc is: 0.046875 , iter= 7549
current loss is: 4.0456276 , acc is: 0.046875 , iter= 7550
current loss is: 4.053008 , acc is: 0.015625 , iter= 7551
current loss is: 4.0830054 , acc is: 0.03125 , iter= 7552
current loss is: 4.0810847 , acc is: 0.0 , iter= 7553
current loss is: 4.0987306 , acc is: 0.0625 , iter= 7554
current loss is: 3.9928305 , acc is: 0.078125 , iter= 7555
current loss is: 4.0471983 , acc is: 0.03125 , iter= 7556
current loss is: 3.9866047 , acc is: 0.078125 , iter= 7557
current loss is: 4.1565595 , acc is: 0.015625 , iter= 7558
current loss is: 4.1470556 , acc is: 0.015625 , iter= 7559
current loss is: 4.1505346 , acc is: 0.0 , iter= 7560
current loss is: 4.0203924 , acc is: 0.046875 , iter= 7561
current loss is: 3.9890242 , acc is: 0.046875 , iter= 7562
current loss is: 4.1614776 , acc is: 0.03125 , iter= 7563
current loss is: 3.9958503 , acc is: 0.03125 , iter= 7564
current loss is: 4.128884 , acc is: 0.03125 , iter= 7565
current loss is: 4.1872606 , acc is: 0.0 , iter= 7566
current loss is: 4.133256 , acc is: 0.03125 , iter= 7567
current loss is: 4.1010847 , acc is: 0.03125 , iter= 7568
current loss is: 4.1068754 , acc is: 0.0625 , iter= 7569
current loss is: 4.1447835 , acc is: 0.03125 , iter= 7570
current loss is: 4.092756 , acc is: 0.046875 , iter= 7571
current loss is: 4.120599 , acc is: 0.015625 , iter= 7572
current loss is: 4.1291943 , acc is: 0.015625 , iter= 7573
current loss is: 3.9830675 , acc is: 0.03125 , iter= 7574
current loss is: 4.058984 , acc is: 0.03125 , iter= 7575
current loss is: 4.092034 , acc is: 0.0625 , iter= 7576
current loss is: 4.1359396 , acc is: 0.015625 , iter= 7577
current loss is: 4.104695 , acc is: 0.03125 , iter= 7578
current loss is: 4.1899548 , acc is: 0.03125 , iter= 7579
current loss is: 4.042694 , acc is: 0.03125 , iter= 7580
current loss is: 4.0618114 , acc is: 0.03125 , iter= 7581
current loss is: 4.04047 , acc is: 0.0625 , iter= 7582
current loss is: 3.9866734 , acc is: 0.0625 , iter= 7583
current loss is: 4.1757503 , acc is: 0.015625 , iter= 7584
current loss is: 4.1594744 , acc is: 0.03125 , iter= 7585
current loss is: 4.2060127 , acc is: 0.0 , iter= 7586
current loss is: 3.9371066 , acc is: 0.046875 , iter= 7587
current loss is: 4.1251597 , acc is: 0.03125 , iter= 7588
current loss is: 4.181778 , acc is: 0.03125 , iter= 7589
current loss is: 3.9934504 , acc is: 0.046875 , iter= 7590
current loss is: 4.116023 , acc is: 0.03125 , iter= 7591
current loss is: 4.1585646 , acc is: 0.015625 , iter= 7592
current loss is: 4.0436535 , acc is: 0.046875 , iter= 7593
current loss is: 4.163068 , acc is: 0.046875 , iter= 7594
current loss is: 4.1383333 , acc is: 0.015625 , iter= 7595
current loss is: 4.1824985 , acc is: 0.015625 , iter= 7596
current loss is: 4.0468264 , acc is: 0.046875 , iter= 7597
current loss is: 3.992853 , acc is: 0.046875 , iter= 7598
current loss is: 4.041082 , acc is: 0.03125 , iter= 7599
current loss is: 4.1328382 , acc is: 0.015625 , iter= 7600
current loss is: 4.061359 , acc is: 0.046875 , iter= 7601
current loss is: 4.093468 , acc is: 0.015625 , iter= 7602
current loss is: 4.1384206 , acc is: 0.0 , iter= 7603
current loss is: 4.0694284 , acc is: 0.03125 , iter= 7604
current loss is: 4.0265813 , acc is: 0.03125 , iter= 7605
current loss is: 4.0186915 , acc is: 0.03125 , iter= 7606
current loss is: 3.9917164 , acc is: 0.09375 , iter= 7607
current loss is: 3.9737551 , acc is: 0.046875 , iter= 7608
current loss is: 4.069107 , acc is: 0.015625 , iter= 7609
current loss is: 4.0007944 , acc is: 0.046875 , iter= 7610
current loss is: 4.022948 , acc is: 0.03125 , iter= 7611
current loss is: 4.10983 , acc is: 0.03125 , iter= 7612
current loss is: 4.097828 , acc is: 0.015625 , iter= 7613
current loss is: 4.0661306 , acc is: 0.046875 , iter= 7614
current loss is: 4.062872 , acc is: 0.03125 , iter= 7615
current loss is: 4.0598526 , acc is: 0.0625 , iter= 7616
current loss is: 4.122531 , acc is: 0.046875 , iter= 7617
current loss is: 4.1649914 , acc is: 0.015625 , iter= 7618
current loss is: 4.10494 , acc is: 0.03125 , iter= 7619
current loss is: 3.9561424 , acc is: 0.0625 , iter= 7620
current loss is: 4.0460925 , acc is: 0.046875 , iter= 7621
current loss is: 4.2296658 , acc is: 0.03125 , iter= 7622
current loss is: 4.0949373 , acc is: 0.015625 , iter= 7623
current loss is: 4.181222 , acc is: 0.03125 , iter= 7624
current loss is: 4.1396623 , acc is: 0.0 , iter= 7625
current loss is: 4.1543307 , acc is: 0.0 , iter= 7626
current loss is: 4.086753 , acc is: 0.046875 , iter= 7627
current loss is: 4.1986766 , acc is: 0.03125 , iter= 7628
current loss is: 4.0821223 , acc is: 0.03125 , iter= 7629
current loss is: 4.188639 , acc is: 0.015625 , iter= 7630
current loss is: 4.0725374 , acc is: 0.015625 , iter= 7631
current loss is: 4.078445 , acc is: 0.046875 , iter= 7632
current loss is: 4.077502 , acc is: 0.015625 , iter= 7633
current loss is: 4.088498 , acc is: 0.03125 , iter= 7634
current loss is: 4.1337833 , acc is: 0.015625 , iter= 7635
current loss is: 4.0571237 , acc is: 0.03125 , iter= 7636
current loss is: 4.1491785 , acc is: 0.015625 , iter= 7637
current loss is: 3.9940076 , acc is: 0.09375 , iter= 7638
current loss is: 4.0701494 , acc is: 0.03125 , iter= 7639
current loss is: 4.1789393 , acc is: 0.046875 , iter= 7640
current loss is: 4.0738964 , acc is: 0.03125 , iter= 7641
current loss is: 4.1437016 , acc is: 0.0 , iter= 7642
current loss is: 4.138072 , acc is: 0.0 , iter= 7643
current loss is: 4.0906525 , acc is: 0.046875 , iter= 7644
current loss is: 4.025414 , acc is: 0.046875 , iter= 7645
current loss is: 4.0945797 , acc is: 0.03125 , iter= 7646
current loss is: 4.105714 , acc is: 0.015625 , iter= 7647
current loss is: 4.069438 , acc is: 0.046875 , iter= 7648
current loss is: 4.223614 , acc is: 0.0 , iter= 7649
current loss is: 4.0378494 , acc is: 0.03125 , iter= 7650
current loss is: 3.9593794 , acc is: 0.0625 , iter= 7651
current loss is: 3.976183 , acc is: 0.046875 , iter= 7652
current loss is: 4.19551 , acc is: 0.015625 , iter= 7653
current loss is: 4.1353874 , acc is: 0.015625 , iter= 7654
current loss is: 4.101179 , acc is: 0.03125 , iter= 7655
current loss is: 4.150034 , acc is: 0.03125 , iter= 7656
current loss is: 4.0119863 , acc is: 0.03125 , iter= 7657
current loss is: 4.1580467 , acc is: 0.046875 , iter= 7658
current loss is: 4.1110163 , acc is: 0.015625 , iter= 7659
current loss is: 4.107834 , acc is: 0.015625 , iter= 7660
current loss is: 4.0839715 , acc is: 0.046875 , iter= 7661
current loss is: 4.092535 , acc is: 0.015625 , iter= 7662
current loss is: 4.0997124 , acc is: 0.03125 , iter= 7663
current loss is: 4.010865 , acc is: 0.046875 , iter= 7664
current loss is: 4.1137033 , acc is: 0.078125 , iter= 7665
current loss is: 3.9386106 , acc is: 0.0625 , iter= 7666
current loss is: 4.091401 , acc is: 0.03125 , iter= 7667
current loss is: 3.976234 , acc is: 0.046875 , iter= 7668
current loss is: 4.199239 , acc is: 0.03125 , iter= 7669
current loss is: 4.1734524 , acc is: 0.0 , iter= 7670
current loss is: 4.070412 , acc is: 0.078125 , iter= 7671
current loss is: 4.093122 , acc is: 0.03125 , iter= 7672
current loss is: 3.9500403 , acc is: 0.046875 , iter= 7673
current loss is: 4.168851 , acc is: 0.015625 , iter= 7674
current loss is: 4.1300473 , acc is: 0.015625 , iter= 7675
current loss is: 4.181341 , acc is: 0.03125 , iter= 7676
current loss is: 4.1842256 , acc is: 0.015625 , iter= 7677
current loss is: 4.1255074 , acc is: 0.0 , iter= 7678
current loss is: 4.186592 , acc is: 0.0 , iter= 7679
current loss is: 4.128218 , acc is: 0.015625 , iter= 7680
current loss is: 4.1307364 , acc is: 0.03125 , iter= 7681
current loss is: 3.9718785 , acc is: 0.09375 , iter= 7682
current loss is: 4.1674166 , acc is: 0.0 , iter= 7683
current loss is: 4.098545 , acc is: 0.03125 , iter= 7684
current loss is: 4.1803627 , acc is: 0.0 , iter= 7685
current loss is: 4.151964 , acc is: 0.0 , iter= 7686
current loss is: 4.100949 , acc is: 0.03125 , iter= 7687
current loss is: 3.9540544 , acc is: 0.0625 , iter= 7688
current loss is: 4.1342654 , acc is: 0.0 , iter= 7689
current loss is: 4.1447577 , acc is: 0.015625 , iter= 7690
current loss is: 3.9595618 , acc is: 0.0625 , iter= 7691
current loss is: 4.089319 , acc is: 0.015625 , iter= 7692
current loss is: 3.999386 , acc is: 0.046875 , iter= 7693
current loss is: 4.15145 , acc is: 0.03125 , iter= 7694
current loss is: 4.1196823 , acc is: 0.0 , iter= 7695
current loss is: 4.0709996 , acc is: 0.03125 , iter= 7696
current loss is: 4.047829 , acc is: 0.03125 , iter= 7697
current loss is: 4.085112 , acc is: 0.015625 , iter= 7698
current loss is: 4.060175 , acc is: 0.015625 , iter= 7699
current loss is: 4.0628614 , acc is: 0.03125 , iter= 7700
current loss is: 3.9866023 , acc is: 0.09375 , iter= 7701
current loss is: 4.229591 , acc is: 0.03125 , iter= 7702
current loss is: 4.2173367 , acc is: 0.03125 , iter= 7703
current loss is: 4.13683 , acc is: 0.03125 , iter= 7704
current loss is: 4.159221 , acc is: 0.015625 , iter= 7705
current loss is: 4.0752497 , acc is: 0.03125 , iter= 7706
current loss is: 4.1684084 , acc is: 0.03125 , iter= 7707
current loss is: 4.0917406 , acc is: 0.046875 , iter= 7708
current loss is: 4.153186 , acc is: 0.015625 , iter= 7709
current loss is: 3.9991026 , acc is: 0.078125 , iter= 7710
current loss is: 4.065428 , acc is: 0.03125 , iter= 7711
current loss is: 4.148494 , acc is: 0.0 , iter= 7712
current loss is: 3.9433851 , acc is: 0.046875 , iter= 7713
current loss is: 4.0713534 , acc is: 0.03125 , iter= 7714
current loss is: 4.0646973 , acc is: 0.03125 , iter= 7715
current loss is: 3.9780102 , acc is: 0.078125 , iter= 7716
current loss is: 3.993338 , acc is: 0.078125 , iter= 7717
current loss is: 4.0628057 , acc is: 0.078125 , iter= 7718
current loss is: 4.1114264 , acc is: 0.0 , iter= 7719
current loss is: 4.043376 , acc is: 0.046875 , iter= 7720
current loss is: 4.041686 , acc is: 0.015625 , iter= 7721
current loss is: 4.067661 , acc is: 0.0 , iter= 7722
current loss is: 4.1834207 , acc is: 0.015625 , iter= 7723
current loss is: 4.1342278 , acc is: 0.015625 , iter= 7724
current loss is: 4.109057 , acc is: 0.046875 , iter= 7725
current loss is: 4.1254263 , acc is: 0.0 , iter= 7726
current loss is: 4.008233 , acc is: 0.0625 , iter= 7727
current loss is: 4.0908985 , acc is: 0.03125 , iter= 7728
current loss is: 4.067627 , acc is: 0.015625 , iter= 7729
current loss is: 4.113367 , acc is: 0.03125 , iter= 7730
current loss is: 4.0533085 , acc is: 0.03125 , iter= 7731
current loss is: 4.076641 , acc is: 0.0625 , iter= 7732
current loss is: 4.0939083 , acc is: 0.0 , iter= 7733
current loss is: 3.8995502 , acc is: 0.09375 , iter= 7734
current loss is: 4.1485996 , acc is: 0.0 , iter= 7735
current loss is: 4.110015 , acc is: 0.03125 , iter= 7736
current loss is: 4.05149 , acc is: 0.015625 , iter= 7737
current loss is: 4.1905675 , acc is: 0.015625 , iter= 7738
current loss is: 4.1220984 , acc is: 0.046875 , iter= 7739
current loss is: 4.0659876 , acc is: 0.046875 , iter= 7740
current loss is: 4.037155 , acc is: 0.046875 , iter= 7741
current loss is: 4.142121 , acc is: 0.03125 , iter= 7742
current loss is: 4.1897306 , acc is: 0.015625 , iter= 7743
current loss is: 4.0939903 , acc is: 0.046875 , iter= 7744
current loss is: 3.9597626 , acc is: 0.03125 , iter= 7745
current loss is: 4.123183 , acc is: 0.015625 , iter= 7746
current loss is: 4.256398 , acc is: 0.0 , iter= 7747
current loss is: 4.049759 , acc is: 0.03125 , iter= 7748
current loss is: 4.0876017 , acc is: 0.0625 , iter= 7749
current loss is: 4.085536 , acc is: 0.03125 , iter= 7750
current loss is: 4.119979 , acc is: 0.03125 , iter= 7751
current loss is: 4.0941 , acc is: 0.015625 , iter= 7752
current loss is: 3.9429536 , acc is: 0.09375 , iter= 7753
current loss is: 4.122794 , acc is: 0.015625 , iter= 7754
current loss is: 4.1325517 , acc is: 0.015625 , iter= 7755
current loss is: 4.0020266 , acc is: 0.078125 , iter= 7756
current loss is: 4.0846014 , acc is: 0.0625 , iter= 7757
current loss is: 3.9854093 , acc is: 0.03125 , iter= 7758
current loss is: 4.057373 , acc is: 0.0625 , iter= 7759
current loss is: 3.9903994 , acc is: 0.046875 , iter= 7760
current loss is: 4.162328 , acc is: 0.0 , iter= 7761
current loss is: 4.1702547 , acc is: 0.03125 , iter= 7762
current loss is: 8.53064 , acc is: 0.046875 , iter= 7763
current loss is: 4.0690765 , acc is: 0.015625 , iter= 7764
current loss is: 4.1159143 , acc is: 0.015625 , iter= 7765
current loss is: 4.113093 , acc is: 0.015625 , iter= 7766
current loss is: 4.0963264 , acc is: 0.015625 , iter= 7767
current loss is: 4.1279798 , acc is: 0.03125 , iter= 7768
current loss is: 4.1611853 , acc is: 0.015625 , iter= 7769
current loss is: 4.087793 , acc is: 0.015625 , iter= 7770
current loss is: 4.075464 , acc is: 0.03125 , iter= 7771
current loss is: 4.0960803 , acc is: 0.03125 , iter= 7772
current loss is: 8.122698 , acc is: 0.0 , iter= 7773
current loss is: 4.2341175 , acc is: 0.015625 , iter= 7774
current loss is: 6.090006 , acc is: 0.0625 , iter= 7775
current loss is: 4.0860844 , acc is: 0.015625 , iter= 7776
current loss is: 4.064169 , acc is: 0.0625 , iter= 7777
current loss is: 4.2300024 , acc is: 0.03125 , iter= 7778
current loss is: 4.1163826 , acc is: 0.015625 , iter= 7779
current loss is: 3.93583 , acc is: 0.046875 , iter= 7780
current loss is: 4.070034 , acc is: 0.03125 , iter= 7781
current loss is: 4.094988 , acc is: 0.015625 , iter= 7782
current loss is: 4.0757995 , acc is: 0.015625 , iter= 7783
current loss is: 4.1556177 , acc is: 0.03125 , iter= 7784
current loss is: 4.172677 , acc is: 0.0 , iter= 7785
current loss is: 4.0539994 , acc is: 0.03125 , iter= 7786
current loss is: 4.135642 , acc is: 0.046875 , iter= 7787
current loss is: 4.063445 , acc is: 0.015625 , iter= 7788
current loss is: 4.096328 , acc is: 0.0625 , iter= 7789
current loss is: 4.107095 , acc is: 0.0625 , iter= 7790
current loss is: 4.2010174 , acc is: 0.015625 , iter= 7791
current loss is: 4.233327 , acc is: 0.0 , iter= 7792
current loss is: 4.224925 , acc is: 0.03125 , iter= 7793
current loss is: 4.0811973 , acc is: 0.046875 , iter= 7794
current loss is: 4.1180286 , acc is: 0.03125 , iter= 7795
current loss is: 4.1219187 , acc is: 0.0625 , iter= 7796
current loss is: 4.0822334 , acc is: 0.015625 , iter= 7797
current loss is: 4.0346346 , acc is: 0.03125 , iter= 7798
current loss is: 4.127589 , acc is: 0.03125 , iter= 7799
current loss is: 4.1209326 , acc is: 0.0 , iter= 7800
current loss is: 4.105421 , acc is: 0.015625 , iter= 7801
current loss is: 4.1131 , acc is: 0.015625 , iter= 7802
current loss is: 4.187018 , acc is: 0.0 , iter= 7803
current loss is: 3.9599602 , acc is: 0.046875 , iter= 7804
current loss is: 4.1860476 , acc is: 0.0 , iter= 7805
current loss is: 4.1781535 , acc is: 0.015625 , iter= 7806
current loss is: 3.800012 , acc is: 0.140625 , iter= 7807
current loss is: 4.1220455 , acc is: 0.015625 , iter= 7808
current loss is: 9.268839 , acc is: 0.0 , iter= 7809
current loss is: 4.08771 , acc is: 0.0 , iter= 7810
current loss is: 4.1134515 , acc is: 0.015625 , iter= 7811
current loss is: 4.206469 , acc is: 0.015625 , iter= 7812
current loss is: 4.164429 , acc is: 0.0 , iter= 7813
current loss is: 4.1244345 , acc is: 0.078125 , iter= 7814
current loss is: 4.1514735 , acc is: 0.015625 , iter= 7815
current loss is: 4.1738877 , acc is: 0.03125 , iter= 7816
current loss is: 4.1286745 , acc is: 0.015625 , iter= 7817
current loss is: 4.15108 , acc is: 0.0 , iter= 7818
current loss is: 4.0869026 , acc is: 0.046875 , iter= 7819
current loss is: 4.1286273 , acc is: 0.03125 , iter= 7820
current loss is: 4.0374146 , acc is: 0.046875 , iter= 7821
current loss is: 4.1219006 , acc is: 0.0 , iter= 7822
current loss is: 4.0946865 , acc is: 0.03125 , iter= 7823
current loss is: 4.164115 , acc is: 0.015625 , iter= 7824
current loss is: 4.1484194 , acc is: 0.046875 , iter= 7825
current loss is: 3.9747543 , acc is: 0.0625 , iter= 7826
current loss is: 4.0943594 , acc is: 0.046875 , iter= 7827
current loss is: 4.1839027 , acc is: 0.03125 , iter= 7828
current loss is: 3.9899442 , acc is: 0.0625 , iter= 7829
current loss is: 4.059327 , acc is: 0.0625 , iter= 7830
current loss is: 4.147835 , acc is: 0.0 , iter= 7831
current loss is: 4.1513286 , acc is: 0.0 , iter= 7832
current loss is: 4.0394573 , acc is: 0.0625 , iter= 7833
current loss is: 4.265236 , acc is: 0.015625 , iter= 7834
current loss is: 4.155832 , acc is: 0.015625 , iter= 7835
current loss is: 4.0102673 , acc is: 0.046875 , iter= 7836
current loss is: 4.008055 , acc is: 0.0625 , iter= 7837
current loss is: 4.0937724 , acc is: 0.03125 , iter= 7838
current loss is: 4.0473714 , acc is: 0.0625 , iter= 7839
current loss is: 3.895152 , acc is: 0.078125 , iter= 7840
current loss is: 4.061205 , acc is: 0.0625 , iter= 7841
current loss is: 4.157064 , acc is: 0.015625 , iter= 7842
current loss is: 4.080368 , acc is: 0.03125 , iter= 7843
current loss is: 4.1330695 , acc is: 0.046875 , iter= 7844
current loss is: 4.115678 , acc is: 0.03125 , iter= 7845
current loss is: 4.0893497 , acc is: 0.03125 , iter= 7846
current loss is: 4.0592947 , acc is: 0.0625 , iter= 7847
current loss is: 4.1320705 , acc is: 0.015625 , iter= 7848
current loss is: 4.2231827 , acc is: 0.0 , iter= 7849
current loss is: 4.0983896 , acc is: 0.046875 , iter= 7850
current loss is: 4.100545 , acc is: 0.0 , iter= 7851
current loss is: 4.160206 , acc is: 0.046875 , iter= 7852
current loss is: 4.14083 , acc is: 0.046875 , iter= 7853
current loss is: 4.084638 , acc is: 0.046875 , iter= 7854
current loss is: 4.023551 , acc is: 0.03125 , iter= 7855
current loss is: 4.1436863 , acc is: 0.078125 , iter= 7856
current loss is: 4.048648 , acc is: 0.046875 , iter= 7857
current loss is: 4.0622168 , acc is: 0.03125 , iter= 7858
current loss is: 4.06841 , acc is: 0.0625 , iter= 7859
current loss is: 4.1330776 , acc is: 0.015625 , iter= 7860
current loss is: 4.1141562 , acc is: 0.015625 , iter= 7861
current loss is: 4.3388233 , acc is: 0.03125 , iter= 7862
current loss is: 4.1586156 , acc is: 0.03125 , iter= 7863
current loss is: 4.021914 , acc is: 0.03125 , iter= 7864
current loss is: 4.192904 , acc is: 0.0 , iter= 7865
current loss is: 5.1426 , acc is: 0.03125 , iter= 7866
current loss is: 4.141496 , acc is: 0.03125 , iter= 7867
current loss is: 4.1577954 , acc is: 0.0625 , iter= 7868
current loss is: 4.1238275 , acc is: 0.015625 , iter= 7869
current loss is: 4.289551 , acc is: 0.046875 , iter= 7870
current loss is: 4.0674353 , acc is: 0.03125 , iter= 7871
current loss is: 4.15924 , acc is: 0.0 , iter= 7872
current loss is: 4.1855097 , acc is: 0.03125 , iter= 7873
current loss is: 4.16169 , acc is: 0.03125 , iter= 7874
current loss is: 4.19833 , acc is: 0.03125 , iter= 7875
current loss is: 4.10755 , acc is: 0.015625 , iter= 7876
current loss is: 4.0011425 , acc is: 0.03125 , iter= 7877
current loss is: 4.08196 , acc is: 0.015625 , iter= 7878
current loss is: 4.0410576 , acc is: 0.046875 , iter= 7879
current loss is: 4.151062 , acc is: 0.03125 , iter= 7880
current loss is: 4.1194386 , acc is: 0.046875 , iter= 7881
current loss is: 3.9795613 , acc is: 0.046875 , iter= 7882
current loss is: 4.2032604 , acc is: 0.03125 , iter= 7883
current loss is: 4.113086 , acc is: 0.015625 , iter= 7884
current loss is: 4.153079 , acc is: 0.015625 , iter= 7885
current loss is: 4.0894885 , acc is: 0.03125 , iter= 7886
current loss is: 4.141202 , acc is: 0.046875 , iter= 7887
current loss is: 4.1450553 , acc is: 0.015625 , iter= 7888
current loss is: 4.042196 , acc is: 0.046875 , iter= 7889
current loss is: 4.091236 , acc is: 0.03125 , iter= 7890
current loss is: 4.153076 , acc is: 0.046875 , iter= 7891
current loss is: 4.135275 , acc is: 0.015625 , iter= 7892
current loss is: 4.1092043 , acc is: 0.03125 , iter= 7893
current loss is: 4.1183414 , acc is: 0.0625 , iter= 7894
current loss is: 4.0309305 , acc is: 0.03125 , iter= 7895
current loss is: 4.09394 , acc is: 0.015625 , iter= 7896
current loss is: 4.066955 , acc is: 0.015625 , iter= 7897
current loss is: 4.109829 , acc is: 0.03125 , iter= 7898
current loss is: 4.1639023 , acc is: 0.03125 , iter= 7899
current loss is: 4.1674557 , acc is: 0.03125 , iter= 7900
current loss is: 4.0341682 , acc is: 0.03125 , iter= 7901
current loss is: 4.1588316 , acc is: 0.0 , iter= 7902
current loss is: 4.1074877 , acc is: 0.015625 , iter= 7903
current loss is: 3.980396 , acc is: 0.046875 , iter= 7904
current loss is: 4.07894 , acc is: 0.078125 , iter= 7905
current loss is: 4.067956 , acc is: 0.03125 , iter= 7906
current loss is: 4.0580473 , acc is: 0.046875 , iter= 7907
current loss is: 4.1099987 , acc is: 0.0625 , iter= 7908
current loss is: 4.1191063 , acc is: 0.0 , iter= 7909
current loss is: 4.0725303 , acc is: 0.0625 , iter= 7910
current loss is: 4.074929 , acc is: 0.0625 , iter= 7911
current loss is: 4.0791273 , acc is: 0.03125 , iter= 7912
current loss is: 4.016029 , acc is: 0.0625 , iter= 7913
current loss is: 4.105895 , acc is: 0.015625 , iter= 7914
current loss is: 4.1356516 , acc is: 0.03125 , iter= 7915
current loss is: 4.139085 , acc is: 0.0 , iter= 7916
current loss is: 4.0269933 , acc is: 0.03125 , iter= 7917
current loss is: 4.0534987 , acc is: 0.046875 , iter= 7918
current loss is: 4.133387 , acc is: 0.015625 , iter= 7919
current loss is: 4.0572095 , acc is: 0.015625 , iter= 7920
current loss is: 4.141599 , acc is: 0.0 , iter= 7921
current loss is: 4.131947 , acc is: 0.015625 , iter= 7922
current loss is: 4.010214 , acc is: 0.046875 , iter= 7923
current loss is: 4.1590495 , acc is: 0.03125 , iter= 7924
current loss is: 4.2221947 , acc is: 0.0 , iter= 7925
current loss is: 4.148999 , acc is: 0.03125 , iter= 7926
current loss is: 4.087995 , acc is: 0.046875 , iter= 7927
current loss is: 4.0802794 , acc is: 0.03125 , iter= 7928
current loss is: 4.0912066 , acc is: 0.015625 , iter= 7929
current loss is: 4.1774106 , acc is: 0.0 , iter= 7930
current loss is: 4.189053 , acc is: 0.03125 , iter= 7931
current loss is: 4.1201787 , acc is: 0.03125 , iter= 7932
current loss is: 4.0690145 , acc is: 0.03125 , iter= 7933
current loss is: 4.054814 , acc is: 0.015625 , iter= 7934
current loss is: 4.139476 , acc is: 0.015625 , iter= 7935
current loss is: 4.143445 , acc is: 0.03125 , iter= 7936
current loss is: 4.2557116 , acc is: 0.046875 , iter= 7937
current loss is: 4.1406817 , acc is: 0.015625 , iter= 7938
current loss is: 4.1426835 , acc is: 0.015625 , iter= 7939
current loss is: 4.154725 , acc is: 0.03125 , iter= 7940
current loss is: 4.0919275 , acc is: 0.03125 , iter= 7941
current loss is: 4.0826645 , acc is: 0.015625 , iter= 7942
current loss is: 4.104791 , acc is: 0.015625 , iter= 7943
current loss is: 4.117215 , acc is: 0.03125 , iter= 7944
current loss is: 3.9977348 , acc is: 0.046875 , iter= 7945
current loss is: 4.068243 , acc is: 0.015625 , iter= 7946
current loss is: 4.1091895 , acc is: 0.015625 , iter= 7947
current loss is: 4.167713 , acc is: 0.03125 , iter= 7948
current loss is: 4.1674986 , acc is: 0.015625 , iter= 7949
current loss is: 4.112176 , acc is: 0.03125 , iter= 7950
current loss is: 4.2001095 , acc is: 0.0 , iter= 7951
current loss is: 4.129213 , acc is: 0.015625 , iter= 7952
current loss is: 4.0902395 , acc is: 0.0625 , iter= 7953
current loss is: 4.1611958 , acc is: 0.015625 , iter= 7954
current loss is: 4.178191 , acc is: 0.015625 , iter= 7955
current loss is: 4.1365824 , acc is: 0.0 , iter= 7956
current loss is: 4.107452 , acc is: 0.109375 , iter= 7957
current loss is: 4.0876865 , acc is: 0.03125 , iter= 7958
current loss is: 4.137268 , acc is: 0.015625 , iter= 7959
current loss is: 4.0670767 , acc is: 0.0625 , iter= 7960
current loss is: 3.9590542 , acc is: 0.078125 , iter= 7961
current loss is: 4.153946 , acc is: 0.015625 , iter= 7962
current loss is: 4.1129837 , acc is: 0.0 , iter= 7963
current loss is: 4.102656 , acc is: 0.015625 , iter= 7964
current loss is: 4.1342735 , acc is: 0.03125 , iter= 7965
current loss is: 4.0061245 , acc is: 0.03125 , iter= 7966
current loss is: 4.0791044 , acc is: 0.0625 , iter= 7967
current loss is: 4.1217556 , acc is: 0.03125 , iter= 7968
current loss is: 4.0251017 , acc is: 0.03125 , iter= 7969
current loss is: 4.0309567 , acc is: 0.0625 , iter= 7970
current loss is: 4.178693 , acc is: 0.0 , iter= 7971
current loss is: 3.9768138 , acc is: 0.0625 , iter= 7972
current loss is: 4.1414127 , acc is: 0.015625 , iter= 7973
current loss is: 4.153158 , acc is: 0.0 , iter= 7974
current loss is: 4.0673456 , acc is: 0.03125 , iter= 7975
current loss is: 4.0498734 , acc is: 0.015625 , iter= 7976
current loss is: 4.032521 , acc is: 0.046875 , iter= 7977
current loss is: 4.0834227 , acc is: 0.03125 , iter= 7978
current loss is: 4.129782 , acc is: 0.03125 , iter= 7979
current loss is: 4.08306 , acc is: 0.03125 , iter= 7980
current loss is: 4.139471 , acc is: 0.03125 , iter= 7981
current loss is: 4.1818733 , acc is: 0.015625 , iter= 7982
current loss is: 4.145937 , acc is: 0.015625 , iter= 7983
current loss is: 4.0861206 , acc is: 0.015625 , iter= 7984
current loss is: 4.142021 , acc is: 0.015625 , iter= 7985
current loss is: 4.1404047 , acc is: 0.0625 , iter= 7986
current loss is: 4.0438013 , acc is: 0.03125 , iter= 7987
current loss is: 4.2070713 , acc is: 0.015625 , iter= 7988
current loss is: 4.099861 , acc is: 0.03125 , iter= 7989
current loss is: 4.0743117 , acc is: 0.03125 , iter= 7990
current loss is: 4.1063395 , acc is: 0.03125 , iter= 7991
current loss is: 4.150861 , acc is: 0.046875 , iter= 7992
current loss is: 4.0871544 , acc is: 0.015625 , iter= 7993
current loss is: 4.1254044 , acc is: 0.015625 , iter= 7994
current loss is: 4.09747 , acc is: 0.015625 , iter= 7995
current loss is: 3.8828778 , acc is: 0.09375 , iter= 7996
current loss is: 4.094388 , acc is: 0.03125 , iter= 7997
current loss is: 4.1846375 , acc is: 0.0625 , iter= 7998
current loss is: 4.1377854 , acc is: 0.03125 , iter= 7999
current loss is: 4.0027976 , acc is: 0.046875 , iter= 8000
tot_acc= 18.0 tot_input= 768
current accuracy is: 0.0234375
current loss is: 4.153771 , acc is: 0.046875 , iter= 8001
current loss is: 4.09289 , acc is: 0.046875 , iter= 8002
current loss is: 4.1483793 , acc is: 0.015625 , iter= 8003
current loss is: 4.148304 , acc is: 0.015625 , iter= 8004
current loss is: 4.126188 , acc is: 0.015625 , iter= 8005
current loss is: 4.12617 , acc is: 0.03125 , iter= 8006
current loss is: 4.1954827 , acc is: 0.0 , iter= 8007
current loss is: 4.0860724 , acc is: 0.015625 , iter= 8008
current loss is: 4.1303635 , acc is: 0.03125 , iter= 8009
current loss is: 4.073411 , acc is: 0.03125 , iter= 8010
current loss is: 4.1562986 , acc is: 0.0 , iter= 8011
current loss is: 4.1800947 , acc is: 0.046875 , iter= 8012
current loss is: 4.0637007 , acc is: 0.046875 , iter= 8013
current loss is: 4.1493073 , acc is: 0.015625 , iter= 8014
current loss is: 4.06396 , acc is: 0.078125 , iter= 8015
current loss is: 4.0805707 , acc is: 0.03125 , iter= 8016
current loss is: 4.1416907 , acc is: 0.015625 , iter= 8017
current loss is: 4.111726 , acc is: 0.0 , iter= 8018
current loss is: 4.1256595 , acc is: 0.015625 , iter= 8019
current loss is: 4.0330687 , acc is: 0.046875 , iter= 8020
current loss is: 4.086755 , acc is: 0.03125 , iter= 8021
current loss is: 4.051342 , acc is: 0.03125 , iter= 8022
current loss is: 4.063671 , acc is: 0.046875 , iter= 8023
current loss is: 4.0735683 , acc is: 0.015625 , iter= 8024
current loss is: 3.9478915 , acc is: 0.078125 , iter= 8025
current loss is: 4.0566063 , acc is: 0.0625 , iter= 8026
current loss is: 4.1008506 , acc is: 0.03125 , iter= 8027
current loss is: 4.1442947 , acc is: 0.0 , iter= 8028
current loss is: 4.0469055 , acc is: 0.03125 , iter= 8029
current loss is: 4.0111723 , acc is: 0.046875 , iter= 8030
current loss is: 4.151547 , acc is: 0.046875 , iter= 8031
current loss is: 4.116501 , acc is: 0.03125 , iter= 8032
current loss is: 4.1362615 , acc is: 0.015625 , iter= 8033
current loss is: 4.012192 , acc is: 0.0625 , iter= 8034
current loss is: 4.1305113 , acc is: 0.03125 , iter= 8035
current loss is: 4.1381216 , acc is: 0.03125 , iter= 8036
current loss is: 4.158001 , acc is: 0.0625 , iter= 8037
current loss is: 4.0603156 , acc is: 0.078125 , iter= 8038
current loss is: 4.079892 , acc is: 0.0 , iter= 8039
current loss is: 4.140839 , acc is: 0.03125 , iter= 8040
current loss is: 4.1141996 , acc is: 0.015625 , iter= 8041
current loss is: 4.141708 , acc is: 0.015625 , iter= 8042
current loss is: 4.1627846 , acc is: 0.03125 , iter= 8043
current loss is: 4.1242805 , acc is: 0.015625 , iter= 8044
current loss is: 4.1503286 , acc is: 0.015625 , iter= 8045
current loss is: 4.1927204 , acc is: 0.0 , iter= 8046
current loss is: 4.078001 , acc is: 0.03125 , iter= 8047
current loss is: 4.164837 , acc is: 0.03125 , iter= 8048
current loss is: 3.9976802 , acc is: 0.046875 , iter= 8049
current loss is: 4.033243 , acc is: 0.03125 , iter= 8050
current loss is: 4.0431175 , acc is: 0.109375 , iter= 8051
current loss is: 4.1622486 , acc is: 0.0 , iter= 8052
current loss is: 4.146291 , acc is: 0.0 , iter= 8053
current loss is: 4.1619864 , acc is: 0.015625 , iter= 8054
current loss is: 4.1083145 , acc is: 0.015625 , iter= 8055
current loss is: 4.0170784 , acc is: 0.03125 , iter= 8056
current loss is: 4.1556044 , acc is: 0.03125 , iter= 8057
current loss is: 4.120451 , acc is: 0.03125 , iter= 8058
current loss is: 4.135778 , acc is: 0.046875 , iter= 8059
current loss is: 3.982473 , acc is: 0.078125 , iter= 8060
current loss is: 4.083296 , acc is: 0.015625 , iter= 8061
current loss is: 3.968035 , acc is: 0.03125 , iter= 8062
current loss is: 4.086919 , acc is: 0.0625 , iter= 8063
current loss is: 4.0551567 , acc is: 0.046875 , iter= 8064
current loss is: 4.1406126 , acc is: 0.0 , iter= 8065
current loss is: 4.109394 , acc is: 0.015625 , iter= 8066
current loss is: 4.1082783 , acc is: 0.03125 , iter= 8067
current loss is: 4.184334 , acc is: 0.0 , iter= 8068
current loss is: 4.045071 , acc is: 0.03125 , iter= 8069
current loss is: 4.132817 , acc is: 0.046875 , iter= 8070
current loss is: 4.178641 , acc is: 0.0 , iter= 8071
current loss is: 4.0878887 , acc is: 0.046875 , iter= 8072
current loss is: 4.1881423 , acc is: 0.0 , iter= 8073
current loss is: 4.109885 , acc is: 0.046875 , iter= 8074
current loss is: 4.113435 , acc is: 0.015625 , iter= 8075
current loss is: 4.187811 , acc is: 0.0 , iter= 8076
current loss is: 4.0607696 , acc is: 0.03125 , iter= 8077
current loss is: 4.1296144 , acc is: 0.0 , iter= 8078
current loss is: 4.0958242 , acc is: 0.015625 , iter= 8079
current loss is: 4.153521 , acc is: 0.015625 , iter= 8080
current loss is: 4.1686563 , acc is: 0.0 , iter= 8081
current loss is: 3.9507833 , acc is: 0.046875 , iter= 8082
current loss is: 4.070153 , acc is: 0.03125 , iter= 8083
current loss is: 4.1623697 , acc is: 0.015625 , iter= 8084
current loss is: 4.14589 , acc is: 0.015625 , iter= 8085
current loss is: 4.0982738 , acc is: 0.015625 , iter= 8086
current loss is: 4.156593 , acc is: 0.03125 , iter= 8087
current loss is: 4.1262503 , acc is: 0.015625 , iter= 8088
current loss is: 4.0438414 , acc is: 0.015625 , iter= 8089
current loss is: 4.211316 , acc is: 0.0 , iter= 8090
current loss is: 4.0949984 , acc is: 0.03125 , iter= 8091
current loss is: 4.076169 , acc is: 0.078125 , iter= 8092
current loss is: 4.087739 , acc is: 0.015625 , iter= 8093
current loss is: 4.1558228 , acc is: 0.03125 , iter= 8094
current loss is: 4.0545673 , acc is: 0.046875 , iter= 8095
current loss is: 4.1591673 , acc is: 0.015625 , iter= 8096
current loss is: 4.157852 , acc is: 0.046875 , iter= 8097
current loss is: 4.0062757 , acc is: 0.046875 , iter= 8098
current loss is: 4.0857534 , acc is: 0.015625 , iter= 8099
current loss is: 4.2008915 , acc is: 0.0 , iter= 8100
current loss is: 4.1676483 , acc is: 0.03125 , iter= 8101
current loss is: 4.15308 , acc is: 0.015625 , iter= 8102
current loss is: 4.0634604 , acc is: 0.0625 , iter= 8103
current loss is: 4.0816603 , acc is: 0.03125 , iter= 8104
current loss is: 4.0389795 , acc is: 0.03125 , iter= 8105
current loss is: 4.1571684 , acc is: 0.046875 , iter= 8106
current loss is: 4.084751 , acc is: 0.0625 , iter= 8107
current loss is: 4.0837765 , acc is: 0.015625 , iter= 8108
current loss is: 4.0650244 , acc is: 0.046875 , iter= 8109
current loss is: 4.0248976 , acc is: 0.046875 , iter= 8110
current loss is: 4.198079 , acc is: 0.015625 , iter= 8111
current loss is: 4.090973 , acc is: 0.0625 , iter= 8112
current loss is: 4.135278 , acc is: 0.0 , iter= 8113
current loss is: 4.031049 , acc is: 0.046875 , iter= 8114
current loss is: 4.0640054 , acc is: 0.03125 , iter= 8115
current loss is: 4.0743732 , acc is: 0.046875 , iter= 8116
current loss is: 4.011758 , acc is: 0.046875 , iter= 8117
current loss is: 4.167544 , acc is: 0.03125 , iter= 8118
current loss is: 4.1134524 , acc is: 0.03125 , iter= 8119
current loss is: 4.151527 , acc is: 0.0 , iter= 8120
current loss is: 4.070173 , acc is: 0.03125 , iter= 8121
current loss is: 4.128295 , acc is: 0.046875 , iter= 8122
current loss is: 4.0899243 , acc is: 0.015625 , iter= 8123
current loss is: 4.0181594 , acc is: 0.046875 , iter= 8124
current loss is: 4.1693788 , acc is: 0.0 , iter= 8125
current loss is: 4.101312 , acc is: 0.046875 , iter= 8126
current loss is: 4.085049 , acc is: 0.015625 , iter= 8127
current loss is: 4.1959524 , acc is: 0.0 , iter= 8128
current loss is: 4.1578646 , acc is: 0.015625 , iter= 8129
current loss is: 4.1126986 , acc is: 0.015625 , iter= 8130
current loss is: 4.073312 , acc is: 0.0625 , iter= 8131
current loss is: 4.227722 , acc is: 0.015625 , iter= 8132
current loss is: 3.8047652 , acc is: 0.078125 , iter= 8133
current loss is: 4.045515 , acc is: 0.046875 , iter= 8134
current loss is: 4.1081505 , acc is: 0.03125 , iter= 8135
current loss is: 4.1395354 , acc is: 0.0 , iter= 8136
current loss is: 4.0126734 , acc is: 0.03125 , iter= 8137
current loss is: 4.1589622 , acc is: 0.0 , iter= 8138
current loss is: 4.098385 , acc is: 0.03125 , iter= 8139
current loss is: 4.162568 , acc is: 0.0 , iter= 8140
current loss is: 4.095413 , acc is: 0.03125 , iter= 8141
current loss is: 4.1177454 , acc is: 0.03125 , iter= 8142
current loss is: 4.1704803 , acc is: 0.0 , iter= 8143
current loss is: 4.076007 , acc is: 0.078125 , iter= 8144
current loss is: 4.151284 , acc is: 0.03125 , iter= 8145
current loss is: 4.075803 , acc is: 0.046875 , iter= 8146
current loss is: 4.191574 , acc is: 0.0 , iter= 8147
current loss is: 4.1357107 , acc is: 0.0 , iter= 8148
current loss is: 4.0813923 , acc is: 0.015625 , iter= 8149
current loss is: 4.0820932 , acc is: 0.03125 , iter= 8150
current loss is: 4.15961 , acc is: 0.046875 , iter= 8151
current loss is: 4.1836 , acc is: 0.015625 , iter= 8152
current loss is: 4.1452913 , acc is: 0.015625 , iter= 8153
current loss is: 4.076307 , acc is: 0.078125 , iter= 8154
current loss is: 4.0331655 , acc is: 0.046875 , iter= 8155
current loss is: 4.156374 , acc is: 0.03125 , iter= 8156
current loss is: 4.122247 , acc is: 0.0 , iter= 8157
current loss is: 4.153576 , acc is: 0.03125 , iter= 8158
current loss is: 4.02033 , acc is: 0.0625 , iter= 8159
current loss is: 4.033771 , acc is: 0.015625 , iter= 8160
current loss is: 4.1407475 , acc is: 0.015625 , iter= 8161
current loss is: 4.0913944 , acc is: 0.03125 , iter= 8162
current loss is: 4.16734 , acc is: 0.03125 , iter= 8163
current loss is: 4.1345844 , acc is: 0.015625 , iter= 8164
current loss is: 4.16971 , acc is: 0.015625 , iter= 8165
current loss is: 4.0511827 , acc is: 0.078125 , iter= 8166
current loss is: 4.0421596 , acc is: 0.046875 , iter= 8167
current loss is: 4.146102 , acc is: 0.015625 , iter= 8168
current loss is: 4.1048946 , acc is: 0.015625 , iter= 8169
current loss is: 4.1391706 , acc is: 0.03125 , iter= 8170
current loss is: 4.0749865 , acc is: 0.046875 , iter= 8171
current loss is: 4.0983377 , acc is: 0.015625 , iter= 8172
current loss is: 4.1437645 , acc is: 0.015625 , iter= 8173
current loss is: 4.1246777 , acc is: 0.015625 , iter= 8174
current loss is: 4.113622 , acc is: 0.046875 , iter= 8175
current loss is: 4.11695 , acc is: 0.078125 , iter= 8176
current loss is: 4.026602 , acc is: 0.046875 , iter= 8177
current loss is: 4.0732036 , acc is: 0.046875 , iter= 8178
current loss is: 4.045991 , acc is: 0.03125 , iter= 8179
current loss is: 4.1619196 , acc is: 0.0 , iter= 8180
current loss is: 4.070169 , acc is: 0.015625 , iter= 8181
current loss is: 4.1627846 , acc is: 0.046875 , iter= 8182
current loss is: 4.0200315 , acc is: 0.046875 , iter= 8183
current loss is: 4.0826654 , acc is: 0.015625 , iter= 8184
current loss is: 4.1026316 , acc is: 0.03125 , iter= 8185
current loss is: 4.062421 , acc is: 0.078125 , iter= 8186
current loss is: 4.0822535 , acc is: 0.015625 , iter= 8187
current loss is: 4.0978937 , acc is: 0.0625 , iter= 8188
current loss is: 4.1420355 , acc is: 0.0 , iter= 8189
current loss is: 4.037791 , acc is: 0.046875 , iter= 8190
current loss is: 4.0717278 , acc is: 0.046875 , iter= 8191
current loss is: 4.0566587 , acc is: 0.015625 , iter= 8192
current loss is: 4.1047964 , acc is: 0.03125 , iter= 8193
current loss is: 4.0982795 , acc is: 0.015625 , iter= 8194
current loss is: 4.0289073 , acc is: 0.03125 , iter= 8195
current loss is: 4.2076283 , acc is: 0.0 , iter= 8196
current loss is: 4.1474504 , acc is: 0.015625 , iter= 8197
current loss is: 4.0748997 , acc is: 0.015625 , iter= 8198
current loss is: 4.1742415 , acc is: 0.0 , iter= 8199
current loss is: 4.138091 , acc is: 0.03125 , iter= 8200
current loss is: 4.1572685 , acc is: 0.0 , iter= 8201
current loss is: 4.1858764 , acc is: 0.046875 , iter= 8202
current loss is: 4.145568 , acc is: 0.03125 , iter= 8203
current loss is: 3.926981 , acc is: 0.0625 , iter= 8204
current loss is: 4.1356077 , acc is: 0.046875 , iter= 8205
current loss is: 4.038514 , acc is: 0.046875 , iter= 8206
current loss is: 4.14944 , acc is: 0.03125 , iter= 8207
current loss is: 4.0587454 , acc is: 0.046875 , iter= 8208
current loss is: 4.1258726 , acc is: 0.015625 , iter= 8209
current loss is: 4.1451693 , acc is: 0.015625 , iter= 8210
current loss is: 4.1788936 , acc is: 0.0 , iter= 8211
current loss is: 4.1214905 , acc is: 0.0 , iter= 8212
current loss is: 4.117572 , acc is: 0.0 , iter= 8213
current loss is: 4.1218653 , acc is: 0.015625 , iter= 8214
current loss is: 4.0831404 , acc is: 0.03125 , iter= 8215
current loss is: 4.147519 , acc is: 0.015625 , iter= 8216
current loss is: 4.0447245 , acc is: 0.03125 , iter= 8217
current loss is: 4.0907025 , acc is: 0.015625 , iter= 8218
current loss is: 4.100561 , acc is: 0.03125 , iter= 8219
current loss is: 4.0890093 , acc is: 0.015625 , iter= 8220
current loss is: 4.1571536 , acc is: 0.015625 , iter= 8221
current loss is: 4.0586996 , acc is: 0.0625 , iter= 8222
current loss is: 4.085679 , acc is: 0.015625 , iter= 8223
current loss is: 4.0683894 , acc is: 0.046875 , iter= 8224
current loss is: 4.0603695 , acc is: 0.09375 , iter= 8225
current loss is: 4.1738567 , acc is: 0.015625 , iter= 8226
current loss is: 4.007672 , acc is: 0.0625 , iter= 8227
current loss is: 4.1002855 , acc is: 0.015625 , iter= 8228
current loss is: 4.0062428 , acc is: 0.078125 , iter= 8229
current loss is: 4.0979633 , acc is: 0.015625 , iter= 8230
current loss is: 4.0487237 , acc is: 0.03125 , iter= 8231
current loss is: 4.1501184 , acc is: 0.0 , iter= 8232
current loss is: 4.171871 , acc is: 0.0 , iter= 8233
current loss is: 4.1353025 , acc is: 0.03125 , iter= 8234
current loss is: 4.1653295 , acc is: 0.015625 , iter= 8235
current loss is: 3.993155 , acc is: 0.03125 , iter= 8236
current loss is: 4.0529084 , acc is: 0.0625 , iter= 8237
current loss is: 4.13562 , acc is: 0.0 , iter= 8238
current loss is: 4.0036154 , acc is: 0.046875 , iter= 8239
current loss is: 4.068876 , acc is: 0.0625 , iter= 8240
current loss is: 4.134596 , acc is: 0.0 , iter= 8241
current loss is: 4.095572 , acc is: 0.03125 , iter= 8242
current loss is: 4.1905193 , acc is: 0.0 , iter= 8243
current loss is: 4.189666 , acc is: 0.015625 , iter= 8244
current loss is: 4.0975685 , acc is: 0.03125 , iter= 8245
current loss is: 3.987918 , acc is: 0.0625 , iter= 8246
current loss is: 4.130046 , acc is: 0.0 , iter= 8247
current loss is: 4.1206903 , acc is: 0.015625 , iter= 8248
current loss is: 4.098466 , acc is: 0.015625 , iter= 8249
current loss is: 4.142796 , acc is: 0.046875 , iter= 8250
current loss is: 4.163206 , acc is: 0.015625 , iter= 8251
current loss is: 4.123993 , acc is: 0.015625 , iter= 8252
current loss is: 4.094297 , acc is: 0.03125 , iter= 8253
current loss is: 4.142771 , acc is: 0.015625 , iter= 8254
current loss is: 4.139451 , acc is: 0.03125 , iter= 8255
current loss is: 4.017802 , acc is: 0.046875 , iter= 8256
current loss is: 4.028941 , acc is: 0.0625 , iter= 8257
current loss is: 4.0909104 , acc is: 0.015625 , iter= 8258
current loss is: 4.0209107 , acc is: 0.03125 , iter= 8259
current loss is: 4.0697556 , acc is: 0.0625 , iter= 8260
current loss is: 4.0012255 , acc is: 0.0625 , iter= 8261
current loss is: 4.1420817 , acc is: 0.03125 , iter= 8262
current loss is: 3.9757028 , acc is: 0.03125 , iter= 8263
current loss is: 3.9751244 , acc is: 0.03125 , iter= 8264
current loss is: 4.1056323 , acc is: 0.03125 , iter= 8265
current loss is: 4.0689163 , acc is: 0.0625 , iter= 8266
current loss is: 4.117942 , acc is: 0.03125 , iter= 8267
current loss is: 4.0164485 , acc is: 0.0625 , iter= 8268
current loss is: 4.0026865 , acc is: 0.046875 , iter= 8269
current loss is: 4.1152983 , acc is: 0.015625 , iter= 8270
current loss is: 4.0852118 , acc is: 0.03125 , iter= 8271
current loss is: 4.1122518 , acc is: 0.03125 , iter= 8272
current loss is: 4.10555 , acc is: 0.03125 , iter= 8273
current loss is: 4.1311684 , acc is: 0.015625 , iter= 8274
current loss is: 4.0613933 , acc is: 0.078125 , iter= 8275
current loss is: 4.129674 , acc is: 0.03125 , iter= 8276
current loss is: 4.2000065 , acc is: 0.0 , iter= 8277
current loss is: 4.135201 , acc is: 0.03125 , iter= 8278
current loss is: 4.163293 , acc is: 0.015625 , iter= 8279
current loss is: 4.149581 , acc is: 0.0 , iter= 8280
current loss is: 4.0388927 , acc is: 0.046875 , iter= 8281
current loss is: 4.1422462 , acc is: 0.0 , iter= 8282
current loss is: 4.0553093 , acc is: 0.046875 , iter= 8283
current loss is: 4.117796 , acc is: 0.03125 , iter= 8284
current loss is: 5.515938 , acc is: 0.046875 , iter= 8285
current loss is: 4.0742025 , acc is: 0.0625 , iter= 8286
current loss is: 4.1802063 , acc is: 0.0 , iter= 8287
current loss is: 4.019205 , acc is: 0.03125 , iter= 8288
current loss is: 4.1756124 , acc is: 0.03125 , iter= 8289
current loss is: 4.1664 , acc is: 0.015625 , iter= 8290
current loss is: 4.1465907 , acc is: 0.03125 , iter= 8291
current loss is: 4.149765 , acc is: 0.03125 , iter= 8292
current loss is: 4.234156 , acc is: 0.0 , iter= 8293
current loss is: 4.157503 , acc is: 0.046875 , iter= 8294
current loss is: 4.1326303 , acc is: 0.046875 , iter= 8295
current loss is: 4.0818853 , acc is: 0.03125 , iter= 8296
current loss is: 4.1606293 , acc is: 0.015625 , iter= 8297
current loss is: 4.2092233 , acc is: 0.015625 , iter= 8298
current loss is: 4.1650987 , acc is: 0.015625 , iter= 8299
current loss is: 4.1459017 , acc is: 0.015625 , iter= 8300
current loss is: 4.1659184 , acc is: 0.0 , iter= 8301
current loss is: 4.057574 , acc is: 0.03125 , iter= 8302
current loss is: 4.1646476 , acc is: 0.0625 , iter= 8303
current loss is: 4.0013742 , acc is: 0.0625 , iter= 8304
current loss is: 4.007413 , acc is: 0.078125 , iter= 8305
current loss is: 4.169278 , acc is: 0.0 , iter= 8306
current loss is: 4.0834007 , acc is: 0.03125 , iter= 8307
current loss is: 4.020501 , acc is: 0.078125 , iter= 8308
current loss is: 4.1135063 , acc is: 0.0625 , iter= 8309
current loss is: 4.0488396 , acc is: 0.03125 , iter= 8310
current loss is: 4.104895 , acc is: 0.015625 , iter= 8311
current loss is: 4.0485625 , acc is: 0.046875 , iter= 8312
current loss is: 4.1114264 , acc is: 0.0625 , iter= 8313
current loss is: 4.149548 , acc is: 0.0625 , iter= 8314
current loss is: 4.1847715 , acc is: 0.03125 , iter= 8315
current loss is: 4.056188 , acc is: 0.046875 , iter= 8316
current loss is: 4.1492805 , acc is: 0.015625 , iter= 8317
current loss is: 4.098453 , acc is: 0.0 , iter= 8318
current loss is: 4.0544057 , acc is: 0.046875 , iter= 8319
current loss is: 4.099161 , acc is: 0.03125 , iter= 8320
current loss is: 4.032427 , acc is: 0.046875 , iter= 8321
current loss is: 4.121638 , acc is: 0.046875 , iter= 8322
current loss is: 4.114249 , acc is: 0.03125 , iter= 8323
current loss is: 4.155614 , acc is: 0.03125 , iter= 8324
current loss is: 4.0457067 , acc is: 0.046875 , iter= 8325
current loss is: 4.1052055 , acc is: 0.046875 , iter= 8326
current loss is: 4.13124 , acc is: 0.03125 , iter= 8327
current loss is: 4.1426725 , acc is: 0.03125 , iter= 8328
current loss is: 4.1239743 , acc is: 0.046875 , iter= 8329
current loss is: 4.0660267 , acc is: 0.046875 , iter= 8330
current loss is: 4.0637884 , acc is: 0.03125 , iter= 8331
current loss is: 4.103379 , acc is: 0.015625 , iter= 8332
current loss is: 4.121504 , acc is: 0.015625 , iter= 8333
current loss is: 4.059797 , acc is: 0.03125 , iter= 8334
current loss is: 4.1340194 , acc is: 0.015625 , iter= 8335
current loss is: 4.1100254 , acc is: 0.0 , iter= 8336
current loss is: 4.1643414 , acc is: 0.0 , iter= 8337
current loss is: 4.0426674 , acc is: 0.015625 , iter= 8338
current loss is: 4.19217 , acc is: 0.015625 , iter= 8339
current loss is: 4.1337557 , acc is: 0.015625 , iter= 8340
current loss is: 4.0763097 , acc is: 0.046875 , iter= 8341
current loss is: 4.164811 , acc is: 0.0 , iter= 8342
current loss is: 4.1080675 , acc is: 0.0625 , iter= 8343
current loss is: 4.1200895 , acc is: 0.015625 , iter= 8344
current loss is: 4.0817494 , acc is: 0.015625 , iter= 8345
current loss is: 4.103518 , acc is: 0.03125 , iter= 8346
current loss is: 4.0348907 , acc is: 0.0625 , iter= 8347
current loss is: 4.1798 , acc is: 0.0 , iter= 8348
current loss is: 4.08683 , acc is: 0.015625 , iter= 8349
current loss is: 4.1225243 , acc is: 0.03125 , iter= 8350
current loss is: 4.195336 , acc is: 0.015625 , iter= 8351
current loss is: 4.006434 , acc is: 0.046875 , iter= 8352
current loss is: 4.119152 , acc is: 0.03125 , iter= 8353
current loss is: 4.0908194 , acc is: 0.0625 , iter= 8354
current loss is: 4.1540437 , acc is: 0.015625 , iter= 8355
current loss is: 4.0183425 , acc is: 0.03125 , iter= 8356
current loss is: 4.10656 , acc is: 0.0 , iter= 8357
current loss is: 4.042487 , acc is: 0.0625 , iter= 8358
current loss is: 4.107605 , acc is: 0.015625 , iter= 8359
current loss is: 4.145843 , acc is: 0.0 , iter= 8360
current loss is: 4.167777 , acc is: 0.0 , iter= 8361
current loss is: 4.1222286 , acc is: 0.015625 , iter= 8362
current loss is: 4.076065 , acc is: 0.046875 , iter= 8363
current loss is: 4.12182 , acc is: 0.0 , iter= 8364
current loss is: 4.033677 , acc is: 0.0625 , iter= 8365
current loss is: 4.004117 , acc is: 0.046875 , iter= 8366
current loss is: 4.0062227 , acc is: 0.03125 , iter= 8367
current loss is: 4.174727 , acc is: 0.015625 , iter= 8368
current loss is: 4.014467 , acc is: 0.0625 , iter= 8369
current loss is: 4.1809955 , acc is: 0.015625 , iter= 8370
current loss is: 4.102985 , acc is: 0.03125 , iter= 8371
current loss is: 4.0388746 , acc is: 0.03125 , iter= 8372
current loss is: 4.106566 , acc is: 0.0625 , iter= 8373
current loss is: 4.064847 , acc is: 0.046875 , iter= 8374
current loss is: 4.1760416 , acc is: 0.015625 , iter= 8375
current loss is: 4.117097 , acc is: 0.03125 , iter= 8376
current loss is: 4.1638737 , acc is: 0.03125 , iter= 8377
current loss is: 4.175206 , acc is: 0.0 , iter= 8378
current loss is: 4.1491795 , acc is: 0.046875 , iter= 8379
current loss is: 4.0370398 , acc is: 0.015625 , iter= 8380
current loss is: 4.1963034 , acc is: 0.03125 , iter= 8381
current loss is: 4.101941 , acc is: 0.015625 , iter= 8382
current loss is: 4.118968 , acc is: 0.0625 , iter= 8383
current loss is: 4.117388 , acc is: 0.015625 , iter= 8384
current loss is: 4.0339375 , acc is: 0.046875 , iter= 8385
current loss is: 4.053089 , acc is: 0.03125 , iter= 8386
current loss is: 4.226575 , acc is: 0.015625 , iter= 8387
current loss is: 4.084944 , acc is: 0.046875 , iter= 8388
current loss is: 4.022139 , acc is: 0.03125 , iter= 8389
current loss is: 4.1636057 , acc is: 0.0 , iter= 8390
current loss is: 4.066808 , acc is: 0.015625 , iter= 8391
current loss is: 4.108507 , acc is: 0.03125 , iter= 8392
current loss is: 4.0904846 , acc is: 0.046875 , iter= 8393
current loss is: 4.1575317 , acc is: 0.046875 , iter= 8394
current loss is: 4.1357555 , acc is: 0.03125 , iter= 8395
current loss is: 4.070916 , acc is: 0.015625 , iter= 8396
current loss is: 4.0843687 , acc is: 0.015625 , iter= 8397
current loss is: 4.0270233 , acc is: 0.03125 , iter= 8398
current loss is: 4.1445894 , acc is: 0.015625 , iter= 8399
current loss is: 4.122389 , acc is: 0.015625 , iter= 8400
current loss is: 4.032455 , acc is: 0.03125 , iter= 8401
current loss is: 4.0888596 , acc is: 0.046875 , iter= 8402
current loss is: 4.126899 , acc is: 0.015625 , iter= 8403
current loss is: 4.1384387 , acc is: 0.03125 , iter= 8404
current loss is: 4.1392584 , acc is: 0.03125 , iter= 8405
current loss is: 4.168703 , acc is: 0.015625 , iter= 8406
current loss is: 4.1639786 , acc is: 0.0 , iter= 8407
current loss is: 4.091214 , acc is: 0.015625 , iter= 8408
current loss is: 4.1271276 , acc is: 0.046875 , iter= 8409
current loss is: 4.1405125 , acc is: 0.015625 , iter= 8410
current loss is: 4.1554575 , acc is: 0.03125 , iter= 8411
current loss is: 4.1355467 , acc is: 0.03125 , iter= 8412
current loss is: 4.048773 , acc is: 0.0625 , iter= 8413
current loss is: 4.0546713 , acc is: 0.015625 , iter= 8414
current loss is: 4.1664124 , acc is: 0.03125 , iter= 8415
current loss is: 4.047237 , acc is: 0.03125 , iter= 8416
current loss is: 4.044753 , acc is: 0.015625 , iter= 8417
current loss is: 4.098871 , acc is: 0.046875 , iter= 8418
current loss is: 4.1319094 , acc is: 0.015625 , iter= 8419
current loss is: 4.1271915 , acc is: 0.03125 , iter= 8420
current loss is: 4.084738 , acc is: 0.03125 , iter= 8421
current loss is: 4.090487 , acc is: 0.046875 , iter= 8422
current loss is: 4.0437317 , acc is: 0.078125 , iter= 8423
current loss is: 4.1137166 , acc is: 0.03125 , iter= 8424
current loss is: 4.1331263 , acc is: 0.015625 , iter= 8425
current loss is: 4.0826855 , acc is: 0.015625 , iter= 8426
current loss is: 4.0711937 , acc is: 0.03125 , iter= 8427
current loss is: 4.0410795 , acc is: 0.046875 , iter= 8428
current loss is: 4.0747337 , acc is: 0.0625 , iter= 8429
current loss is: 4.1933155 , acc is: 0.0 , iter= 8430
current loss is: 4.0111685 , acc is: 0.046875 , iter= 8431
current loss is: 4.0442867 , acc is: 0.03125 , iter= 8432
current loss is: 4.199874 , acc is: 0.015625 , iter= 8433
current loss is: 4.141247 , acc is: 0.03125 , iter= 8434
current loss is: 4.1681123 , acc is: 0.015625 , iter= 8435
current loss is: 4.071727 , acc is: 0.03125 , iter= 8436
current loss is: 4.0768824 , acc is: 0.046875 , iter= 8437
current loss is: 4.0858374 , acc is: 0.03125 , iter= 8438
current loss is: 4.150985 , acc is: 0.03125 , iter= 8439
current loss is: 4.035804 , acc is: 0.03125 , iter= 8440
current loss is: 4.0999665 , acc is: 0.03125 , iter= 8441
current loss is: 4.1771903 , acc is: 0.03125 , iter= 8442
current loss is: 4.06122 , acc is: 0.03125 , iter= 8443
current loss is: 4.071524 , acc is: 0.046875 , iter= 8444
current loss is: 4.0823727 , acc is: 0.03125 , iter= 8445
current loss is: 4.03598 , acc is: 0.078125 , iter= 8446
current loss is: 4.128312 , acc is: 0.03125 , iter= 8447
current loss is: 4.154665 , acc is: 0.0 , iter= 8448
current loss is: 4.0751214 , acc is: 0.03125 , iter= 8449
current loss is: 4.083398 , acc is: 0.046875 , iter= 8450
current loss is: 4.096876 , acc is: 0.03125 , iter= 8451
current loss is: 4.1524124 , acc is: 0.03125 , iter= 8452
current loss is: 4.1151648 , acc is: 0.03125 , iter= 8453
current loss is: 4.1438913 , acc is: 0.03125 , iter= 8454
current loss is: 4.066893 , acc is: 0.046875 , iter= 8455
current loss is: 4.203496 , acc is: 0.0 , iter= 8456
current loss is: 4.114423 , acc is: 0.015625 , iter= 8457
current loss is: 4.0770645 , acc is: 0.015625 , iter= 8458
current loss is: 3.9885101 , acc is: 0.046875 , iter= 8459
current loss is: 4.1222878 , acc is: 0.0 , iter= 8460
current loss is: 4.1533575 , acc is: 0.0625 , iter= 8461
current loss is: 4.130903 , acc is: 0.015625 , iter= 8462
current loss is: 4.1302156 , acc is: 0.015625 , iter= 8463
current loss is: 4.03078 , acc is: 0.046875 , iter= 8464
current loss is: 4.0919247 , acc is: 0.015625 , iter= 8465
current loss is: 4.131883 , acc is: 0.015625 , iter= 8466
current loss is: 4.0668664 , acc is: 0.03125 , iter= 8467
current loss is: 4.1514063 , acc is: 0.03125 , iter= 8468
current loss is: 4.1835318 , acc is: 0.015625 , iter= 8469
current loss is: 4.149171 , acc is: 0.03125 , iter= 8470
current loss is: 4.0861545 , acc is: 0.046875 , iter= 8471
current loss is: 4.082124 , acc is: 0.0625 , iter= 8472
current loss is: 4.1176147 , acc is: 0.0 , iter= 8473
current loss is: 4.0278025 , acc is: 0.046875 , iter= 8474
current loss is: 4.1413984 , acc is: 0.015625 , iter= 8475
current loss is: 4.1245136 , acc is: 0.0 , iter= 8476
current loss is: 4.0960884 , acc is: 0.03125 , iter= 8477
current loss is: 4.135596 , acc is: 0.015625 , iter= 8478
current loss is: 4.1404057 , acc is: 0.046875 , iter= 8479
current loss is: 4.1931167 , acc is: 0.0 , iter= 8480
current loss is: 4.121785 , acc is: 0.0 , iter= 8481
current loss is: 4.059902 , acc is: 0.046875 , iter= 8482
current loss is: 4.113351 , acc is: 0.03125 , iter= 8483
current loss is: 4.0493774 , acc is: 0.015625 , iter= 8484
current loss is: 4.049038 , acc is: 0.03125 , iter= 8485
current loss is: 4.0593233 , acc is: 0.03125 , iter= 8486
current loss is: 4.0318217 , acc is: 0.078125 , iter= 8487
current loss is: 4.0247364 , acc is: 0.0625 , iter= 8488
current loss is: 3.9813058 , acc is: 0.078125 , iter= 8489
current loss is: 4.169277 , acc is: 0.0 , iter= 8490
current loss is: 4.103172 , acc is: 0.015625 , iter= 8491
current loss is: 4.073739 , acc is: 0.046875 , iter= 8492
current loss is: 4.1812553 , acc is: 0.015625 , iter= 8493
current loss is: 4.105248 , acc is: 0.046875 , iter= 8494
current loss is: 4.0077176 , acc is: 0.03125 , iter= 8495
current loss is: 4.1386538 , acc is: 0.03125 , iter= 8496
current loss is: 4.125289 , acc is: 0.015625 , iter= 8497
current loss is: 4.0909066 , acc is: 0.046875 , iter= 8498
current loss is: 4.1535864 , acc is: 0.015625 , iter= 8499
current loss is: 4.1273627 , acc is: 0.03125 , iter= 8500
current loss is: 4.0618477 , acc is: 0.0625 , iter= 8501
current loss is: 4.0185013 , acc is: 0.046875 , iter= 8502
current loss is: 4.156502 , acc is: 0.015625 , iter= 8503
current loss is: 4.111674 , acc is: 0.03125 , iter= 8504
current loss is: 4.1512938 , acc is: 0.0 , iter= 8505
current loss is: 4.052432 , acc is: 0.0625 , iter= 8506
current loss is: 4.0460644 , acc is: 0.046875 , iter= 8507
current loss is: 4.0419354 , acc is: 0.046875 , iter= 8508
current loss is: 4.106441 , acc is: 0.03125 , iter= 8509
current loss is: 4.1511974 , acc is: 0.015625 , iter= 8510
current loss is: 4.089369 , acc is: 0.0625 , iter= 8511
current loss is: 4.025436 , acc is: 0.046875 , iter= 8512
current loss is: 4.1171603 , acc is: 0.078125 , iter= 8513
current loss is: 4.0874977 , acc is: 0.046875 , iter= 8514
current loss is: 4.1436534 , acc is: 0.015625 , iter= 8515
current loss is: 4.0852013 , acc is: 0.046875 , iter= 8516
current loss is: 4.1562195 , acc is: 0.015625 , iter= 8517
current loss is: 3.9966729 , acc is: 0.03125 , iter= 8518
current loss is: 4.135293 , acc is: 0.0 , iter= 8519
current loss is: 4.117942 , acc is: 0.0 , iter= 8520
current loss is: 4.0703773 , acc is: 0.046875 , iter= 8521
current loss is: 4.087486 , acc is: 0.0625 , iter= 8522
current loss is: 4.1684065 , acc is: 0.015625 , iter= 8523
current loss is: 4.1292973 , acc is: 0.0 , iter= 8524
current loss is: 4.0590982 , acc is: 0.0625 , iter= 8525
current loss is: 4.0803995 , acc is: 0.03125 , iter= 8526
current loss is: 4.0919366 , acc is: 0.03125 , iter= 8527
current loss is: 4.168247 , acc is: 0.03125 , iter= 8528
current loss is: 4.1130276 , acc is: 0.015625 , iter= 8529
current loss is: 4.119007 , acc is: 0.0 , iter= 8530
current loss is: 4.0529804 , acc is: 0.046875 , iter= 8531
current loss is: 4.099207 , acc is: 0.046875 , iter= 8532
current loss is: 4.117418 , acc is: 0.015625 , iter= 8533
current loss is: 4.0668373 , acc is: 0.03125 , iter= 8534
current loss is: 4.1287546 , acc is: 0.046875 , iter= 8535
current loss is: 4.128728 , acc is: 0.015625 , iter= 8536
current loss is: 4.1402035 , acc is: 0.03125 , iter= 8537
current loss is: 4.0617375 , acc is: 0.0625 , iter= 8538
current loss is: 4.2057276 , acc is: 0.0 , iter= 8539
current loss is: 4.0545034 , acc is: 0.078125 , iter= 8540
current loss is: 4.1466794 , acc is: 0.015625 , iter= 8541
current loss is: 4.125307 , acc is: 0.0 , iter= 8542
current loss is: 4.1060553 , acc is: 0.078125 , iter= 8543
current loss is: 4.1246634 , acc is: 0.015625 , iter= 8544
current loss is: 4.122967 , acc is: 0.046875 , iter= 8545
current loss is: 4.0810246 , acc is: 0.03125 , iter= 8546
current loss is: 4.194276 , acc is: 0.03125 , iter= 8547
current loss is: 4.1440682 , acc is: 0.03125 , iter= 8548
current loss is: 4.089732 , acc is: 0.03125 , iter= 8549
current loss is: 4.136388 , acc is: 0.046875 , iter= 8550
current loss is: 4.1380243 , acc is: 0.03125 , iter= 8551
current loss is: 4.222311 , acc is: 0.0 , iter= 8552
current loss is: 4.1404705 , acc is: 0.015625 , iter= 8553
current loss is: 4.1056604 , acc is: 0.0625 , iter= 8554
current loss is: 4.136937 , acc is: 0.015625 , iter= 8555
current loss is: 4.064367 , acc is: 0.0625 , iter= 8556
current loss is: 4.10938 , acc is: 0.03125 , iter= 8557
current loss is: 4.087883 , acc is: 0.046875 , iter= 8558
current loss is: 3.9822512 , acc is: 0.0625 , iter= 8559
current loss is: 4.1508846 , acc is: 0.0 , iter= 8560
current loss is: 4.163477 , acc is: 0.015625 , iter= 8561
current loss is: 4.1286116 , acc is: 0.0 , iter= 8562
current loss is: 4.0952888 , acc is: 0.046875 , iter= 8563
current loss is: 4.1229506 , acc is: 0.0 , iter= 8564
current loss is: 4.0939665 , acc is: 0.03125 , iter= 8565
current loss is: 4.176223 , acc is: 0.015625 , iter= 8566
current loss is: 4.0704784 , acc is: 0.03125 , iter= 8567
current loss is: 4.0794773 , acc is: 0.03125 , iter= 8568
current loss is: 4.0885916 , acc is: 0.03125 , iter= 8569
current loss is: 4.122955 , acc is: 0.0 , iter= 8570
current loss is: 4.09346 , acc is: 0.046875 , iter= 8571
current loss is: 4.2825756 , acc is: 0.0625 , iter= 8572
current loss is: 4.164748 , acc is: 0.0 , iter= 8573
current loss is: 4.1987863 , acc is: 0.0 , iter= 8574
current loss is: 4.099904 , acc is: 0.015625 , iter= 8575
current loss is: 4.1357355 , acc is: 0.0 , iter= 8576
current loss is: 4.1299596 , acc is: 0.015625 , iter= 8577
current loss is: 4.0409327 , acc is: 0.03125 , iter= 8578
current loss is: 4.1519194 , acc is: 0.046875 , iter= 8579
current loss is: 4.1151404 , acc is: 0.046875 , iter= 8580
current loss is: 4.15702 , acc is: 0.078125 , iter= 8581
current loss is: 4.075035 , acc is: 0.046875 , iter= 8582
current loss is: 4.081815 , acc is: 0.046875 , iter= 8583
current loss is: 4.03306 , acc is: 0.046875 , iter= 8584
current loss is: 4.1728954 , acc is: 0.015625 , iter= 8585
current loss is: 4.067407 , acc is: 0.03125 , iter= 8586
current loss is: 4.1035085 , acc is: 0.046875 , iter= 8587
current loss is: 4.0861225 , acc is: 0.03125 , iter= 8588
current loss is: 3.9908276 , acc is: 0.078125 , iter= 8589
current loss is: 4.1346292 , acc is: 0.0625 , iter= 8590
current loss is: 4.0318966 , acc is: 0.046875 , iter= 8591
current loss is: 4.1211734 , acc is: 0.015625 , iter= 8592
current loss is: 4.1941204 , acc is: 0.015625 , iter= 8593
current loss is: 4.119234 , acc is: 0.015625 , iter= 8594
current loss is: 4.0719967 , acc is: 0.015625 , iter= 8595
current loss is: 4.0776615 , acc is: 0.015625 , iter= 8596
current loss is: 4.1187425 , acc is: 0.015625 , iter= 8597
current loss is: 4.0703015 , acc is: 0.046875 , iter= 8598
current loss is: 4.1402597 , acc is: 0.0 , iter= 8599
current loss is: 4.1044226 , acc is: 0.0625 , iter= 8600
current loss is: 4.1456575 , acc is: 0.03125 , iter= 8601
current loss is: 4.156844 , acc is: 0.0 , iter= 8602
current loss is: 4.1775246 , acc is: 0.0 , iter= 8603
current loss is: 4.1638865 , acc is: 0.015625 , iter= 8604
current loss is: 4.0515594 , acc is: 0.078125 , iter= 8605
current loss is: 4.139726 , acc is: 0.0 , iter= 8606
current loss is: 4.114933 , acc is: 0.03125 , iter= 8607
current loss is: 4.100071 , acc is: 0.0 , iter= 8608
current loss is: 4.0958347 , acc is: 0.046875 , iter= 8609
current loss is: 4.1684227 , acc is: 0.03125 , iter= 8610
current loss is: 4.105094 , acc is: 0.03125 , iter= 8611
current loss is: 4.02159 , acc is: 0.078125 , iter= 8612
current loss is: 3.9798136 , acc is: 0.03125 , iter= 8613
current loss is: 4.1794596 , acc is: 0.03125 , iter= 8614
current loss is: 4.1550975 , acc is: 0.03125 , iter= 8615
current loss is: 4.1078205 , acc is: 0.03125 , iter= 8616
current loss is: 4.078167 , acc is: 0.046875 , iter= 8617
current loss is: 4.0342865 , acc is: 0.046875 , iter= 8618
current loss is: 4.121723 , acc is: 0.046875 , iter= 8619
current loss is: 4.0104756 , acc is: 0.0625 , iter= 8620
current loss is: 3.828277 , acc is: 0.125 , iter= 8621
current loss is: 4.1148987 , acc is: 0.015625 , iter= 8622
current loss is: 4.098627 , acc is: 0.015625 , iter= 8623
current loss is: 4.134029 , acc is: 0.03125 , iter= 8624
current loss is: 4.15889 , acc is: 0.03125 , iter= 8625
current loss is: 4.1008334 , acc is: 0.03125 , iter= 8626
current loss is: 4.020129 , acc is: 0.0625 , iter= 8627
current loss is: 4.1135225 , acc is: 0.0 , iter= 8628
current loss is: 4.012388 , acc is: 0.046875 , iter= 8629
current loss is: 4.19358 , acc is: 0.015625 , iter= 8630
current loss is: 4.06664 , acc is: 0.046875 , iter= 8631
current loss is: 4.080944 , acc is: 0.046875 , iter= 8632
current loss is: 4.066722 , acc is: 0.03125 , iter= 8633
current loss is: 4.1508603 , acc is: 0.015625 , iter= 8634
current loss is: 4.096689 , acc is: 0.046875 , iter= 8635
current loss is: 4.0789165 , acc is: 0.03125 , iter= 8636
current loss is: 4.129124 , acc is: 0.015625 , iter= 8637
current loss is: 4.1929846 , acc is: 0.0 , iter= 8638
current loss is: 4.2436304 , acc is: 0.03125 , iter= 8639
current loss is: 4.0452585 , acc is: 0.0625 , iter= 8640
current loss is: 4.1082673 , acc is: 0.046875 , iter= 8641
current loss is: 4.152088 , acc is: 0.015625 , iter= 8642
current loss is: 4.188187 , acc is: 0.0 , iter= 8643
current loss is: 4.1274014 , acc is: 0.015625 , iter= 8644
current loss is: 4.149053 , acc is: 0.03125 , iter= 8645
current loss is: 4.1312437 , acc is: 0.015625 , iter= 8646
current loss is: 4.1765223 , acc is: 0.0 , iter= 8647
current loss is: 4.1148014 , acc is: 0.015625 , iter= 8648
current loss is: 4.0534477 , acc is: 0.03125 , iter= 8649
current loss is: 4.18396 , acc is: 0.046875 , iter= 8650
current loss is: 4.0491314 , acc is: 0.046875 , iter= 8651
current loss is: 3.884583 , acc is: 0.0625 , iter= 8652
current loss is: 4.200942 , acc is: 0.015625 , iter= 8653
current loss is: 4.2035303 , acc is: 0.0 , iter= 8654
current loss is: 4.058424 , acc is: 0.015625 , iter= 8655
current loss is: 4.148882 , acc is: 0.0 , iter= 8656
current loss is: 4.161165 , acc is: 0.015625 , iter= 8657
current loss is: 4.1696854 , acc is: 0.0 , iter= 8658
current loss is: 4.052123 , acc is: 0.046875 , iter= 8659
current loss is: 4.204284 , acc is: 0.03125 , iter= 8660
current loss is: 4.1537375 , acc is: 0.03125 , iter= 8661
current loss is: 4.0794277 , acc is: 0.03125 , iter= 8662
current loss is: 4.1062803 , acc is: 0.015625 , iter= 8663
current loss is: 3.9677608 , acc is: 0.0625 , iter= 8664
current loss is: 4.163167 , acc is: 0.03125 , iter= 8665
current loss is: 4.137022 , acc is: 0.0625 , iter= 8666
current loss is: 4.08704 , acc is: 0.015625 , iter= 8667
current loss is: 4.084793 , acc is: 0.03125 , iter= 8668
current loss is: 4.1191854 , acc is: 0.015625 , iter= 8669
current loss is: 4.056669 , acc is: 0.046875 , iter= 8670
current loss is: 4.122938 , acc is: 0.046875 , iter= 8671
current loss is: 4.003399 , acc is: 0.03125 , iter= 8672
current loss is: 4.1394234 , acc is: 0.015625 , iter= 8673
current loss is: 4.1476884 , acc is: 0.046875 , iter= 8674
current loss is: 4.1124163 , acc is: 0.015625 , iter= 8675
current loss is: 3.998696 , acc is: 0.046875 , iter= 8676
current loss is: 4.098124 , acc is: 0.015625 , iter= 8677
current loss is: 4.057369 , acc is: 0.0625 , iter= 8678
current loss is: 4.1293845 , acc is: 0.046875 , iter= 8679
current loss is: 4.1422386 , acc is: 0.0 , iter= 8680
current loss is: 4.1695447 , acc is: 0.0 , iter= 8681
current loss is: 4.1066227 , acc is: 0.03125 , iter= 8682
current loss is: 3.9745865 , acc is: 0.09375 , iter= 8683
current loss is: 4.1457386 , acc is: 0.03125 , iter= 8684
current loss is: 4.189877 , acc is: 0.0 , iter= 8685
current loss is: 4.134671 , acc is: 0.015625 , iter= 8686
current loss is: 4.102374 , acc is: 0.03125 , iter= 8687
current loss is: 4.1135235 , acc is: 0.0 , iter= 8688
current loss is: 4.1530375 , acc is: 0.0 , iter= 8689
current loss is: 4.0603557 , acc is: 0.0625 , iter= 8690
current loss is: 4.09133 , acc is: 0.03125 , iter= 8691
current loss is: 4.1700897 , acc is: 0.0 , iter= 8692
current loss is: 4.1310835 , acc is: 0.0 , iter= 8693
current loss is: 4.084519 , acc is: 0.03125 , iter= 8694
current loss is: 4.144683 , acc is: 0.03125 , iter= 8695
current loss is: 4.062377 , acc is: 0.03125 , iter= 8696
current loss is: 4.0964766 , acc is: 0.03125 , iter= 8697
current loss is: 4.1460366 , acc is: 0.03125 , iter= 8698
current loss is: 4.0291348 , acc is: 0.03125 , iter= 8699
current loss is: 4.0875907 , acc is: 0.03125 , iter= 8700
current loss is: 4.144714 , acc is: 0.015625 , iter= 8701
current loss is: 4.0792084 , acc is: 0.03125 , iter= 8702
current loss is: 4.130148 , acc is: 0.015625 , iter= 8703
current loss is: 4.1437893 , acc is: 0.015625 , iter= 8704
current loss is: 4.1684327 , acc is: 0.046875 , iter= 8705
current loss is: 4.2225494 , acc is: 0.015625 , iter= 8706
current loss is: 4.091219 , acc is: 0.0 , iter= 8707
current loss is: 4.0895705 , acc is: 0.015625 , iter= 8708
current loss is: 4.1066394 , acc is: 0.015625 , iter= 8709
current loss is: 4.031028 , acc is: 0.0625 , iter= 8710
current loss is: 4.03676 , acc is: 0.03125 , iter= 8711
current loss is: 4.0867968 , acc is: 0.015625 , iter= 8712
current loss is: 4.0247183 , acc is: 0.03125 , iter= 8713
current loss is: 4.1530557 , acc is: 0.015625 , iter= 8714
current loss is: 4.1572843 , acc is: 0.0 , iter= 8715
current loss is: 4.0365167 , acc is: 0.03125 , iter= 8716
current loss is: 4.049138 , acc is: 0.046875 , iter= 8717
current loss is: 4.105996 , acc is: 0.015625 , iter= 8718
current loss is: 4.197603 , acc is: 0.015625 , iter= 8719
current loss is: 4.184615 , acc is: 0.0 , iter= 8720
current loss is: 4.19107 , acc is: 0.0 , iter= 8721
current loss is: 4.022725 , acc is: 0.03125 , iter= 8722
current loss is: 4.051364 , acc is: 0.0625 , iter= 8723
current loss is: 4.1853247 , acc is: 0.03125 , iter= 8724
current loss is: 4.097654 , acc is: 0.03125 , iter= 8725
current loss is: 4.1352634 , acc is: 0.046875 , iter= 8726
current loss is: 4.00969 , acc is: 0.078125 , iter= 8727
current loss is: 4.1268578 , acc is: 0.0 , iter= 8728
current loss is: 4.1720886 , acc is: 0.03125 , iter= 8729
current loss is: 4.0827603 , acc is: 0.03125 , iter= 8730
current loss is: 4.093109 , acc is: 0.03125 , iter= 8731
current loss is: 4.1166 , acc is: 0.015625 , iter= 8732
current loss is: 4.104274 , acc is: 0.046875 , iter= 8733
current loss is: 4.1034393 , acc is: 0.03125 , iter= 8734
current loss is: 3.990231 , acc is: 0.03125 , iter= 8735
current loss is: 4.0405617 , acc is: 0.0625 , iter= 8736
current loss is: 4.139654 , acc is: 0.015625 , iter= 8737
current loss is: 4.0307155 , acc is: 0.0625 , iter= 8738
current loss is: 4.0853243 , acc is: 0.046875 , iter= 8739
current loss is: 4.149945 , acc is: 0.046875 , iter= 8740
current loss is: 4.106763 , acc is: 0.03125 , iter= 8741
current loss is: 4.090805 , acc is: 0.03125 , iter= 8742
current loss is: 4.073457 , acc is: 0.015625 , iter= 8743
current loss is: 4.137471 , acc is: 0.015625 , iter= 8744
current loss is: 4.074853 , acc is: 0.03125 , iter= 8745
current loss is: 4.143938 , acc is: 0.046875 , iter= 8746
current loss is: 4.2215986 , acc is: 0.0 , iter= 8747
current loss is: 4.0294046 , acc is: 0.078125 , iter= 8748
current loss is: 4.114567 , acc is: 0.046875 , iter= 8749
current loss is: 4.130204 , acc is: 0.015625 , iter= 8750
current loss is: 4.057824 , acc is: 0.0625 , iter= 8751
current loss is: 4.1194754 , acc is: 0.03125 , iter= 8752
current loss is: 4.1277795 , acc is: 0.046875 , iter= 8753
current loss is: 4.1702323 , acc is: 0.03125 , iter= 8754
current loss is: 4.1467 , acc is: 0.015625 , iter= 8755
current loss is: 4.167086 , acc is: 0.015625 , iter= 8756
current loss is: 4.0901756 , acc is: 0.0625 , iter= 8757
current loss is: 3.943231 , acc is: 0.046875 , iter= 8758
current loss is: 4.073658 , acc is: 0.03125 , iter= 8759
current loss is: 4.1145616 , acc is: 0.046875 , iter= 8760
current loss is: 4.263983 , acc is: 0.0 , iter= 8761
current loss is: 4.123767 , acc is: 0.015625 , iter= 8762
current loss is: 4.0745473 , acc is: 0.015625 , iter= 8763
current loss is: 4.1497216 , acc is: 0.015625 , iter= 8764
current loss is: 4.1041574 , acc is: 0.03125 , iter= 8765
current loss is: 4.1255703 , acc is: 0.046875 , iter= 8766
current loss is: 4.091028 , acc is: 0.03125 , iter= 8767
current loss is: 4.0559444 , acc is: 0.046875 , iter= 8768
current loss is: 4.127331 , acc is: 0.03125 , iter= 8769
current loss is: 3.9782689 , acc is: 0.0625 , iter= 8770
current loss is: 4.1748447 , acc is: 0.03125 , iter= 8771
current loss is: 4.1034584 , acc is: 0.015625 , iter= 8772
current loss is: 4.014839 , acc is: 0.0625 , iter= 8773
current loss is: 4.1322193 , acc is: 0.015625 , iter= 8774
current loss is: 4.095077 , acc is: 0.046875 , iter= 8775
current loss is: 4.046533 , acc is: 0.046875 , iter= 8776
current loss is: 4.1449847 , acc is: 0.0 , iter= 8777
current loss is: 4.171346 , acc is: 0.015625 , iter= 8778
current loss is: 4.0235453 , acc is: 0.03125 , iter= 8779
current loss is: 4.0092144 , acc is: 0.03125 , iter= 8780
current loss is: 4.0866857 , acc is: 0.015625 , iter= 8781
current loss is: 4.1256027 , acc is: 0.015625 , iter= 8782
current loss is: 4.123846 , acc is: 0.0625 , iter= 8783
current loss is: 4.026519 , acc is: 0.109375 , iter= 8784
current loss is: 4.1107783 , acc is: 0.0 , iter= 8785
current loss is: 4.241403 , acc is: 0.0 , iter= 8786
current loss is: 4.1378474 , acc is: 0.03125 , iter= 8787
current loss is: 4.1793156 , acc is: 0.015625 , iter= 8788
current loss is: 4.0919785 , acc is: 0.0 , iter= 8789
current loss is: 4.063837 , acc is: 0.046875 , iter= 8790
current loss is: 4.104368 , acc is: 0.03125 , iter= 8791
current loss is: 4.0009747 , acc is: 0.046875 , iter= 8792
current loss is: 4.0773463 , acc is: 0.0625 , iter= 8793
current loss is: 4.1049385 , acc is: 0.015625 , iter= 8794
current loss is: 4.151908 , acc is: 0.0 , iter= 8795
current loss is: 4.0720587 , acc is: 0.015625 , iter= 8796
current loss is: 4.0978827 , acc is: 0.015625 , iter= 8797
current loss is: 4.1100097 , acc is: 0.015625 , iter= 8798
current loss is: 4.181447 , acc is: 0.0 , iter= 8799
current loss is: 4.1407976 , acc is: 0.0 , iter= 8800
current loss is: 4.154002 , acc is: 0.015625 , iter= 8801
current loss is: 4.1240244 , acc is: 0.03125 , iter= 8802
current loss is: 4.0959883 , acc is: 0.03125 , iter= 8803
current loss is: 4.09673 , acc is: 0.046875 , iter= 8804
current loss is: 4.0684786 , acc is: 0.03125 , iter= 8805
current loss is: 4.126674 , acc is: 0.0 , iter= 8806
current loss is: 4.0285215 , acc is: 0.0625 , iter= 8807
current loss is: 4.10571 , acc is: 0.046875 , iter= 8808
current loss is: 4.190098 , acc is: 0.0 , iter= 8809
current loss is: 4.1214743 , acc is: 0.046875 , iter= 8810
current loss is: 4.0795326 , acc is: 0.046875 , iter= 8811
current loss is: 4.162691 , acc is: 0.0 , iter= 8812
current loss is: 4.059964 , acc is: 0.046875 , iter= 8813
current loss is: 4.0967693 , acc is: 0.015625 , iter= 8814
current loss is: 4.0813603 , acc is: 0.03125 , iter= 8815
current loss is: 4.122595 , acc is: 0.015625 , iter= 8816
current loss is: 4.1263323 , acc is: 0.03125 , iter= 8817
current loss is: 4.003764 , acc is: 0.03125 , iter= 8818
current loss is: 4.057188 , acc is: 0.03125 , iter= 8819
current loss is: 4.2112923 , acc is: 0.015625 , iter= 8820
current loss is: 4.068404 , acc is: 0.03125 , iter= 8821
current loss is: 4.044281 , acc is: 0.046875 , iter= 8822
current loss is: 4.017522 , acc is: 0.109375 , iter= 8823
current loss is: 4.0524673 , acc is: 0.046875 , iter= 8824
current loss is: 4.142994 , acc is: 0.046875 , iter= 8825
current loss is: 4.129668 , acc is: 0.03125 , iter= 8826
current loss is: 4.130642 , acc is: 0.0 , iter= 8827
current loss is: 4.091647 , acc is: 0.03125 , iter= 8828
current loss is: 4.082895 , acc is: 0.015625 , iter= 8829
current loss is: 4.0842695 , acc is: 0.0625 , iter= 8830
current loss is: 4.0552616 , acc is: 0.046875 , iter= 8831
current loss is: 4.099166 , acc is: 0.015625 , iter= 8832
current loss is: 4.0698986 , acc is: 0.0625 , iter= 8833
current loss is: 4.122836 , acc is: 0.03125 , iter= 8834
current loss is: 4.136024 , acc is: 0.046875 , iter= 8835
current loss is: 4.1173186 , acc is: 0.03125 , iter= 8836
current loss is: 4.1487427 , acc is: 0.015625 , iter= 8837
current loss is: 3.9953892 , acc is: 0.0625 , iter= 8838
current loss is: 4.1894217 , acc is: 0.03125 , iter= 8839
current loss is: 4.0251393 , acc is: 0.046875 , iter= 8840
current loss is: 4.09838 , acc is: 0.015625 , iter= 8841
current loss is: 4.1780844 , acc is: 0.015625 , iter= 8842
current loss is: 4.0585055 , acc is: 0.0625 , iter= 8843
current loss is: 4.1563506 , acc is: 0.015625 , iter= 8844
current loss is: 4.1599193 , acc is: 0.015625 , iter= 8845
current loss is: 4.151208 , acc is: 0.0 , iter= 8846
current loss is: 4.1754694 , acc is: 0.015625 , iter= 8847
current loss is: 4.1467905 , acc is: 0.046875 , iter= 8848
current loss is: 4.085206 , acc is: 0.03125 , iter= 8849
current loss is: 4.122922 , acc is: 0.015625 , iter= 8850
current loss is: 4.1070595 , acc is: 0.046875 , iter= 8851
current loss is: 4.059312 , acc is: 0.015625 , iter= 8852
current loss is: 3.9496765 , acc is: 0.0625 , iter= 8853
current loss is: 4.134016 , acc is: 0.0 , iter= 8854
current loss is: 4.148686 , acc is: 0.015625 , iter= 8855
current loss is: 4.0640445 , acc is: 0.03125 , iter= 8856
current loss is: 4.1818438 , acc is: 0.03125 , iter= 8857
current loss is: 3.9870796 , acc is: 0.046875 , iter= 8858
current loss is: 4.149582 , acc is: 0.015625 , iter= 8859
current loss is: 4.0190697 , acc is: 0.046875 , iter= 8860
current loss is: 4.133151 , acc is: 0.015625 , iter= 8861
current loss is: 4.1997585 , acc is: 0.03125 , iter= 8862
current loss is: 4.1185555 , acc is: 0.0 , iter= 8863
current loss is: 4.152522 , acc is: 0.046875 , iter= 8864
current loss is: 4.0280595 , acc is: 0.03125 , iter= 8865
current loss is: 4.106884 , acc is: 0.015625 , iter= 8866
current loss is: 4.0869527 , acc is: 0.0625 , iter= 8867
current loss is: 4.1321096 , acc is: 0.03125 , iter= 8868
current loss is: 4.025593 , acc is: 0.046875 , iter= 8869
current loss is: 4.1224203 , acc is: 0.03125 , iter= 8870
current loss is: 4.182443 , acc is: 0.046875 , iter= 8871
current loss is: 4.102702 , acc is: 0.03125 , iter= 8872
current loss is: 4.102165 , acc is: 0.046875 , iter= 8873
current loss is: 4.2012625 , acc is: 0.03125 , iter= 8874
current loss is: 4.1546755 , acc is: 0.015625 , iter= 8875
current loss is: 4.1133966 , acc is: 0.03125 , iter= 8876
current loss is: 4.1523767 , acc is: 0.0 , iter= 8877
current loss is: 4.1943927 , acc is: 0.015625 , iter= 8878
current loss is: 4.0092173 , acc is: 0.046875 , iter= 8879
current loss is: 4.115629 , acc is: 0.015625 , iter= 8880
current loss is: 3.9965034 , acc is: 0.109375 , iter= 8881
current loss is: 4.0803814 , acc is: 0.03125 , iter= 8882
current loss is: 4.0520134 , acc is: 0.015625 , iter= 8883
current loss is: 4.147729 , acc is: 0.0 , iter= 8884
current loss is: 4.1474504 , acc is: 0.015625 , iter= 8885
current loss is: 4.106635 , acc is: 0.015625 , iter= 8886
current loss is: 4.1297646 , acc is: 0.03125 , iter= 8887
current loss is: 4.1286607 , acc is: 0.015625 , iter= 8888
current loss is: 4.124789 , acc is: 0.046875 , iter= 8889
current loss is: 4.103207 , acc is: 0.03125 , iter= 8890
current loss is: 4.123928 , acc is: 0.03125 , iter= 8891
current loss is: 4.0755715 , acc is: 0.0625 , iter= 8892
current loss is: 4.0389347 , acc is: 0.015625 , iter= 8893
current loss is: 4.076441 , acc is: 0.046875 , iter= 8894
current loss is: 4.132931 , acc is: 0.015625 , iter= 8895
current loss is: 4.158202 , acc is: 0.0 , iter= 8896
current loss is: 4.083955 , acc is: 0.046875 , iter= 8897
current loss is: 4.113945 , acc is: 0.046875 , iter= 8898
current loss is: 4.0875254 , acc is: 0.015625 , iter= 8899
current loss is: 4.056015 , acc is: 0.046875 , iter= 8900
current loss is: 4.052302 , acc is: 0.03125 , iter= 8901
current loss is: 4.0509405 , acc is: 0.03125 , iter= 8902
current loss is: 4.1271186 , acc is: 0.03125 , iter= 8903
current loss is: 4.1011467 , acc is: 0.03125 , iter= 8904
current loss is: 4.1031637 , acc is: 0.03125 , iter= 8905
current loss is: 4.10761 , acc is: 0.046875 , iter= 8906
current loss is: 4.048562 , acc is: 0.015625 , iter= 8907
current loss is: 4.008618 , acc is: 0.0625 , iter= 8908
current loss is: 4.1776276 , acc is: 0.015625 , iter= 8909
current loss is: 4.0584946 , acc is: 0.046875 , iter= 8910
current loss is: 4.050933 , acc is: 0.0625 , iter= 8911
current loss is: 4.096937 , acc is: 0.015625 , iter= 8912
current loss is: 4.193631 , acc is: 0.0 , iter= 8913
current loss is: 4.13571 , acc is: 0.03125 , iter= 8914
current loss is: 4.100418 , acc is: 0.015625 , iter= 8915
current loss is: 4.122444 , acc is: 0.03125 , iter= 8916
current loss is: 4.1642437 , acc is: 0.0625 , iter= 8917
current loss is: 4.046434 , acc is: 0.0625 , iter= 8918
current loss is: 4.1211786 , acc is: 0.015625 , iter= 8919
current loss is: 4.130516 , acc is: 0.03125 , iter= 8920
current loss is: 4.0707054 , acc is: 0.046875 , iter= 8921
current loss is: 4.119094 , acc is: 0.015625 , iter= 8922
current loss is: 4.1679525 , acc is: 0.0 , iter= 8923
current loss is: 3.9969864 , acc is: 0.046875 , iter= 8924
current loss is: 4.1320887 , acc is: 0.03125 , iter= 8925
current loss is: 4.144844 , acc is: 0.015625 , iter= 8926
current loss is: 4.145948 , acc is: 0.0625 , iter= 8927
current loss is: 4.0939445 , acc is: 0.03125 , iter= 8928
current loss is: 4.1665606 , acc is: 0.03125 , iter= 8929
current loss is: 4.1161294 , acc is: 0.03125 , iter= 8930
current loss is: 4.172497 , acc is: 0.015625 , iter= 8931
current loss is: 4.184753 , acc is: 0.015625 , iter= 8932
current loss is: 4.0878534 , acc is: 0.0625 , iter= 8933
current loss is: 4.11037 , acc is: 0.03125 , iter= 8934
current loss is: 4.1344066 , acc is: 0.015625 , iter= 8935
current loss is: 4.0349884 , acc is: 0.0625 , iter= 8936
current loss is: 4.1282644 , acc is: 0.015625 , iter= 8937
current loss is: 4.1806 , acc is: 0.015625 , iter= 8938
current loss is: 4.070473 , acc is: 0.015625 , iter= 8939
current loss is: 4.121927 , acc is: 0.03125 , iter= 8940
current loss is: 4.163337 , acc is: 0.015625 , iter= 8941
current loss is: 4.128264 , acc is: 0.0 , iter= 8942
current loss is: 4.17735 , acc is: 0.03125 , iter= 8943
current loss is: 4.0066047 , acc is: 0.0625 , iter= 8944
current loss is: 3.9072504 , acc is: 0.078125 , iter= 8945
current loss is: 4.108625 , acc is: 0.015625 , iter= 8946
current loss is: 4.078495 , acc is: 0.03125 , iter= 8947
current loss is: 4.1097765 , acc is: 0.046875 , iter= 8948
current loss is: 4.1623225 , acc is: 0.03125 , iter= 8949
current loss is: 4.0994143 , acc is: 0.03125 , iter= 8950
current loss is: 4.147403 , acc is: 0.0 , iter= 8951
current loss is: 4.154025 , acc is: 0.03125 , iter= 8952
current loss is: 4.188038 , acc is: 0.015625 , iter= 8953
current loss is: 4.1411533 , acc is: 0.03125 , iter= 8954
current loss is: 4.1469965 , acc is: 0.046875 , iter= 8955
current loss is: 4.1260037 , acc is: 0.015625 , iter= 8956
current loss is: 3.9401467 , acc is: 0.046875 , iter= 8957
current loss is: 4.171585 , acc is: 0.015625 , iter= 8958
current loss is: 4.147294 , acc is: 0.0 , iter= 8959
current loss is: 3.9953008 , acc is: 0.03125 , iter= 8960
current loss is: 4.154191 , acc is: 0.03125 , iter= 8961
current loss is: 4.1523476 , acc is: 0.03125 , iter= 8962
current loss is: 4.106279 , acc is: 0.015625 , iter= 8963
current loss is: 4.1309123 , acc is: 0.03125 , iter= 8964
current loss is: 4.0624814 , acc is: 0.046875 , iter= 8965
current loss is: 4.0743265 , acc is: 0.03125 , iter= 8966
current loss is: 4.038915 , acc is: 0.0625 , iter= 8967
current loss is: 4.094489 , acc is: 0.046875 , iter= 8968
current loss is: 4.1363873 , acc is: 0.0625 , iter= 8969
current loss is: 4.196733 , acc is: 0.015625 , iter= 8970
current loss is: 4.1459413 , acc is: 0.03125 , iter= 8971
current loss is: 4.065941 , acc is: 0.046875 , iter= 8972
current loss is: 4.125143 , acc is: 0.0 , iter= 8973
current loss is: 3.9705627 , acc is: 0.09375 , iter= 8974
current loss is: 4.103839 , acc is: 0.015625 , iter= 8975
current loss is: 4.1213646 , acc is: 0.03125 , iter= 8976
current loss is: 4.0137534 , acc is: 0.046875 , iter= 8977
current loss is: 4.052044 , acc is: 0.078125 , iter= 8978
current loss is: 4.136676 , acc is: 0.0 , iter= 8979
current loss is: 4.155979 , acc is: 0.015625 , iter= 8980
current loss is: 4.063343 , acc is: 0.03125 , iter= 8981
current loss is: 4.1738605 , acc is: 0.046875 , iter= 8982
current loss is: 4.0866795 , acc is: 0.046875 , iter= 8983
current loss is: 4.1543655 , acc is: 0.015625 , iter= 8984
current loss is: 4.15375 , acc is: 0.015625 , iter= 8985
current loss is: 4.1480303 , acc is: 0.015625 , iter= 8986
current loss is: 4.1169243 , acc is: 0.03125 , iter= 8987
current loss is: 4.1201863 , acc is: 0.0 , iter= 8988
current loss is: 4.0788813 , acc is: 0.015625 , iter= 8989
current loss is: 3.9993362 , acc is: 0.078125 , iter= 8990
current loss is: 4.101946 , acc is: 0.046875 , iter= 8991
current loss is: 4.0953083 , acc is: 0.015625 , iter= 8992
current loss is: 4.180134 , acc is: 0.03125 , iter= 8993
current loss is: 3.9723358 , acc is: 0.0625 , iter= 8994
current loss is: 4.146805 , acc is: 0.03125 , iter= 8995
current loss is: 3.9422617 , acc is: 0.078125 , iter= 8996
current loss is: 4.0974703 , acc is: 0.03125 , iter= 8997
current loss is: 4.1693234 , acc is: 0.0 , iter= 8998
current loss is: 4.1638103 , acc is: 0.03125 , iter= 8999
current loss is: 4.1552606 , acc is: 0.015625 , iter= 9000
tot_acc= 18.0 tot_input= 768
current accuracy is: 0.0234375
current loss is: 4.164216 , acc is: 0.03125 , iter= 9001
current loss is: 4.022559 , acc is: 0.03125 , iter= 9002
current loss is: 4.1433506 , acc is: 0.015625 , iter= 9003
current loss is: 4.0788755 , acc is: 0.046875 , iter= 9004
current loss is: 4.089302 , acc is: 0.046875 , iter= 9005
current loss is: 4.067461 , acc is: 0.046875 , iter= 9006
current loss is: 4.1631513 , acc is: 0.078125 , iter= 9007
current loss is: 4.1384497 , acc is: 0.03125 , iter= 9008
current loss is: 4.14778 , acc is: 0.03125 , iter= 9009
current loss is: 4.1457415 , acc is: 0.03125 , iter= 9010
current loss is: 4.074912 , acc is: 0.046875 , iter= 9011
current loss is: 4.1419163 , acc is: 0.0 , iter= 9012
current loss is: 4.017113 , acc is: 0.03125 , iter= 9013
current loss is: 4.054139 , acc is: 0.03125 , iter= 9014
current loss is: 4.1245236 , acc is: 0.0 , iter= 9015
current loss is: 4.2012553 , acc is: 0.015625 , iter= 9016
current loss is: 4.107782 , acc is: 0.03125 , iter= 9017
current loss is: 4.1238146 , acc is: 0.046875 , iter= 9018
current loss is: 4.101092 , acc is: 0.0 , iter= 9019
current loss is: 4.0278206 , acc is: 0.0625 , iter= 9020
current loss is: 4.083351 , acc is: 0.046875 , iter= 9021
current loss is: 4.1921473 , acc is: 0.03125 , iter= 9022
current loss is: 4.071767 , acc is: 0.046875 , iter= 9023
current loss is: 3.9747787 , acc is: 0.09375 , iter= 9024
current loss is: 4.1010313 , acc is: 0.03125 , iter= 9025
current loss is: 4.132059 , acc is: 0.0 , iter= 9026
current loss is: 4.1161776 , acc is: 0.046875 , iter= 9027
current loss is: 4.1048746 , acc is: 0.015625 , iter= 9028
current loss is: 4.0678434 , acc is: 0.03125 , iter= 9029
current loss is: 3.991637 , acc is: 0.078125 , iter= 9030
current loss is: 4.008902 , acc is: 0.046875 , iter= 9031
current loss is: 4.176153 , acc is: 0.0 , iter= 9032
current loss is: 4.164265 , acc is: 0.015625 , iter= 9033
current loss is: 4.0859723 , acc is: 0.015625 , iter= 9034
current loss is: 4.0036807 , acc is: 0.078125 , iter= 9035
current loss is: 4.1683745 , acc is: 0.015625 , iter= 9036
current loss is: 4.086296 , acc is: 0.015625 , iter= 9037
current loss is: 4.02272 , acc is: 0.046875 , iter= 9038
current loss is: 4.1608896 , acc is: 0.0 , iter= 9039
current loss is: 4.1008434 , acc is: 0.046875 , iter= 9040
current loss is: 4.1277294 , acc is: 0.015625 , iter= 9041
current loss is: 4.1191416 , acc is: 0.015625 , iter= 9042
current loss is: 4.0160875 , acc is: 0.0625 , iter= 9043
current loss is: 4.239088 , acc is: 0.015625 , iter= 9044
current loss is: 4.144556 , acc is: 0.015625 , iter= 9045
current loss is: 4.0374765 , acc is: 0.03125 , iter= 9046
current loss is: 4.144333 , acc is: 0.0 , iter= 9047
current loss is: 4.1503434 , acc is: 0.0 , iter= 9048
current loss is: 4.191791 , acc is: 0.015625 , iter= 9049
current loss is: 3.9740334 , acc is: 0.078125 , iter= 9050
current loss is: 3.9491596 , acc is: 0.046875 , iter= 9051
current loss is: 4.1123548 , acc is: 0.015625 , iter= 9052
current loss is: 4.1601524 , acc is: 0.0 , iter= 9053
current loss is: 4.110591 , acc is: 0.046875 , iter= 9054
current loss is: 4.1222095 , acc is: 0.03125 , iter= 9055
current loss is: 4.102691 , acc is: 0.03125 , iter= 9056
current loss is: 4.0771966 , acc is: 0.046875 , iter= 9057
current loss is: 4.171945 , acc is: 0.0 , iter= 9058
current loss is: 4.1744566 , acc is: 0.015625 , iter= 9059
current loss is: 4.160775 , acc is: 0.015625 , iter= 9060
current loss is: 4.0976057 , acc is: 0.046875 , iter= 9061
current loss is: 4.101064 , acc is: 0.0625 , iter= 9062
current loss is: 4.063502 , acc is: 0.015625 , iter= 9063
current loss is: 4.1245346 , acc is: 0.03125 , iter= 9064
current loss is: 4.0693474 , acc is: 0.046875 , iter= 9065
current loss is: 4.155734 , acc is: 0.0 , iter= 9066
current loss is: 4.028472 , acc is: 0.046875 , iter= 9067
current loss is: 4.119016 , acc is: 0.015625 , iter= 9068
current loss is: 4.147175 , acc is: 0.0 , iter= 9069
current loss is: 4.096377 , acc is: 0.046875 , iter= 9070
current loss is: 4.1590815 , acc is: 0.015625 , iter= 9071
current loss is: 4.105906 , acc is: 0.015625 , iter= 9072
current loss is: 4.1109085 , acc is: 0.015625 , iter= 9073
current loss is: 4.1626577 , acc is: 0.0 , iter= 9074
current loss is: 3.946435 , acc is: 0.0625 , iter= 9075
current loss is: 4.124289 , acc is: 0.03125 , iter= 9076
current loss is: 4.111575 , acc is: 0.078125 , iter= 9077
current loss is: 4.1570153 , acc is: 0.015625 , iter= 9078
current loss is: 4.1825533 , acc is: 0.015625 , iter= 9079
current loss is: 4.1383367 , acc is: 0.03125 , iter= 9080
current loss is: 4.1874247 , acc is: 0.015625 , iter= 9081
current loss is: 4.133419 , acc is: 0.015625 , iter= 9082
current loss is: 4.0621743 , acc is: 0.046875 , iter= 9083
current loss is: 4.077619 , acc is: 0.046875 , iter= 9084
current loss is: 3.974247 , acc is: 0.0625 , iter= 9085
current loss is: 4.112606 , acc is: 0.015625 